{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b889bde-e223-4079-8468-2780b6a72b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done.\n",
      "  EWI summary: mw_actions_out/ewi_summary.csv\n",
      "  Minimal push summary: mw_actions_out/minimal_push_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# run_ewi_and_minimal_push.py\n",
    "# ------------------------------------------------------------\n",
    "# A) Early-warning indicators (variance, lag-1 AC) per subject\n",
    "#    computed on the observed H proxy series from your CSV.\n",
    "# B) Minimal intervention search to flip the hysteretic model\n",
    "#    back to the healthy branch using fitted global parameters.\n",
    "#\n",
    "# Inputs:\n",
    "#   - /mnt/data/combined_scfas_table_scored.csv  (must have subject_id, sample_id, H_proxy_meta_smooth or H_proxy_meta)\n",
    "#   - /mnt/data/fitted_global_params.csv         (from your previous fit)\n",
    "#\n",
    "# Outputs (in ./mw_actions_out):\n",
    "#   - ewi_summary.csv\n",
    "#   - ewi_<subject>.png (per-subject EWI plots)\n",
    "#   - minimal_push_summary.csv\n",
    "#   - minimal_push_<mode>.png (time-course plots for each successful mode)\n",
    "#\n",
    "# Reqs: numpy, pandas, scipy, matplotlib\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kendalltau\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "# ----------------- Config -----------------\n",
    "DATA_CSV = \"timeseries/combined_scfas_table_scored.csv\"\n",
    "PARAMS_CSV = \"mw_fit_out/fitted_global_params.csv\"\n",
    "OUTDIR = \"mw_actions_out\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "H_COL_CANDIDATES = [\"H_proxy_meta_smooth\", \"H_proxy_meta\"]\n",
    "TIME_COL = None            # if you have a real time col, put its name here; else we use within-subject index\n",
    "MIN_SERIES = 8             # minimum points for EWI on a subject\n",
    "ROLL_FRAC = 0.25           # rolling window as fraction of series length (>= 6)\n",
    "EPS = 1e-6\n",
    "\n",
    "# ----------------- Load data -----------------\n",
    "df = pd.read_csv(DATA_CSV)\n",
    "h_col = None\n",
    "for c in H_COL_CANDIDATES:\n",
    "    if c in df.columns:\n",
    "        h_col = c\n",
    "        break\n",
    "if h_col is None:\n",
    "    raise ValueError(\"No H proxy column found (looked for H_proxy_meta_smooth or H_proxy_meta).\")\n",
    "\n",
    "if TIME_COL and TIME_COL in df.columns:\n",
    "    df = df.dropna(subset=[\"subject_id\", \"sample_id\", TIME_COL]).copy()\n",
    "else:\n",
    "    df = df.dropna(subset=[\"subject_id\", \"sample_id\"]).copy()\n",
    "    df[\"t_idx\"] = df.groupby(\"subject_id\").cumcount().astype(float)\n",
    "    TIME_COL = \"t_idx\"\n",
    "\n",
    "# clip H into [0,1]\n",
    "df[\"H_obs\"] = df[h_col].clip(0, 1)\n",
    "df = df.sort_values([\"subject_id\", TIME_COL])\n",
    "\n",
    "# ----------------- A) Early-warning indicators -----------------\n",
    "def rolling_ac1(x):\n",
    "    x = np.asarray(x, float)\n",
    "    if len(x) < 2 or np.all(~np.isfinite(x)):\n",
    "        return np.nan\n",
    "    x0 = x[:-1]; x1 = x[1:]\n",
    "    mask = np.isfinite(x0) & np.isfinite(x1)\n",
    "    if mask.sum() < 3:\n",
    "        return np.nan\n",
    "    return float(np.corrcoef(x0[mask], x1[mask])[0, 1])\n",
    "\n",
    "ewi_rows = []\n",
    "for sid, sub in df.groupby(\"subject_id\"):\n",
    "    t = sub[TIME_COL].values.astype(float)\n",
    "    H = sub[\"H_obs\"].values.astype(float)\n",
    "    # require enough finite points\n",
    "    mask_fin = np.isfinite(H)\n",
    "    if mask_fin.sum() < MIN_SERIES:\n",
    "        continue\n",
    "\n",
    "    # rolling window\n",
    "    w = max(6, int(np.ceil(len(H) * ROLL_FRAC)))\n",
    "    # variance\n",
    "    H_var = pd.Series(H).rolling(window=w, min_periods=max(4, w//2)).var().values\n",
    "    # lag-1 autocorrelation (computed per window)\n",
    "    H_ac1 = pd.Series(H).rolling(window=w, min_periods=max(4, w//2)).apply(rolling_ac1, raw=False).values\n",
    "\n",
    "    # trend tests (Kendall's tau) on available points\n",
    "    def tau_trend(series):\n",
    "        m = np.isfinite(series) & np.isfinite(t)\n",
    "        if m.sum() < 6:  # need enough for a meaningful rank test\n",
    "            return np.nan, np.nan\n",
    "        tau, p = kendalltau(t[m], series[m])\n",
    "        return float(tau), float(p)\n",
    "\n",
    "    tau_var, p_var = tau_trend(H_var)\n",
    "    tau_ac1, p_ac1 = tau_trend(H_ac1)\n",
    "\n",
    "    # save per-subject plot\n",
    "    fig, ax = plt.subplots(3, 1, figsize=(8, 9), sharex=True)\n",
    "    ax[0].plot(t, H, lw=1.8); ax[0].set_ylabel(\"H proxy\")\n",
    "    ax[0].grid(True, ls=\":\", alpha=0.6)\n",
    "    ax[1].plot(t, H_var, lw=1.8); ax[1].set_ylabel(\"Var(H)\")\n",
    "    ax[1].set_title(f\"{sid} | τ_var={tau_var:.2f} (p={p_var:.3g})\")\n",
    "    ax[1].grid(True, ls=\":\", alpha=0.6)\n",
    "    ax[2].plot(t, H_ac1, lw=1.8); ax[2].set_ylabel(\"AC1(H)\"); ax[2].set_xlabel(\"time\")\n",
    "    ax[2].set_title(f\"τ_ac1={tau_ac1:.2f} (p={p_ac1:.3g})\")\n",
    "    ax[2].grid(True, ls=\":\", alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTDIR, f\"ewi_{sid}.png\"), dpi=180)\n",
    "    plt.close()\n",
    "\n",
    "    ewi_rows.append({\n",
    "        \"subject_id\": sid, \"n_points\": int(mask_fin.sum()),\n",
    "        \"window\": int(w),\n",
    "        \"tau_var\": tau_var, \"p_var\": p_var,\n",
    "        \"tau_ac1\": tau_ac1, \"p_ac1\": p_ac1\n",
    "    })\n",
    "\n",
    "ewi_df = pd.DataFrame(ewi_rows).sort_values([\"p_var\", \"p_ac1\"])\n",
    "ewi_df.to_csv(os.path.join(OUTDIR, \"ewi_summary.csv\"), index=False)\n",
    "\n",
    "# ----------------- B) Minimal intervention search -----------------\n",
    "# Load fitted global parameters\n",
    "g = pd.read_csv(PARAMS_CSV, index_col=0).squeeze(\"columns\")\n",
    "# Ordered parameter vector expected by rhs: [r_max,K_M,c,d,g,u,p_low,p_high,H_on,H_off,tau_q]\n",
    "pars = [\n",
    "    float(g.get(\"r_max\", 0.32)),\n",
    "    float(g.get(\"K_M\", 1.0)),\n",
    "    float(g.get(\"c\", 0.10)),\n",
    "    float(g.get(\"d\", 0.12)),     # baseline d for intervention tests\n",
    "    float(g.get(\"g\", 0.5)),\n",
    "    float(g.get(\"u\", 0.6)),\n",
    "    float(g.get(\"p_low\", 0.1)),\n",
    "    float(g.get(\"p_high\", 2.5)),\n",
    "    float(g.get(\"H_on\", 0.55)),\n",
    "    float(g.get(\"H_off\", 0.70)),\n",
    "    float(g.get(\"tau_q\", 4.0)),\n",
    "]\n",
    "\n",
    "# Model with intervention\n",
    "def rhs_mem(t, y, p, U=0.0, T=0.0, mode=\"butyrate\"):\n",
    "    M, H, B, q = y\n",
    "    r_max, K_M, c, d, gH, u, pL, pH, H_on, H_off, tau = p\n",
    "    pB = pL + (pH - pL) * np.clip(q, 0, 1)\n",
    "\n",
    "    # base dynamics\n",
    "    r_eff = r_max\n",
    "    inp_B = 0.0\n",
    "    pB_aug = 0.0\n",
    "\n",
    "    if t <= T and U > 0:\n",
    "        if mode == \"butyrate\":           # direct butyrate input (e.g., releasing formulation)\n",
    "            inp_B = U\n",
    "        elif mode == \"prebiotic\":        # transiently augments production rate\n",
    "            pB_aug = U\n",
    "        elif mode == \"engineered\":       # transient boost to growth (seeding/engineered producer)\n",
    "            r_eff = r_max + U\n",
    "\n",
    "    dM = (r_eff - c * pB) * M * (1 - M / K_M)\n",
    "    dH = gH * B * (1 - H) - d * H\n",
    "    dB = (pB + pB_aug) * M - u * H * B + inp_B\n",
    "\n",
    "    if H < H_on:\n",
    "        q_inf = 1.0\n",
    "    elif H > H_off:\n",
    "        q_inf = 0.0\n",
    "    else:\n",
    "        q_inf = q\n",
    "    dq = (q_inf - q) / tau\n",
    "    return [dM, dH, dB, dq]\n",
    "\n",
    "def integrate(p, y0, U=0.0, T=0.0, mode=\"butyrate\", T_end=220.0):\n",
    "    ts = np.linspace(0, T_end, 900)\n",
    "    sol = solve_ivp(lambda t,y: rhs_mem(t, y, p, U=U, T=T, mode=mode),\n",
    "                    (0, T_end), y0, t_eval=ts, rtol=1e-6, atol=1e-8, max_step=0.5)\n",
    "    return sol\n",
    "\n",
    "# Get a \"bad-branch\" steady state y_bad at baseline d by relaxing from low-H\n",
    "def relax_to_branch(p, H_init=0.55, q_init=1.0, T_relax=200.0):\n",
    "    y0 = np.array([0.2, H_init, 0.1, q_init], float)\n",
    "    sol = solve_ivp(lambda t,y: rhs_mem(t,y,p), (0, T_relax), y0,\n",
    "                    t_eval=np.linspace(0, T_relax, 600),\n",
    "                    rtol=1e-6, atol=1e-8, max_step=0.5)\n",
    "    return sol.y[:, -1], sol\n",
    "\n",
    "y_bad, _ = relax_to_branch(pars, H_init=min(0.6, pars[9]-0.05), q_init=1.0, T_relax=220.0)\n",
    "\n",
    "def success(sol, H_off, eps=0.02):\n",
    "    # success = ends above H_off with q ~ off\n",
    "    H_end = float(np.mean(sol.y[1, -40:]))\n",
    "    q_end = float(np.mean(sol.y[3, -40:]))\n",
    "    return (H_end > H_off + eps) and (q_end < 0.2)\n",
    "\n",
    "modes = [\"butyrate\", \"prebiotic\", \"engineered\"]\n",
    "U_grid = np.linspace(0.02, 1.2, 25)     # magnitude grid\n",
    "T_grid = np.linspace(2.0, 60.0, 20)     # duration grid\n",
    "\n",
    "summary = []\n",
    "for mode in modes:\n",
    "    found = None\n",
    "    for U in U_grid:\n",
    "        for T in T_grid:\n",
    "            sol = integrate(pars, y_bad, U=U, T=T, mode=mode, T_end=240.0)\n",
    "            if success(sol, pars[9]):\n",
    "                found = (U, T, sol)\n",
    "                break\n",
    "        if found:\n",
    "            break\n",
    "    if found:\n",
    "        U_found, T_found, sol_found = found\n",
    "        summary.append({\"mode\": mode, \"U\": U_found, \"T\": T_found, \"success\": True})\n",
    "        # plot time course\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(sol_found.t, sol_found.y[1], lw=2, label=\"H\")\n",
    "        plt.plot(sol_found.t, sol_found.y[3], lw=1.5, label=\"q\")\n",
    "        plt.axhline(pars[8], ls=\":\", c=\"gray\", label=\"H_on\")\n",
    "        plt.axhline(pars[9], ls=\"--\", c=\"gray\", label=\"H_off\")\n",
    "        plt.axvline(T_found, ls=\"-.\", c=\"k\", alpha=0.6, label=\"end of intervention\")\n",
    "        plt.title(f\"{mode}: minimal-ish U={U*:.2f}, T={T*:.1f} h\")\n",
    "        plt.xlabel(\"time (h)\"); plt.ylabel(\"H, q\")\n",
    "        plt.legend(); plt.grid(True, ls=\":\", alpha=0.6)\n",
    "        plt.tight_layout(); plt.savefig(os.path.join(OUTDIR, f\"minimal_push_{mode}.png\"), dpi=180)\n",
    "        plt.close()\n",
    "    else:\n",
    "        summary.append({\"mode\": mode, \"U\": np.nan, \"T\": np.nan, \"success\": False})\n",
    "\n",
    "pd.DataFrame(summary).to_csv(os.path.join(OUTDIR, \"minimal_push_summary.csv\"), index=False)\n",
    "\n",
    "print(\"✅ Done.\")\n",
    "print(f\"  EWI summary: {os.path.join(OUTDIR,'ewi_summary.csv')}\")\n",
    "print(f\"  Minimal push summary: {os.path.join(OUTDIR,'minimal_push_summary.csv')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b03a8844-edbb-47d3-a7e3-337af7fbe126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 subjects with strongest EWI signals (lower score = stronger):\n",
      "subject_id  n_points   tau_var    p_var   tau_ac1    p_ac1  ewi_score\n",
      "     H4004         8  1.000000 0.002778  0.333333 0.469444   0.236111\n",
      "     M2085         7 -0.800000 0.083333  0.800000 0.083333   0.333333\n",
      "     H4010         7  0.527046 0.206507 -0.737865 0.076974   0.391741\n",
      "     C3023         7 -0.800000 0.083333  0.600000 0.233333   0.408333\n",
      "     H4014         6 -1.000000 0.083333 -0.666667 0.333333   0.458333\n",
      "     P6010         6 -1.000000 0.083333 -0.666667 0.333333   0.458333\n",
      "     C3002         6 -0.666667 0.333333 -0.666667 0.333333   0.583333\n",
      "     H4006         6 -0.666667 0.333333  0.666667 0.333333   0.583333\n",
      "     P6016         6 -0.666667 0.333333  0.666667 0.333333   0.583333\n",
      "     M2008         6  0.666667 0.333333  0.000000 1.000000   0.666667\n",
      "\n",
      "Saved ranked EWI list -> mw_actions_out/ewi_ranked.csv\n"
     ]
    }
   ],
   "source": [
    "# analyze_ewi.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "EWI_CSV = \"mw_actions_out_2/ewi_summary.csv\"\n",
    "df = pd.read_csv(EWI_CSV)\n",
    "\n",
    "# prefer subjects with positive tau and low p for BOTH variance and AC1\n",
    "def score_row(r):\n",
    "    # smaller is better\n",
    "    p_var = r.get(\"p_var\", np.nan)\n",
    "    p_ac1 = r.get(\"p_ac1\", np.nan)\n",
    "    tau_var = r.get(\"tau_var\", 0.0)\n",
    "    tau_ac1 = r.get(\"tau_ac1\", 0.0)\n",
    "    # encourage positive tau (increasing trends), penalize negative\n",
    "    tau_pen = (0.0 if (tau_var >= 0 and tau_ac1 >= 0) else 0.25)\n",
    "    return (p_var + p_ac1) / 2.0 + tau_pen\n",
    "\n",
    "df[\"ewi_score\"] = df.apply(score_row, axis=1)\n",
    "df = df.sort_values([\"ewi_score\", \"p_var\", \"p_ac1\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nTop 10 subjects with strongest EWI signals (lower score = stronger):\")\n",
    "cols = [\"subject_id\",\"n_points\",\"tau_var\",\"p_var\",\"tau_ac1\",\"p_ac1\",\"ewi_score\"]\n",
    "print(df[cols].head(10).to_string(index=False))\n",
    "\n",
    "# Save ranked list\n",
    "df.to_csv(\"mw_actions_out/ewi_ranked.csv\", index=False)\n",
    "print(\"\\nSaved ranked EWI list -> mw_actions_out/ewi_ranked.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87469eae-df37-4159-b7eb-75d59495e884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         mode  U_refined  T_refined  area_UxT\n",
      "0    butyrate        NaN        NaN       NaN\n",
      "1   prebiotic        NaN        NaN       NaN\n",
      "2  engineered        NaN        NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "# refine_minimal_push.py\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "PARAMS = pd.read_csv(\"mw_fit_out/fitted_global_params.csv\", index_col=0).squeeze(\"columns\")\n",
    "\n",
    "pars = [\n",
    "    float(PARAMS.get(\"r_max\", 0.32)),\n",
    "    float(PARAMS.get(\"K_M\", 1.0)),\n",
    "    float(PARAMS.get(\"c\", 0.10)),\n",
    "    float(PARAMS.get(\"d\", 0.12)),\n",
    "    float(PARAMS.get(\"g\", 0.5)),\n",
    "    float(PARAMS.get(\"u\", 0.6)),\n",
    "    float(PARAMS.get(\"p_low\", 0.1)),\n",
    "    float(PARAMS.get(\"p_high\", 2.5)),\n",
    "    float(PARAMS.get(\"H_on\", 0.55)),\n",
    "    float(PARAMS.get(\"H_off\", 0.70)),\n",
    "    float(PARAMS.get(\"tau_q\", 4.0)),\n",
    "]\n",
    "\n",
    "def rhs_mem(t, y, p, U=0.0, T=0.0, mode=\"butyrate\"):\n",
    "    M,H,B,q = y\n",
    "    r_max,K_M,c,d,gH,u,pL,pH,H_on,H_off,tau = p\n",
    "    pB = pL + (pH - pL)*np.clip(q,0,1)\n",
    "    r_eff = r_max\n",
    "    inp_B = 0.0\n",
    "    pB_aug = 0.0\n",
    "    if t <= T and U > 0:\n",
    "        if mode == \"butyrate\": inp_B = U\n",
    "        elif mode == \"prebiotic\": pB_aug = U\n",
    "        elif mode == \"engineered\": r_eff = r_max + U\n",
    "    dM = (r_eff - c*pB)*M*(1 - M/K_M)\n",
    "    dH = gH*B*(1 - H) - d*H\n",
    "    dB = (pB + pB_aug)*M - u*H*B + inp_B\n",
    "    if H < H_on: q_inf=1.0\n",
    "    elif H > H_off: q_inf=0.0\n",
    "    else: q_inf=q\n",
    "    dq = (q_inf - q)/tau\n",
    "    return [dM,dH,dB,dq]\n",
    "\n",
    "def integrate(p, y0, U=0.0, T=0.0, mode=\"butyrate\", T_end=240):\n",
    "    ts = np.linspace(0, T_end, 900)\n",
    "    sol = solve_ivp(lambda t,y: rhs_mem(t,y,p,U=U,T=T,mode=mode),\n",
    "                    (0, T_end), y0, t_eval=ts, rtol=1e-6, atol=1e-8, max_step=0.5)\n",
    "    return sol\n",
    "\n",
    "def relax_bad(p):\n",
    "    y0 = np.array([0.2, min(0.6, p[9]-0.05), 0.1, 1.0], float)\n",
    "    sol = integrate(p, y0, T_end=220)\n",
    "    return sol.y[:,-1]\n",
    "\n",
    "def success(sol, H_off, eps=0.02):\n",
    "    H_end = float(np.mean(sol.y[1,-40:])); q_end=float(np.mean(sol.y[3,-40:]))\n",
    "    return (H_end > H_off + eps) and (q_end < 0.2)\n",
    "\n",
    "modes = [\"butyrate\",\"prebiotic\",\"engineered\"]\n",
    "coarse = pd.read_csv(\"mw_actions_out/minimal_push_summary.csv\")\n",
    "\n",
    "y_bad = relax_bad(pars)\n",
    "\n",
    "def refine_one(mode, U0, T0):\n",
    "    if not np.isfinite(U0) or not np.isfinite(T0):\n",
    "        return None\n",
    "    best = (U0, T0)\n",
    "    stepU, stepT = max(0.05, 0.2*U0), max(1.0, 0.2*T0)\n",
    "    improved=True\n",
    "    while improved and (stepU>0.01 or stepT>0.5):\n",
    "        improved=False\n",
    "        for dU,dT in [(+1,0),(-1,0),(0,+1),(0,-1),(+1,+1),(+1,-1),(-1,+1),(-1,-1)]:\n",
    "            U_try = max(0.0, best[0] + dU*stepU)\n",
    "            T_try = max(0.5, best[1] + dT*stepT)\n",
    "            sol = integrate(pars, y_bad, U=U_try, T=T_try, mode=mode, T_end=240)\n",
    "            if success(sol, pars[9]) and (U_try*T_try < best[0]*best[1] - 1e-6):\n",
    "                best=(U_try,T_try); improved=True\n",
    "        if not improved:\n",
    "            stepU *= 0.5; stepT *= 0.5\n",
    "    return best\n",
    "\n",
    "rows=[]\n",
    "for _,r in coarse.iterrows():\n",
    "    mode=r[\"mode\"]; U0=r[\"U\"]; T0=r[\"T\"]; ok = bool(r[\"success\"])\n",
    "    if ok:\n",
    "        best=refine_one(mode,U0,T0)\n",
    "        if best:\n",
    "            rows.append({\"mode\":mode,\"U_refined\":best[0],\"T_refined\":best[1],\n",
    "                         \"area_UxT\":best[0]*best[1]})\n",
    "        else:\n",
    "            rows.append({\"mode\":mode,\"U_refined\":np.nan,\"T_refined\":np.nan,\"area_UxT\":np.nan})\n",
    "    else:\n",
    "        rows.append({\"mode\":mode,\"U_refined\":np.nan,\"T_refined\":np.nan,\"area_UxT\":np.nan})\n",
    "\n",
    "ref = pd.DataFrame(rows)\n",
    "ref.to_csv(\"mw_actions_out/minimal_push_refined.csv\", index=False)\n",
    "print(ref)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78e79416-7675-4aef-803c-ebc4a17b9491",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 70\u001b[0m\n\u001b[1;32m     68\u001b[0m     p \u001b[38;5;241m=\u001b[39m pars_base\u001b[38;5;241m.\u001b[39mcopy(); p[\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(d)\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m modes:\n\u001b[0;32m---> 70\u001b[0m         U,T \u001b[38;5;241m=\u001b[39m \u001b[43mfind_minimal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mUgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTgrid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m         rows\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m\"\u001b[39m:d, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m:mode, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mU_min\u001b[39m\u001b[38;5;124m\"\u001b[39m:U, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT_min\u001b[39m\u001b[38;5;124m\"\u001b[39m:T, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marea_UxT\u001b[39m\u001b[38;5;124m\"\u001b[39m: (U\u001b[38;5;241m*\u001b[39mT \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(U) \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(T) \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan)})\n\u001b[1;32m     73\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(rows)\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmw_actions_out/minimal_push_vs_d.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[6], line 57\u001b[0m, in \u001b[0;36mfind_minimal\u001b[0;34m(p, mode, U_grid, T_grid)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m U \u001b[38;5;129;01min\u001b[39;00m U_grid:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m T \u001b[38;5;129;01min\u001b[39;00m T_grid:\n\u001b[0;32m---> 57\u001b[0m         sol\u001b[38;5;241m=\u001b[39m\u001b[43mintegrate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_bad\u001b[49m\u001b[43m,\u001b[49m\u001b[43mU\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mU\u001b[49m\u001b[43m,\u001b[49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success(sol, p[\u001b[38;5;241m9\u001b[39m]):\n\u001b[1;32m     59\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m U,T\n",
      "Cell \u001b[0;32mIn[6], line 40\u001b[0m, in \u001b[0;36mintegrate\u001b[0;34m(p, y0, U, T, mode, T_end)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mintegrate\u001b[39m(p, y0, U\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, T\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbutyrate\u001b[39m\u001b[38;5;124m\"\u001b[39m, T_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m240\u001b[39m):\n\u001b[1;32m     39\u001b[0m     ts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, T_end, \u001b[38;5;241m900\u001b[39m)\n\u001b[0;32m---> 40\u001b[0m     sol \u001b[38;5;241m=\u001b[39m \u001b[43msolve_ivp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrhs_mem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43mU\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mU\u001b[49m\u001b[43m,\u001b[49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT_end\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sol\n",
      "File \u001b[0;32m/new/benpyenv/lib/python3.10/site-packages/scipy/integrate/_ivp/ivp.py:655\u001b[0m, in \u001b[0;36msolve_ivp\u001b[0;34m(fun, t_span, y0, method, t_eval, dense_output, events, vectorized, args, **options)\u001b[0m\n\u001b[1;32m    653\u001b[0m status \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m status \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 655\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    657\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m solver\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinished\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    658\u001b[0m         status \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/new/benpyenv/lib/python3.10/site-packages/scipy/integrate/_ivp/base.py:197\u001b[0m, in \u001b[0;36mOdeSolver.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt\n\u001b[0;32m--> 197\u001b[0m     success, message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m success:\n\u001b[1;32m    200\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailed\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/new/benpyenv/lib/python3.10/site-packages/scipy/integrate/_ivp/rk.py:147\u001b[0m, in \u001b[0;36mRungeKutta._step_impl\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    144\u001b[0m y_new, f_new \u001b[38;5;241m=\u001b[39m rk_step(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfun, t, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, h, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA,\n\u001b[1;32m    145\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mB, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mK)\n\u001b[1;32m    146\u001b[0m scale \u001b[38;5;241m=\u001b[39m atol \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mmaximum(np\u001b[38;5;241m.\u001b[39mabs(y), np\u001b[38;5;241m.\u001b[39mabs(y_new)) \u001b[38;5;241m*\u001b[39m rtol\n\u001b[0;32m--> 147\u001b[0m error_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_estimate_error_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_norm \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m error_norm \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/new/benpyenv/lib/python3.10/site-packages/scipy/integrate/_ivp/rk.py:109\u001b[0m, in \u001b[0;36mRungeKutta._estimate_error_norm\u001b[0;34m(self, K, h, scale)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_estimate_error_norm\u001b[39m(\u001b[38;5;28mself\u001b[39m, K, h, scale):\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_estimate_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# push_vs_d_sensitivity.py\n",
    "import numpy as np, pandas as pd\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "PARAMS = pd.read_csv(\"mw_fit_out/fitted_global_params.csv\", index_col=0).squeeze(\"columns\")\n",
    "pars_base = [\n",
    "    float(PARAMS.get(\"r_max\", 0.32)),\n",
    "    float(PARAMS.get(\"K_M\", 1.0)),\n",
    "    float(PARAMS.get(\"c\", 0.10)),\n",
    "    float(PARAMS.get(\"d\", 0.12)),  # baseline d\n",
    "    float(PARAMS.get(\"g\", 0.5)),\n",
    "    float(PARAMS.get(\"u\", 0.6)),\n",
    "    float(PARAMS.get(\"p_low\", 0.1)),\n",
    "    float(PARAMS.get(\"p_high\", 2.5)),\n",
    "    float(PARAMS.get(\"H_on\", 0.55)),\n",
    "    float(PARAMS.get(\"H_off\", 0.70)),\n",
    "    float(PARAMS.get(\"tau_q\", 4.0)),\n",
    "]\n",
    "\n",
    "def rhs_mem(t, y, p, U=0.0, T=0.0, mode=\"butyrate\"):\n",
    "    M,H,B,q = y\n",
    "    r_max,K_M,c,d,gH,u,pL,pH,H_on,H_off,tau = p\n",
    "    pB = pL + (pH - pL)*np.clip(q,0,1)\n",
    "    r_eff=r_max; inp_B=0.0; pB_aug=0.0\n",
    "    if t<=T and U>0:\n",
    "        if mode==\"butyrate\": inp_B=U\n",
    "        elif mode==\"prebiotic\": pB_aug=U\n",
    "        elif mode==\"engineered\": r_eff=r_max+U\n",
    "    dM=(r_eff - c*pB)*M*(1 - M/K_M)\n",
    "    dH=gH*B*(1 - H) - d*H\n",
    "    dB=(pB + pB_aug)*M - u*H*B + inp_B\n",
    "    if H < H_on: q_inf=1.0\n",
    "    elif H > H_off: q_inf=0.0\n",
    "    else: q_inf=q\n",
    "    dq=(q_inf - q)/tau\n",
    "    return [dM,dH,dB,dq]\n",
    "\n",
    "def integrate(p, y0, U=0.0, T=0.0, mode=\"butyrate\", T_end=240):\n",
    "    ts = np.linspace(0, T_end, 900)\n",
    "    sol = solve_ivp(lambda t,y: rhs_mem(t,y,p,U=U,T=T,mode=mode),\n",
    "                    (0, T_end), y0, t_eval=ts, rtol=1e-6, atol=1e-8, max_step=0.5)\n",
    "    return sol\n",
    "\n",
    "def relax_bad(p):\n",
    "    y0=np.array([0.2, min(0.6, p[9]-0.05), 0.1, 1.0], float)\n",
    "    sol=integrate(p,y0,T_end=220)\n",
    "    return sol.y[:,-1]\n",
    "\n",
    "def success(sol, H_off, eps=0.02):\n",
    "    H_end=float(np.mean(sol.y[1,-40:])); q_end=float(np.mean(sol.y[3,-40:]))\n",
    "    return (H_end > H_off + eps) and (q_end < 0.2)\n",
    "\n",
    "def find_minimal(p, mode, U_grid, T_grid):\n",
    "    y_bad=relax_bad(p)\n",
    "    for U in U_grid:\n",
    "        for T in T_grid:\n",
    "            sol=integrate(p,y_bad,U=U,T=T,mode=mode)\n",
    "            if success(sol, p[9]):\n",
    "                return U,T\n",
    "    return np.nan,np.nan\n",
    "\n",
    "d_vals = np.linspace(pars_base[3]*0.7, pars_base[3]*1.3, 9)\n",
    "Ugrid=np.linspace(0.02,1.2,25); Tgrid=np.linspace(2.0,60.0,20)\n",
    "modes=[\"butyrate\",\"prebiotic\",\"engineered\"]\n",
    "\n",
    "rows=[]\n",
    "for d in d_vals:\n",
    "    p = pars_base.copy(); p[3]=float(d)\n",
    "    for mode in modes:\n",
    "        U,T = find_minimal(p, mode, Ugrid, Tgrid)\n",
    "        rows.append({\"d\":d, \"mode\":mode, \"U_min\":U, \"T_min\":T, \"area_UxT\": (U*T if np.isfinite(U) and np.isfinite(T) else np.nan)})\n",
    "\n",
    "pd.DataFrame(rows).to_csv(\"mw_actions_out/minimal_push_vs_d.csv\", index=False)\n",
    "print(\"saved: mw_actions_out/minimal_push_vs_d.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e9046d5-61ea-480a-aadc-30856cc2eb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EWI + minimal-push done. See: mw_actions_out_2\n"
     ]
    }
   ],
   "source": [
    "# run_ewi_and_minimal_push_shortseries_fix.py\n",
    "# Early-warning indicators adapted for short/flat series + minimal-push search\n",
    "\n",
    "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from scipy.stats import kendalltau\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "# ------------ Config ------------\n",
    "DATA_CSV   = \"timeseries/combined_scfas_table_scored.csv\"\n",
    "PARAMS_CSV = \"mw_fit_out/fitted_global_params.csv\"\n",
    "OUTDIR     = \"mw_actions_out_2\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "H_COLS = [\"H_proxy_meta_smooth\", \"H_proxy_meta\"]\n",
    "TIME_COL = None            # or set to a real timestamp col if you have it\n",
    "MIN_SERIES = 6             # allow shorter series than before\n",
    "EPS = 1e-9\n",
    "\n",
    "# ------------ Load ------------\n",
    "df = pd.read_csv(DATA_CSV)\n",
    "h_col = next((c for c in H_COLS if c in df.columns), None)\n",
    "if not h_col:\n",
    "    raise ValueError(\"Need H_proxy_meta_smooth or H_proxy_meta in the CSV.\")\n",
    "if TIME_COL and TIME_COL in df.columns:\n",
    "    df = df.dropna(subset=[\"subject_id\",\"sample_id\",TIME_COL]).copy()\n",
    "else:\n",
    "    df = df.dropna(subset=[\"subject_id\",\"sample_id\"]).copy()\n",
    "    df[\"t_idx\"] = df.groupby(\"subject_id\").cumcount().astype(float)\n",
    "    TIME_COL = \"t_idx\"\n",
    "\n",
    "df[\"H_obs\"] = df[h_col].clip(0,1)\n",
    "df = df.sort_values([\"subject_id\", TIME_COL])\n",
    "\n",
    "# ------------ helper funcs ------------\n",
    "def lag1_ac(x):\n",
    "    \"\"\"Unbiased lag-1 AC; returns 0 for constant/too-short series.\"\"\"\n",
    "    x = np.asarray(x, float)\n",
    "    m = np.isfinite(x)\n",
    "    x = x[m]\n",
    "    n = len(x)\n",
    "    if n < 3:\n",
    "        return np.nan\n",
    "    x = x - np.mean(x)\n",
    "    denom = np.dot(x, x)\n",
    "    if denom < EPS:\n",
    "        return 0.0\n",
    "    num = np.dot(x[:-1], x[1:])\n",
    "    return float(num / denom)\n",
    "\n",
    "def rolling_ac1_vec(x, w, minp):\n",
    "    \"\"\"Compute lag-1 AC over a rolling window.\"\"\"\n",
    "    out = np.full(len(x), np.nan, float)\n",
    "    for i in range(len(x)):\n",
    "        j0 = max(0, i - w + 1)\n",
    "        seg = x[j0:i+1]\n",
    "        if np.isfinite(seg).sum() >= minp:\n",
    "            out[i] = lag1_ac(seg)\n",
    "    return out\n",
    "\n",
    "# ------------ A) EWIs with short-series logic ------------\n",
    "rows = []\n",
    "for sid, sub in df.groupby(\"subject_id\"):\n",
    "    t = sub[TIME_COL].values.astype(float)\n",
    "    H = sub[\"H_obs\"].values.astype(float)\n",
    "    mfin = np.isfinite(H)\n",
    "    if mfin.sum() < MIN_SERIES:\n",
    "        continue\n",
    "\n",
    "    n = len(H)\n",
    "    # adaptive window for short series\n",
    "    w = max(3, int(np.floor(n/3)))\n",
    "    minp = max(3, int(np.ceil(w*0.6)))\n",
    "\n",
    "    # rolling variance\n",
    "    H_var = pd.Series(H).rolling(window=w, min_periods=minp).var().values\n",
    "    # rolling AC1\n",
    "    H_ac1 = rolling_ac1_vec(H, w, minp)\n",
    "\n",
    "    # trend tests (need at least 3 finite rolling points)\n",
    "    def tau_trend(y):\n",
    "        m = np.isfinite(y)\n",
    "        if m.sum() < 3:\n",
    "            return np.nan, np.nan\n",
    "        tau, p = kendalltau(t[m], y[m])\n",
    "        return float(tau), float(p)\n",
    "\n",
    "    tau_var, p_var = tau_trend(H_var)\n",
    "    tau_ac1, p_ac1 = tau_trend(H_ac1)\n",
    "\n",
    "    # fallbacks if too short/flat: compute global variance & AC1\n",
    "    global_var = float(np.nanvar(H)) if np.isfinite(H).sum() >= 3 else np.nan\n",
    "    global_ac1 = lag1_ac(H)\n",
    "\n",
    "    # annotate plot\n",
    "    fig, ax = plt.subplots(3,1, figsize=(8,9), sharex=True)\n",
    "    ax[0].plot(t, H, lw=1.8); ax[0].set_ylabel(\"H proxy\"); ax[0].grid(True, ls=\":\", alpha=0.6)\n",
    "    ttl = f\"{sid}\"\n",
    "    if np.allclose(np.nanvar(H), 0.0, atol=1e-6):\n",
    "        ttl += \" | (flat series)\"\n",
    "    ax[0].set_title(ttl)\n",
    "\n",
    "    ax[1].plot(t, H_var, lw=1.8); ax[1].set_ylabel(\"Var(H)\")\n",
    "    ax[1].set_title(f\"τ_var={np.nan if np.isnan(tau_var) else round(tau_var,2)}  p={np.nan if np.isnan(p_var) else f'{p_var:.3g}'}   [win={w}]\")\n",
    "    ax[1].grid(True, ls=\":\", alpha=0.6)\n",
    "\n",
    "    ax[2].plot(t, H_ac1, lw=1.8); ax[2].set_ylabel(\"AC1(H)\"); ax[2].set_xlabel(\"time\")\n",
    "    ax[2].set_title(f\"τ_ac1={np.nan if np.isnan(tau_ac1) else round(tau_ac1,2)}  p={np.nan if np.isnan(p_ac1) else f'{p_ac1:.3g}'}   (global AC1={None if np.isnan(global_ac1) else round(global_ac1,2)})\")\n",
    "    ax[2].grid(True, ls=\":\", alpha=0.6)\n",
    "\n",
    "    plt.tight_layout(); plt.savefig(os.path.join(OUTDIR, f\"ewi_{sid}.png\"), dpi=180); plt.close()\n",
    "\n",
    "    rows.append({\n",
    "        \"subject_id\": sid, \"n_points\": int(mfin.sum()),\n",
    "        \"window\": int(w),\n",
    "        \"tau_var\": tau_var, \"p_var\": p_var,\n",
    "        \"tau_ac1\": tau_ac1, \"p_ac1\": p_ac1,\n",
    "        \"global_var\": global_var, \"global_ac1\": global_ac1,\n",
    "        \"flat_series\": bool(np.allclose(np.nanvar(H), 0.0, atol=1e-6)),\n",
    "    })\n",
    "\n",
    "ewi_df = pd.DataFrame(rows)\n",
    "ewi_df.to_csv(os.path.join(OUTDIR, \"ewi_summary.csv\"), index=False)\n",
    "\n",
    "# ------------ B) Minimal-push search (same as before) ------------\n",
    "g = pd.read_csv(PARAMS_CSV, index_col=0).squeeze(\"columns\")\n",
    "pars = [\n",
    "    float(g.get(\"r_max\", 0.32)),\n",
    "    float(g.get(\"K_M\", 1.0)),\n",
    "    float(g.get(\"c\", 0.10)),\n",
    "    float(g.get(\"d\", 0.14)),\n",
    "    float(g.get(\"g\", 0.5)),\n",
    "    float(g.get(\"u\", 0.6)),\n",
    "    float(g.get(\"p_low\", 0.1)),\n",
    "    float(g.get(\"p_high\", 2.5)),\n",
    "    float(g.get(\"H_on\", 0.55)),\n",
    "    float(g.get(\"H_off\", 0.70)),\n",
    "    float(g.get(\"tau_q\", 5.0)),\n",
    "]\n",
    "\n",
    "def rhs_mem(t, y, p, U=0.0, T=0.0, mode=\"butyrate\"):\n",
    "    M, H, B, q = y\n",
    "    r_max,K_M,c,d,gH,u,pL,pH,H_on,H_off,tau = p\n",
    "    pB = pL + (pH - pL)*np.clip(q,0,1)\n",
    "    r_eff=r_max; inp_B=0.0; pB_aug=0.0\n",
    "    if t<=T and U>0:\n",
    "        if mode==\"butyrate\": inp_B=U\n",
    "        elif mode==\"prebiotic\": pB_aug=U\n",
    "        elif mode==\"engineered\": r_eff=r_max+U\n",
    "    dM=(r_eff - c*pB)*M*(1 - M/K_M)\n",
    "    dH=gH*B*(1 - H) - d*H\n",
    "    dB=(pB + pB_aug)*M - u*H*B + inp_B\n",
    "    if H < H_on: q_inf=1.0\n",
    "    elif H > H_off: q_inf=0.0\n",
    "    else: q_inf=q\n",
    "    dq=(q_inf - q)/tau\n",
    "    return [dM,dH,dB,dq]\n",
    "\n",
    "def integrate(p, y0, U=0.0, T=0.0, mode=\"butyrate\", T_end=240):\n",
    "    ts=np.linspace(0,T_end,900)\n",
    "    return solve_ivp(lambda t,y: rhs_mem(t,y,p,U=U,T=T,mode=mode),\n",
    "                     (0,T_end), y0, t_eval=ts, rtol=1e-6, atol=1e-8, max_step=0.5)\n",
    "\n",
    "def relax_bad(p):\n",
    "    y0=np.array([0.2, min(0.6, p[9]-0.05), 0.1, 1.0], float)\n",
    "    sol=integrate(p, y0, T_end=220)\n",
    "    return sol.y[:,-1]\n",
    "\n",
    "def success(sol, H_off, eps=0.00):\n",
    "    H_end=float(np.mean(sol.y[1,-40:])); q_end=float(np.mean(sol.y[3,-40:]))\n",
    "    return (H_end > H_off + eps) and (q_end < 0.35)\n",
    "\n",
    "y_bad=relax_bad(pars)\n",
    "\n",
    "modes=[\"butyrate\",\"prebiotic\",\"engineered\"]\n",
    "U_grid=np.linspace(0.02,2,40)\n",
    "T_grid=np.linspace(2.0,120.0,24)\n",
    "out=[]\n",
    "for mode in modes:\n",
    "    found=None\n",
    "    for U in U_grid:\n",
    "        for T in T_grid:\n",
    "            sol=integrate(pars,y_bad,U=U,T=T,mode=mode, T_end=240)\n",
    "            if success(sol, pars[9]):\n",
    "                found=(U,T,sol); break\n",
    "        if found: break\n",
    "    if found:\n",
    "        U_found,T_found,sol_found = found\n",
    "        out.append({\"mode\":mode,\"U\":U_found,\"T\":T_found,\"success\":True})\n",
    "        plt.figure(figsize=(8,6))\n",
    "        plt.plot(sol_found.t, sol_found.y[1], lw=2, label=\"H\")\n",
    "        plt.plot(sol_found.t, sol_found.y[3], lw=1.5, label=\"q\")\n",
    "        plt.axhline(pars[8], ls=\":\", c=\"gray\", label=\"H_on\")\n",
    "        plt.axhline(pars[9], ls=\"--\", c=\"gray\", label=\"H_off\")\n",
    "        plt.axvline(T_found, ls=\"-.\", c=\"k\", alpha=0.6, label=\"end of intervention\")\n",
    "        plt.title(f\"{mode}: minimal-ish U={U_found:.2f}, T={T_found:.1f} h\")\n",
    "        plt.xlabel(\"time (h)\"); plt.ylabel(\"H, q\")\n",
    "        plt.legend(); plt.grid(True, ls=\":\", alpha=0.6)\n",
    "        plt.tight_layout(); plt.savefig(os.path.join(OUTDIR, f\"minimal_push_{mode}.png\"), dpi=180)\n",
    "        plt.close()\n",
    "    else:\n",
    "        out.append({\"mode\":mode,\"U\":np.nan,\"T\":np.nan,\"success\":False})\n",
    "pd.DataFrame(out).to_csv(os.path.join(OUTDIR,\"minimal_push_summary.csv\"), index=False)\n",
    "print(\"✅ EWI + minimal-push done. See:\", OUTDIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e4c8a4-5658-4559-b129-5f83580e976f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "363c0e8e-d9c5-4c7c-b88a-41ab12e6eba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EWI overview ===\n",
      "subjects in EWI: 28\n",
      "with rolling trend (variance): 27\n",
      "with rolling trend (AC1):      27\n",
      "flat/short (fallback only):    1\n",
      "\n",
      "Top 10 by EWI score:\n",
      "subject_id  n_points  window   tau_var    p_var   tau_ac1    p_ac1  global_var  global_ac1  ewi_score\n",
      "     H4004         8       3  1.000000 0.002778  0.333333 0.469444    0.003747    0.204081   0.805556\n",
      "     M2085         7       3 -0.800000 0.083333  0.800000 0.083333    0.000938   -0.475822   1.166667\n",
      "     H4010         7       3  0.527046 0.206507 -0.737865 0.076974    0.000576    0.603034   1.388891\n",
      "     C3023         7       3 -0.800000 0.083333  0.600000 0.233333    0.001353    0.209515   1.416667\n",
      "     H4006         6       3 -0.666667 0.333333  0.666667 0.333333    0.036828    0.142807   1.666667\n",
      "     P6016         6       3 -0.666667 0.333333  0.666667 0.333333    0.000532    0.042997   1.666667\n",
      "     M2008         6       3  0.666667 0.333333  0.000000 1.000000    0.005067    0.579897   2.000000\n",
      "     C3009         6       3  0.333333 0.750000  0.333333 0.750000    0.003423    0.602452   2.166667\n",
      "     H4035         7       3  0.400000 0.483333 -0.200000 0.816667    0.001755    0.592616   2.200000\n",
      "     H4014         6       3 -1.000000 0.083333 -0.666667 0.333333    0.001470    0.069064   2.250000\n",
      "\n",
      "=== Minimal-push summary ===\n",
      "      mode   U   T  success\n",
      "  butyrate NaN NaN    False\n",
      " prebiotic NaN NaN    False\n",
      "engineered NaN NaN    False\n",
      "\n",
      "Effort proxy (U×T) among successes:\n",
      "      mode   U   T  area_UxT  success\n",
      "  butyrate NaN NaN       NaN    False\n",
      " prebiotic NaN NaN       NaN    False\n",
      "engineered NaN NaN       NaN    False\n"
     ]
    }
   ],
   "source": [
    "# summarize_results.py\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, os\n",
    "\n",
    "EWI = \"mw_actions_out_2/ewi_summary.csv\"\n",
    "MP  = \"mw_actions_out_2/minimal_push_summary.csv\"\n",
    "OUT = \"mw_actions_out_2\"\n",
    "os.makedirs(OUT, exist_ok=True)\n",
    "\n",
    "# ---------- Load ----------\n",
    "ewi = pd.read_csv(EWI)\n",
    "mp  = pd.read_csv(MP)\n",
    "\n",
    "# Clean up EWI NaNs -> informative flags\n",
    "ewi[\"has_trend_var\"] = ewi[\"tau_var\"].notna() & ewi[\"p_var\"].notna()\n",
    "ewi[\"has_trend_ac1\"] = ewi[\"tau_ac1\"].notna() & ewi[\"p_ac1\"].notna()\n",
    "ewi[\"flat_or_short\"] = (~ewi[\"has_trend_var\"]) & (~ewi[\"has_trend_ac1\"])\n",
    "\n",
    "# Score: prefer pos. tau & low p; fall back to global metrics if no trends\n",
    "def ewi_score(r):\n",
    "    # smaller is stronger “EWI”\n",
    "    score = 0.0\n",
    "    if r.get(\"tau_var\") is not np.nan and r.get(\"p_var\") is not np.nan:\n",
    "        score += max(0, 0.5 - 0.5*float(r[\"tau_var\"])) + float(r[\"p_var\"])\n",
    "    else:\n",
    "        # fall back: lower variance → weaker EWI; high AC1 → stronger EWI\n",
    "        gv = r.get(\"global_var\", np.nan)\n",
    "        ga = r.get(\"global_ac1\", np.nan)\n",
    "        score += (0.5 if np.isnan(gv) else 0.5 + 2.0/(1.0 + 10.0*gv))\n",
    "        score += (0.5 if np.isnan(ga) else 0.5 - 0.5*ga)  # higher AC1 => smaller score\n",
    "    if r.get(\"tau_ac1\") is not np.nan and r.get(\"p_ac1\") is not np.nan:\n",
    "        score += max(0, 0.5 - 0.5*float(r[\"tau_ac1\"])) + float(r[\"p_ac1\"])\n",
    "    return float(score)\n",
    "\n",
    "ewi[\"ewi_score\"] = ewi.apply(ewi_score, axis=1)\n",
    "ewi_sorted = ewi.sort_values(\"ewi_score\").reset_index(drop=True)\n",
    "ewi_sorted.to_csv(os.path.join(OUT, \"ewi_ranked.csv\"), index=False)\n",
    "\n",
    "print(\"\\n=== EWI overview ===\")\n",
    "print(f\"subjects in EWI: {len(ewi)}\")\n",
    "print(f\"with rolling trend (variance): {int(ewi['has_trend_var'].sum())}\")\n",
    "print(f\"with rolling trend (AC1):      {int(ewi['has_trend_ac1'].sum())}\")\n",
    "print(f\"flat/short (fallback only):    {int(ewi['flat_or_short'].sum())}\")\n",
    "print(\"\\nTop 10 by EWI score:\")\n",
    "print(ewi_sorted[[\"subject_id\",\"n_points\",\"window\",\"tau_var\",\"p_var\",\"tau_ac1\",\"p_ac1\",\"global_var\",\"global_ac1\",\"ewi_score\"]].head(10).to_string(index=False))\n",
    "\n",
    "# ---------- Minimal-push ----------\n",
    "print(\"\\n=== Minimal-push summary ===\")\n",
    "print(mp.to_string(index=False))\n",
    "\n",
    "# quick bar of successful modes (if any)\n",
    "if \"success\" in mp.columns:\n",
    "    fig, ax = plt.subplots(figsize=(5,3))\n",
    "    ax.bar(mp[\"mode\"], mp[\"success\"].astype(int))\n",
    "    ax.set_ylabel(\"success (0/1)\")\n",
    "    ax.set_title(\"Which modes flipped?\")\n",
    "    ax.grid(True, axis=\"y\", ls=\":\", alpha=0.6)\n",
    "    plt.tight_layout(); plt.savefig(os.path.join(OUT,\"minimal_push_success_bar.png\"), dpi=160); plt.close()\n",
    "\n",
    "# heatmap-like table (area proxy) if available\n",
    "if {\"U\",\"T\",\"success\"}.issubset(mp.columns):\n",
    "    mp2 = mp.copy()\n",
    "    mp2[\"area_UxT\"] = np.where(mp2[\"success\"], mp2[\"U\"]*mp2[\"T\"], np.nan)\n",
    "    print(\"\\nEffort proxy (U×T) among successes:\")\n",
    "    print(mp2[[\"mode\",\"U\",\"T\",\"area_UxT\",\"success\"]].to_string(index=False))\n",
    "    mp2.to_csv(os.path.join(OUT,\"minimal_push_summary_with_area.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d566fd3c-8088-4178-a00c-21f9f31fe1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: mw_bifurcation | Bistable at baseline?  NO\n"
     ]
    }
   ],
   "source": [
    "# bifurcation_and_basins.py\n",
    "# Checks: (A) equilibrium branches vs d, (B) stability via Jacobian eigenvalues,\n",
    "# (C) whether baseline d lies in a bistable interval, and (D) basin map at baseline.\n",
    "\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.optimize import root\n",
    "\n",
    "PARAMS_CSV = \"mw_fit_out/fitted_global_params.csv\"\n",
    "OUTDIR = \"mw_bifurcation\"; import os; os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "g = pd.read_csv(PARAMS_CSV, index_col=0).squeeze(\"columns\")\n",
    "# parameter vector: [r_max,K_M,c,d,g,u,p_low,p_high,H_on,H_off,tau_q]\n",
    "pars = np.array([\n",
    "    float(g.get(\"r_max\", 0.32)),\n",
    "    float(g.get(\"K_M\", 1.0)),\n",
    "    float(g.get(\"c\", 0.10)),\n",
    "    float(g.get(\"d\", 0.12)),   # baseline d\n",
    "    float(g.get(\"g\", 0.5)),\n",
    "    float(g.get(\"u\", 0.6)),\n",
    "    float(g.get(\"p_low\", 0.1)),\n",
    "    float(g.get(\"p_high\", 2.5)),\n",
    "    float(g.get(\"H_on\", 0.55)),\n",
    "    float(g.get(\"H_off\", 0.70)),\n",
    "    float(g.get(\"tau_q\", 4.0)),\n",
    "], float)\n",
    "\n",
    "def rhs(y, p, d_override=None):\n",
    "    M,H,B,q = y\n",
    "    r_max,K_M,c,d,gH,u,pL,pH,H_on,H_off,tau = p.copy()\n",
    "    if d_override is not None: d = d_override\n",
    "    pB = pL + (pH - pL)*np.clip(q,0,1)\n",
    "    dM = (r_max - c*pB)*M*(1 - M/K_M)\n",
    "    dH = gH*B*(1 - H) - d*H\n",
    "    dB = pB*M - u*H*B\n",
    "    # memory target\n",
    "    if H < H_on: q_inf=1.0\n",
    "    elif H > H_off: q_inf=0.0\n",
    "    else: q_inf=q\n",
    "    dq = (q_inf - q)/tau\n",
    "    return np.array([dM,dH,dB,dq], float)\n",
    "\n",
    "def jacobian(y, p, d_override=None, eps=1e-7):\n",
    "    # finite-diff Jacobian\n",
    "    f0 = rhs(y, p, d_override)\n",
    "    J = np.zeros((4,4))\n",
    "    for i in range(4):\n",
    "        y2 = y.copy(); y2[i] += eps\n",
    "        J[:,i] = (rhs(y2, p, d_override) - f0)/eps\n",
    "    return J\n",
    "\n",
    "def find_eq(p, d_val, guess):\n",
    "    fun = lambda y: rhs(y, p, d_override=d_val)\n",
    "    sol = root(fun, guess, method=\"hybr\")\n",
    "    if sol.success:\n",
    "        y = sol.x\n",
    "        # must be physical\n",
    "        if np.all(np.isfinite(y)) and y[0]>=-1e-6 and y[1]>=-1e-6 and y[2]>=-1e-6 and 0-1e-3<=y[3]<=1+1e-3:\n",
    "            return np.clip(y, [0,0,0,0], [np.inf, 1.2, np.inf, 1.2]), True\n",
    "    return guess, False\n",
    "\n",
    "# Continuation in d\n",
    "d_vals = np.linspace(pars[3]*0.6, pars[3]*1.5, 70)  # explore around baseline\n",
    "branches = {\"d\":[], \"H\":[], \"q\":[], \"stable\":[], \"which\":[]}\n",
    "\n",
    "# Try multiple seeds to capture multiple branches\n",
    "seeds = [\n",
    "    np.array([0.2, 0.2, 0.05, 1.0]),   # low-H memory on\n",
    "    np.array([0.2, 0.9, 0.10, 0.0]),   # high-H memory off\n",
    "    np.array([0.8, 0.5, 0.2, 0.5]),    # mid\n",
    "]\n",
    "\n",
    "for d in d_vals:\n",
    "    for wi, y0 in enumerate(seeds):\n",
    "        y_guess = y0.copy()\n",
    "        y_eq, ok = find_eq(pars, d, y_guess)\n",
    "        if ok:\n",
    "            J = jacobian(y_eq, pars, d_override=d)\n",
    "            eigs = np.linalg.eigvals(J)\n",
    "            stable = bool(np.max(np.real(eigs)) < 0)\n",
    "            branches[\"d\"].append(d)\n",
    "            branches[\"H\"].append(float(y_eq[1]))\n",
    "            branches[\"q\"].append(float(y_eq[3]))\n",
    "            branches[\"stable\"].append(stable)\n",
    "            branches[\"which\"].append(wi)\n",
    "\n",
    "df = pd.DataFrame(branches)\n",
    "df.to_csv(f\"{OUTDIR}/branches.csv\", index=False)\n",
    "\n",
    "# Plot branches\n",
    "plt.figure(figsize=(7,5))\n",
    "for wi in sorted(df[\"which\"].unique()):\n",
    "    sub = df[df[\"which\"]==wi]\n",
    "    plt.plot(sub[\"d\"], sub[\"H\"], \".\", ms=3, alpha=0.8, label=f\"seed{wi}\")\n",
    "# mark stability\n",
    "for st, m in [(True, \"o\"), (False, \"x\")]:\n",
    "    sub = df[df[\"stable\"]==st]\n",
    "    plt.scatter(sub[\"d\"], sub[\"H\"], marker=m, s=18, label=f\"{'stable' if st else 'unstable'}\", alpha=0.6)\n",
    "plt.axvline(pars[3], ls=\"--\", c=\"gray\", label=\"baseline d\")\n",
    "plt.xlabel(\"d (1/h)\"); plt.ylabel(\"H* at equilibrium\")\n",
    "plt.legend(); plt.grid(True, ls=\":\", alpha=0.6)\n",
    "plt.tight_layout(); plt.savefig(f\"{OUTDIR}/bifurcation_H_vs_d.png\", dpi=180); plt.close()\n",
    "\n",
    "# Determine if baseline d is inside a bistable region\n",
    "near = df[np.isclose(df[\"d\"], pars[3], rtol=0.0, atol=1e-3)]\n",
    "coexisting = near[\"stable\"].sum() >= 2  # at least two stable eq from different seeds\n",
    "with open(f\"{OUTDIR}/diagnosis.txt\",\"w\") as f:\n",
    "    f.write(f\"Baseline d = {pars[3]:.4f}\\n\")\n",
    "    f.write(f\"Stable equilibria at baseline (count across seeds): {int(near['stable'].sum())}\\n\")\n",
    "    f.write(f\"Bistable at baseline? {'YES' if coexisting else 'NO'}\\n\")\n",
    "\n",
    "print(\"Saved:\", OUTDIR, \"| Bistable at baseline? \", \"YES\" if coexisting else \"NO\")\n",
    "\n",
    "# Basin map at baseline (scan initial H and q)\n",
    "Hs = np.linspace(0.2, 0.95, 16)\n",
    "qs = np.linspace(0.0, 1.0, 16)\n",
    "Z = np.zeros((len(Hs), len(qs)))\n",
    "def simulate(y0, T=300):\n",
    "    sol = solve_ivp(lambda t,y: rhs(y, pars), (0,T), y0, t_eval=np.linspace(0,T,800),\n",
    "                    rtol=1e-6, atol=1e-8, max_step=0.5)\n",
    "    return sol.y[:,-1]\n",
    "for i,H0 in enumerate(Hs):\n",
    "    for j,q0 in enumerate(qs):\n",
    "        y0 = np.array([0.2, H0, 0.1, q0])\n",
    "        yss = simulate(y0)\n",
    "        Z[i,j] = yss[1]  # final H\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(Z, origin=\"lower\", extent=[qs[0], qs[-1], Hs[0], Hs[-1]], aspect=\"auto\")\n",
    "plt.colorbar(label=\"Final H (steady)\")\n",
    "plt.xlabel(\"initial q\"); plt.ylabel(\"initial H\")\n",
    "plt.title(f\"Basins at baseline d={pars[3]:.3f}\")\n",
    "plt.tight_layout(); plt.savefig(f\"{OUTDIR}/basins_heatmap.png\", dpi=180); plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cf6ff3-bd12-406d-9d5d-9af2522ae5a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benpyenv",
   "language": "python",
   "name": "benpyenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
