{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5341c1b0-aa5a-440f-a3a4-35caa048a73a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully loaded parameters from mw_fit_out_guild_hard_targets/fitted_global_params.csv\n",
      "   Baseline inflammation rate 'd' = 0.06000\n",
      "--- üöÄ Starting Full Analysis ---\n",
      "Results will be saved to: full_analysis_results\n",
      "\n",
      "--- Step 1: Analyzing Basins of Attraction ---\n",
      "  Running basin analysis...\n",
      "  ‚úÖ Saved basin heatmap plot to full_analysis_results/basins_heatmap.png\n",
      "  ‚úÖ Saved basin data to full_analysis_results/basins_heatmap_data.csv\n",
      "\n",
      "\n",
      "--- Step 2: Simulating Interventions ---\n",
      "  Running intervention simulations...\n",
      "  - Starting from dysbiotic state (H = 0.096)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4068600/894330634.py:36: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0 / (1.0 + np.exp(-KQ * (H - th)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úÖ Saved intervention plots to full_analysis_results/intervention_simulations.png\n",
      "  ‚úÖ Saved intervention data to full_analysis_results/intervention_simulations_data.csv\n",
      "\n",
      "\n",
      "--- Step 3: Performing Sensitivity Analysis ---\n",
      "  Running sensitivity analysis...\n",
      "  - Testing c increased by 19%\n",
      "  - Running baseline bifurcation...\n",
      "  - Running bifurcation for high 'c'...\n",
      "  ‚úÖ Saved sensitivity plot to full_analysis_results/sensitivity_analysis.png\n",
      "  ‚úÖ Saved baseline branch data to full_analysis_results/sensitivity_baseline_branches.csv\n",
      "  ‚úÖ Saved modified branch data to full_analysis_results/sensitivity_modified_branches.csv\n",
      "\n",
      "\n",
      "--- üéâ All analyses complete! ---\n",
      "The following CSV files have been generated:\n",
      "  - full_analysis_results/basins_heatmap_data.csv\n",
      "  - full_analysis_results/intervention_simulations_data.csv\n",
      "  - full_analysis_results/sensitivity_baseline_branches.csv\n",
      "  - full_analysis_results/sensitivity_modified_branches.csv\n",
      "\n",
      "You can now upload these files for interpretation.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import root\n",
    "import numpy.linalg as npl\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "FIT_PARAMS_FILE = \"mw_fit_out_guild_hard_targets/fitted_global_params.csv\"\n",
    "OUTPUT_DIR = \"full_analysis_results\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "N_HILL = 3\n",
    "KQ = 80\n",
    "\n",
    "# --- 2. LOAD FITTED PARAMETERS ---\n",
    "try:\n",
    "    g = pd.read_csv(FIT_PARAMS_FILE, index_col=0, header=None).squeeze(\"columns\")\n",
    "    print(f\"‚úÖ Successfully loaded parameters from {FIT_PARAMS_FILE}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Error: Parameter file not found at {FIT_PARAMS_FILE}\")\n",
    "    print(\"Please make sure you have run your fitting script (3.txt) first.\")\n",
    "    exit()\n",
    "\n",
    "PARAM_NAMES = list(g.index.values)\n",
    "p_fit = np.array([float(g[k]) for k in PARAM_NAMES], float)\n",
    "d_fit = float(p_fit[6]) # Baseline 'd'\n",
    "\n",
    "print(f\"   Baseline inflammation rate 'd' = {d_fit:.5f}\")\n",
    "\n",
    "# --- 3. MODEL & NUMERICAL DEFINITIONS (from 4.txt) ---\n",
    "\n",
    "def q_inf(H, q, H_on, H_off):\n",
    "    th = (1 - q) * H_on + q * H_off\n",
    "    return 1.0 / (1.0 + np.exp(-KQ * (H - th)))\n",
    "\n",
    "def rhs(y, pvec, d_override=None):\n",
    "    P, C, H, B, q = y\n",
    "    r0P, rHP, r0C, K_M, gamma, c, d, gH, u, K_u, pL, pH, H_on, H_off, tau, K_B = pvec\n",
    "    \n",
    "    if d_override is not None:\n",
    "        d = d_override\n",
    "        \n",
    "    pB = pL + (pH - pL) * np.clip(q, 0, 1)\n",
    "    \n",
    "    dP = P * (r0P + rHP * H - c * pB - (P + gamma * C) / K_M)\n",
    "    dC = C * (r0C - (C + gamma * P) / K_M)\n",
    "    \n",
    "    uptake = u * H * B / (K_u + B + 1e-9)\n",
    "    dB = pB * P - uptake\n",
    "    dH = gH * (B**N_HILL / (K_B**N_HILL + B**N_HILL)) * (1 - H) - d * H\n",
    "    \n",
    "    dq = (q_inf(H, q, H_on, H_off) - q) / tau\n",
    "    \n",
    "    return np.array([dP, dC, dH, dB, dq], float)\n",
    "\n",
    "def jac_fd(fun, y, args, eps=1e-7):\n",
    "    f0 = fun(y, *args)\n",
    "    J = np.zeros((5, 5))\n",
    "    for i in range(5):\n",
    "        y2 = y.copy()\n",
    "        y2[i] += eps\n",
    "        J[:, i] = (fun(y2, *args) - f0) / eps\n",
    "    return J\n",
    "\n",
    "def find_eq(pvec, dval, guess):\n",
    "    sol = root(lambda yy: rhs(yy, pvec, dval), guess, method=\"hybr\")\n",
    "    if not sol.success:\n",
    "        return None, False\n",
    "    y = sol.x\n",
    "    y = np.array([max(0, y[0]), max(0, y[1]),\n",
    "                np.clip(y[2], 0, 1.2), max(0, y[3]), np.clip(y[4], 0, 1.2)], float)\n",
    "    if not np.all(np.isfinite(y)):\n",
    "        return None, False\n",
    "    return y, True\n",
    "\n",
    "# ---\n",
    "# STEP 1: ANALYZE BASINS OF ATTRACTION\n",
    "# ---\n",
    "def analyze_basins(pvec, d_baseline, output_dir):\n",
    "    \"\"\"\n",
    "    Generates a heatmap and CSV of the basins of attraction.\n",
    "    \"\"\"\n",
    "    print(\"  Running basin analysis...\")\n",
    "    \n",
    "    def relax(y0, T=360):\n",
    "        sol = solve_ivp(lambda t, z: rhs(z, pvec, d_baseline), (0, T), y0,\n",
    "                        t_eval=np.linspace(0, T, 2),\n",
    "                        rtol=1e-6, atol=1e-8, max_step=0.5)\n",
    "        return sol.y[:, -1]\n",
    "\n",
    "    Hs = np.linspace(0.20, 0.95, 25)\n",
    "    qs = np.linspace(0.0, 1.0, 25)\n",
    "    Z = np.zeros((len(Hs), len(qs)))\n",
    "    \n",
    "    for i, H0 in enumerate(Hs):\n",
    "        for j, q0 in enumerate(qs):\n",
    "            y0 = np.array([0.12, 0.12, H0, 0.10, q0], float)\n",
    "            yss = relax(y0)\n",
    "            Z[i, j] = yss[2] # Store final Host Health (H)\n",
    "\n",
    "    # --- CSV Export ---\n",
    "    basin_df = pd.DataFrame(Z, index=Hs, columns=qs)\n",
    "    basin_df.index.name = 'Initial_H'\n",
    "    basin_df.columns.name = 'Initial_q'\n",
    "    basin_csv_file = os.path.join(output_dir, \"basins_heatmap_data.csv\")\n",
    "    basin_df.to_csv(basin_csv_file)\n",
    "    # ---\n",
    "\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.imshow(Z, origin=\"lower\", extent=[qs[0], qs[-1], Hs[0], Hs[-1]],\n",
    "               aspect=\"auto\", vmin=0, vmax=1.0, cmap=\"viridis\")\n",
    "    plt.colorbar(label=\"Final Host Health ($H$)\")\n",
    "    plt.xlabel(\"Initial Memory ($q_0$)\")\n",
    "    plt.ylabel(\"Initial Host Health ($H_0$)\")\n",
    "    plt.title(f\"Basins of Attraction at Baseline d={d_baseline:.3f}\")\n",
    "    \n",
    "    plot_file = os.path.join(output_dir, \"basins_heatmap.png\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plot_file, dpi=180)\n",
    "    plt.close()\n",
    "    print(f\"  ‚úÖ Saved basin heatmap plot to {plot_file}\")\n",
    "    print(f\"  ‚úÖ Saved basin data to {basin_csv_file}\")\n",
    "\n",
    "# ---\n",
    "# STEP 2: SIMULATE INTERVENTIONS\n",
    "# ---\n",
    "def simulate_interventions(pvec, d_baseline, output_dir):\n",
    "    \"\"\"\n",
    "    Simulates \"treatment\" scenarios and saves time-series data to CSV.\n",
    "    \"\"\"\n",
    "    print(\"  Running intervention simulations...\")\n",
    "    \n",
    "    guess_dysbiotic = np.array([0.1, 0.1, 0.3, 0.1, 1.0])\n",
    "    y_dysbiotic, ok = find_eq(pvec, d_baseline, guess_dysbiotic)\n",
    "    if not ok:\n",
    "        print(\"  ‚ùå Could not find dysbiotic state. Skipping interventions.\")\n",
    "        return\n",
    "    print(f\"  - Starting from dysbiotic state (H = {y_dysbiotic[2]:.3f})\")\n",
    "\n",
    "    # Common time grid for all simulations\n",
    "    T_total = 100.0\n",
    "    t_intervene_start = 20.0\n",
    "    t_intervene_end = 30.0\n",
    "    t_span = (0, T_total)\n",
    "    t_eval = np.linspace(0, T_total, 200)\n",
    "\n",
    "    # --- Intervention 1: Anti-inflammatory (lower 'd') ---\n",
    "    d_treatment = d_baseline / 3.0\n",
    "    def rhs_anti_inflam(t, y):\n",
    "        d_val = d_treatment if t_intervene_start <= t < t_intervene_end else d_baseline\n",
    "        return rhs(y, pvec, d_override=d_val)\n",
    "        \n",
    "    sol_inflam = solve_ivp(rhs_anti_inflam, t_span, y_dysbiotic, t_eval=t_eval)\n",
    "    H_inflam = sol_inflam.y[2]\n",
    "\n",
    "    # --- Intervention 2: Probiotic (Dose of Producer P) ---\n",
    "    PROBIOTIC_DOSE = 0.8\n",
    "    sol_pre_P = solve_ivp(lambda t,y: rhs(y, pvec, d_baseline), (0, t_intervene_start), y_dysbiotic)\n",
    "    y_dose_P = sol_pre_P.y[:, -1].copy()\n",
    "    y_dose_P[0] += PROBIOTIC_DOSE\n",
    "    sol_post_P = solve_ivp(lambda t,y: rhs(y, pvec, d_baseline), (t_intervene_start, T_total), y_dose_P)\n",
    "    \n",
    "    t_full_P = np.concatenate((sol_pre_P.t, sol_post_P.t))\n",
    "    H_full_P = np.concatenate((sol_pre_P.y[2], sol_post_P.y[2]))\n",
    "    H_probiotic = np.interp(t_eval, t_full_P, H_full_P) # Interpolate onto common grid\n",
    "\n",
    "    # --- Intervention 3: Postbiotic (Dose of Butyrate B) ---\n",
    "    POSTBIOTIC_DOSE = 0.5\n",
    "    y_dose_B = sol_pre_P.y[:, -1].copy() # Can re-use the 'pre' simulation\n",
    "    y_dose_B[3] += POSTBIOTIC_DOSE\n",
    "    sol_post_B = solve_ivp(lambda t,y: rhs(y, pvec, d_baseline), (t_intervene_start, T_total), y_dose_B)\n",
    "    \n",
    "    t_full_B = np.concatenate((sol_pre_P.t, sol_post_B.t))\n",
    "    H_full_B = np.concatenate((sol_pre_P.y[2], sol_post_B.y[2]))\n",
    "    H_postbiotic = np.interp(t_eval, t_full_B, H_full_B) # Interpolate onto common grid\n",
    "\n",
    "    # --- CSV Export ---\n",
    "    intervention_df = pd.DataFrame({\n",
    "        'time': t_eval,\n",
    "        'H_anti_inflammatory': H_inflam,\n",
    "        'H_probiotic_dose': H_probiotic,\n",
    "        'H_postbiotic_dose': H_postbiotic\n",
    "    })\n",
    "    intervention_csv_file = os.path.join(output_dir, \"intervention_simulations_data.csv\")\n",
    "    intervention_df.to_csv(intervention_csv_file, index=False)\n",
    "    # ---\n",
    "\n",
    "    # --- Plotting ---\n",
    "    fig, ax = plt.subplots(3, 1, figsize=(10, 12), sharex=True)\n",
    "    \n",
    "    ax[0].plot(t_eval, H_inflam, lw=2, label=\"Host Health (H)\") # Use t_eval, H_inflam\n",
    "    ax[0].axvspan(t_intervene_start, t_intervene_end, color='red', alpha=0.2, label=f\"Lower d (to {d_treatment:.3f})\")\n",
    "    ax[0].set_title(\"Intervention 1: Anti-inflammatory\")\n",
    "    ax[0].set_ylabel(\"Host Health ($H$)\")\n",
    "    ax[0].legend(); ax[0].grid(True, ls=\":\")\n",
    "\n",
    "    ax[1].plot(t_eval, H_probiotic, lw=2, label=\"Host Health (H)\") # Use t_eval, H_probiotic\n",
    "    ax[1].axvline(t_intervene_start, color='blue', alpha=0.5, ls='--', label=f\"Probiotic Dose (P += {PROBIOTIC_DOSE})\")\n",
    "    ax[1].set_title(\"Intervention 2: Probiotic Dose (Producer)\")\n",
    "    ax[1].set_ylabel(\"Host Health ($H$)\")\n",
    "    ax[1].legend(); ax[1].grid(True, ls=\":\")\n",
    "    \n",
    "    ax[2].plot(t_eval, H_postbiotic, lw=2, label=\"Host Health (H)\") # Use t_eval, H_postbiotic\n",
    "    ax[2].axvline(t_intervene_start, color='green', alpha=0.5, ls='--', label=f\"Postbiotic Dose (B += {POSTBIOTIC_DOSE})\")\n",
    "    ax[2].set_title(\"Intervention 3: Postbiotic Dose (Butyrate)\")\n",
    "    ax[2].set_ylabel(\"Host Health ($H$)\"); ax[2].set_xlabel(\"Time\")\n",
    "    ax[2].legend(); ax[2].grid(True, ls=\":\")\n",
    "\n",
    "    plot_file = os.path.join(output_dir, \"intervention_simulations.png\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plot_file, dpi=180)\n",
    "    plt.close()\n",
    "    print(f\"  ‚úÖ Saved intervention plots to {plot_file}\")\n",
    "    print(f\"  ‚úÖ Saved intervention data to {intervention_csv_file}\")\n",
    "\n",
    "# ---\n",
    "# STEP 3: PERFORM SENSITIVITY ANALYSIS\n",
    "# ---\n",
    "def run_bifurcation(p_vec_to_run, d_range, seeds):\n",
    "    \"\"\"Helper function to run the core bifurcation analysis.\"\"\"\n",
    "    rows = []\n",
    "    for d in d_range:\n",
    "        for wi, y0 in enumerate(seeds):\n",
    "            y, ok = find_eq(p_vec_to_run, d, y0)\n",
    "            if not ok: continue\n",
    "            lam_max = np.max(np.real(npl.eigvals(jac_fd(rhs, y, (p_vec_to_run, d)))))\n",
    "            rows.append({\"d\": d, \"H\": float(y[2]), \"stable\": (lam_max < 0)})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def analyze_sensitivity(pvec, d_baseline, output_dir):\n",
    "    \"\"\"\n",
    "    Compares and saves S-curves for baseline vs. modified parameters.\n",
    "    \"\"\"\n",
    "    print(\"  Running sensitivity analysis...\")\n",
    "    \n",
    "    param_to_change_idx = 5 # 'c' (cost of production)\n",
    "    param_name = PARAM_NAMES[param_to_change_idx]\n",
    "    change_factor = 1.20 \n",
    "    \n",
    "    p_modified = pvec.copy()\n",
    "    p_modified[param_to_change_idx] *= change_factor\n",
    "    print(f\"  - Testing {param_name} increased by {int((change_factor-1)*100)}%\")\n",
    "\n",
    "    d_range = np.linspace(0.7 * d_baseline, 1.6 * d_baseline, 140)\n",
    "    seeds = [\n",
    "        np.array([0.12, 0.12, 0.30, 0.10, 1.0]),\n",
    "        np.array([0.05, 0.20, 0.90, 0.12, 0.0]),\n",
    "        np.array([0.30, 0.08, 0.55, 0.10, 0.6]),\n",
    "        np.array([0.15, 0.15, 0.65, 0.12, 0.4]),\n",
    "    ]\n",
    "    \n",
    "    # Run 1: Baseline\n",
    "    print(\"  - Running baseline bifurcation...\")\n",
    "    branches_base = run_bifurcation(pvec, d_range, seeds)\n",
    "    \n",
    "    # Run 2: Modified Parameter\n",
    "    print(f\"  - Running bifurcation for high '{param_name}'...\")\n",
    "    branches_mod = run_bifurcation(p_modified, d_range, seeds)\n",
    "\n",
    "    # --- CSV Export ---\n",
    "    base_csv_file = os.path.join(output_dir, \"sensitivity_baseline_branches.csv\")\n",
    "    branches_base.to_csv(base_csv_file, index=False)\n",
    "    \n",
    "    mod_csv_file = os.path.join(output_dir, \"sensitivity_modified_branches.csv\")\n",
    "    branches_mod.to_csv(mod_csv_file, index=False)\n",
    "    # ---\n",
    "\n",
    "    # --- Plotting ---\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(branches_base.loc[branches_base['stable'], 'd'],\n",
    "             branches_base.loc[branches_base['stable'], 'H'],\n",
    "             'b-', label=\"Baseline (Stable)\")\n",
    "    plt.plot(branches_base.loc[~branches_base['stable'], 'd'],\n",
    "             branches_base.loc[~branches_base['stable'], 'H'],\n",
    "             'b:', label=\"Baseline (Unstable)\")\n",
    "    plt.plot(branches_mod.loc[branches_mod['stable'], 'd'],\n",
    "             branches_mod.loc[branches_mod['stable'], 'H'],\n",
    "             'r-', label=f\"High '{param_name}' (Stable)\")\n",
    "    plt.plot(branches_mod.loc[~branches_mod['stable'], 'd'],\n",
    "             branches_mod.loc[~branches_mod['stable'], 'H'],\n",
    "             'r:', label=f\"High '{param_name}' (Unstable)\")\n",
    "    plt.axvline(d_baseline, ls=\"--\", c=\"gray\", label=f\"Baseline d = {d_baseline:.4f}\")\n",
    "    plt.xlabel(\"Inflammation Rate ($d$)\", fontsize=12)\n",
    "    plt.ylabel(\"Host Health ($H$)\", fontsize=12)\n",
    "    plt.title(f\"Sensitivity Analysis: Impact of {change_factor:.0%} increase in '{param_name}'\")\n",
    "    plt.legend(); plt.grid(True, ls=\":\", alpha=0.7)\n",
    "    \n",
    "    plot_file = os.path.join(output_dir, \"sensitivity_analysis.png\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plot_file, dpi=180)\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"  ‚úÖ Saved sensitivity plot to {plot_file}\")\n",
    "    print(f\"  ‚úÖ Saved baseline branch data to {base_csv_file}\")\n",
    "    print(f\"  ‚úÖ Saved modified branch data to {mod_csv_file}\")\n",
    "\n",
    "# ---\n",
    "# MAIN EXECUTION\n",
    "# ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"--- üöÄ Starting Full Analysis ---\")\n",
    "    print(f\"Results will be saved to: {OUTPUT_DIR}\\n\")\n",
    "    \n",
    "    # Step 1\n",
    "    print(\"--- Step 1: Analyzing Basins of Attraction ---\")\n",
    "    analyze_basins(p_fit, d_fit, OUTPUT_DIR)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Step 2\n",
    "    print(\"--- Step 2: Simulating Interventions ---\")\n",
    "    simulate_interventions(p_fit, d_fit, OUTPUT_DIR)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Step 3\n",
    "    print(\"--- Step 3: Performing Sensitivity Analysis ---\")\n",
    "    analyze_sensitivity(p_fit, d_fit, OUTPUT_DIR)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"--- üéâ All analyses complete! ---\")\n",
    "    print(\"The following CSV files have been generated:\")\n",
    "    print(f\"  - {OUTPUT_DIR}/basins_heatmap_data.csv\")\n",
    "    print(f\"  - {OUTPUT_DIR}/intervention_simulations_data.csv\")\n",
    "    print(f\"  - {OUTPUT_DIR}/sensitivity_baseline_branches.csv\")\n",
    "    print(f\"  - {OUTPUT_DIR}/sensitivity_modified_branches.csv\")\n",
    "    print(\"\\nYou can now upload these files for interpretation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f63bc8-e812-4e1c-ae9c-cc7b9531258e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5935b2cd-d801-4f18-ad2f-c1548587214a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üöÄ Starting 'Fit-with-Bistability-Check' (v4) ---\n",
      "Loaded 70 subjects for fitting.\n",
      "--- Starting new fit (v4)... ---\n",
      "This will be slower, as it checks for bistability on each step.\n",
      "   Iteration     Total nfev        Cost      Cost reduction    Step norm     Optimality   \n",
      "       0              1         1.0260e+04                                    2.59e+01    \n",
      "       1              2         1.0227e+04      3.23e+01       2.85e+00       9.63e+00    \n",
      "       2              3         1.0211e+04      1.64e+01       1.17e+00       4.98e+01    \n",
      "       3              4         1.0209e+04      2.31e+00       1.64e+00       1.34e+00    \n",
      "       4              5         1.0208e+04      2.46e-01       1.81e-01       1.68e+00    \n",
      "       5              6         1.0207e+04      7.95e-01       1.09e+00       2.32e+00    \n",
      "       6              7         1.0207e+04      3.39e-01       3.57e-01       5.11e-01    \n",
      "       7              8         1.0207e+04      1.87e-01       2.89e-01       1.07e+01    \n",
      "       8             19         1.0207e+04      0.00e+00       0.00e+00       1.07e+01    \n",
      "`xtol` termination condition is satisfied.\n",
      "Function evaluations 19, initial cost 1.0260e+04, final cost 1.0207e+04, first-order optimality 1.07e+01.\n",
      "--- Fit complete. ---\n",
      "[info] new globals (v4): {'r0P': 0.3383709314677053, 'rHP': 0.07218617127623346, 'r0C': 0.27591724957003205, 'K_M': 1.0300996025336098, 'gamma': 0.8311512765636534, 'c': 0.10908905340925838, 'd': 0.07539030116976769, 'g': 1.0267746309610677, 'u': 1.1772525815642552, 'K_u': 0.1784678479979458, 'p_low': 0.10955378848859582, 'p_high': 2.7839767799808555, 'H_on': 0.6081009986795995, 'H_off': 0.8600000000000002, 'tau_q': 4.631976567229618, 'K_B': 0.1892324139697427}\n",
      "‚úÖ Saved new parameters to: mw_fit_out_v4_BISTABLE/fitted_global_params_v4.csv\n",
      "\n",
      "==============================\n",
      "\n",
      "--- PART 2: Validating new parameters ---\n",
      "‚ùå FAILURE: The fitter could not find a bistable solution.\n",
      "This indicates a deeper problem, possibly with the model structure or data.\n",
      "\n",
      "--- üéâ 'Fit-and-Test' v4 complete! ---\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "# ---\n",
    "# === PART 1: FITTING SCRIPT (v4) ===\n",
    "# ---\n",
    "print(\"--- üöÄ Starting 'Fit-with-Bistability-Check' (v4) ---\")\n",
    "\n",
    "INPATH = \"timeseries/combined_scfas_table_scored.csv\"\n",
    "OUTDIR = \"mw_fit_out_v4_BISTABLE\" # New output directory\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "NEW_PARAMS_FILE = os.path.join(OUTDIR, \"fitted_global_params_v4.csv\")\n",
    "\n",
    "H_COLS = [\"H_proxy_meta_smooth\", \"H_proxy_meta\"]\n",
    "SCFA = [\"butyrate\"]\n",
    "MIN_ROWS = 4\n",
    "HILL_N = 3 # Use N=3\n",
    "PENALTY = 1e3\n",
    "BISTABILITY_PENALTY = 1e4 # A new, massive penalty\n",
    "\n",
    "# Baseline priors (Our main guide)\n",
    "# Widen the priors for 'g' and 'p_high' to let the fitter search\n",
    "PRIOR = {\"r0P\":(0.32,0.08),\"rHP\":(0.07,0.04),\"r0C\":(0.28,0.08),\"K_M\":(1.0,0.25),\n",
    "       \"gamma\":(0.85,0.25),\"c\":(0.12,0.05),\"d\":(0.12,0.05),\n",
    "       \"g\":(0.80, 0.40), # Centered near our scan, but wider\n",
    "       \"u\":(0.60,0.15),\"K_u\":(0.20,0.08),\"p_low\":(0.12,0.06),\n",
    "       \"p_high\":(2.7, 0.60), # Centered near our scan, but wider\n",
    "       \"H_on\":(0.60,0.08),\"H_off\":(0.86,0.04),\"tau_q\":(5.0,2.0),\"K_B\":(0.20,0.08)}\n",
    "\n",
    "# General, wide bounds\n",
    "LBg = np.array([0.18, 0.00, 0.15, 0.55, 0.5,  0.06, 0.06, 0.20, 0.2, 0.05, 0.06, 1.0, 0.50, 0.80, 1.0, 0.10])\n",
    "UBg = np.array([0.46, 0.14, 0.40, 1.60, 1.5,  0.20, 0.22, 1.40, 1.2, 0.5,  0.28, 4.0, 0.74, 0.92, 10., 0.40])\n",
    "\n",
    "# Initial guess (x0) based on the center of the PRIORS\n",
    "x0g = np.array([\n",
    "    PRIOR[\"r0P\"][0], PRIOR[\"rHP\"][0], PRIOR[\"r0C\"][0], PRIOR[\"K_M\"][0],\n",
    "    PRIOR[\"gamma\"][0], PRIOR[\"c\"][0], PRIOR[\"d\"][0], PRIOR[\"g\"][0],\n",
    "    PRIOR[\"u\"][0], PRIOR[\"K_u\"][0], PRIOR[\"p_low\"][0], PRIOR[\"p_high\"][0],\n",
    "    PRIOR[\"H_on\"][0], PRIOR[\"H_off\"][0], PRIOR[\"tau_q\"][0], PRIOR[\"K_B\"][0]\n",
    "], float)\n",
    "\n",
    "\n",
    "# --- Data Prep (unchanged) ---\n",
    "df = pd.read_csv(INPATH)\n",
    "Hcol = next((c for c in H_COLS if c in df.columns), None)\n",
    "if Hcol is None: raise ValueError(\"Need H proxy col\")\n",
    "df = df[[\"subject_id\", \"sample_id\", Hcol] + SCFA].dropna(subset=[\"subject_id\", \"sample_id\"]).copy()\n",
    "df[\"t_idx\"] = df.groupby(\"subject_id\").cumcount().astype(float)\n",
    "\n",
    "def robust_z(s):\n",
    "    x = s.astype(float).to_numpy(); m = np.isfinite(x)\n",
    "    if m.sum() == 0: return pd.Series(np.zeros_like(x), index=s.index)\n",
    "    xm = x[m]; med = np.median(xm); mad = np.median(np.abs(xm - med))\n",
    "    scale = mad if mad > 1e-9 else (np.percentile(xm, 75) - np.percentile(xm, 25) or np.std(xm) + 1e-9)\n",
    "    return pd.Series((x - med) / (scale + 1e-9), index=s.index)\n",
    "\n",
    "df[\"B_z\"] = df.groupby(\"subject_id\")[SCFA[0]].transform(robust_z)\n",
    "df[\"H_obs\"] = df[Hcol].clip(0, 1)\n",
    "\n",
    "subs = []\n",
    "for sid, sub in df.groupby(\"subject_id\"):\n",
    "    sub = sub.sort_values(\"t_idx\")\n",
    "    if len(sub) < MIN_ROWS: continue\n",
    "    t = sub[\"t_idx\"].to_numpy(float)\n",
    "    B = sub[\"B_z\"].to_numpy(float); H = sub[\"H_obs\"].to_numpy(float)\n",
    "    mB = np.isfinite(B); mH = np.isfinite(H)\n",
    "    if mB.sum() < 3 or mH.sum() < 3: continue\n",
    "    def first(a, d):\n",
    "        a = np.asarray(a, float); idx = np.where(np.isfinite(a))[0]\n",
    "        return float(a[idx[0]]) if len(idx) else float(d)\n",
    "    subs.append({\"sid\": sid, \"t\": t, \"B\": B, \"H\": H, \"maskB\": mB, \"maskH\": mH,\n",
    "                 \"nB\": int(mB.sum()), \"nH\": int(mH.sum()),\n",
    "                 \"H0\": float(np.clip(first(H, 0.6), 0, 1)),\n",
    "                 \"B0\": float(max(0.05, first(B, 0.1)))})\n",
    "if not subs: raise RuntimeError(\"no subjects\")\n",
    "print(f\"Loaded {len(subs)} subjects for fitting.\")\n",
    "\n",
    "\n",
    "# --- Model (RHS for fitting - SIMPLE HOLD logic) ---\n",
    "# We use the robust 'simple hold' logic for memory\n",
    "def rhs_simple_hold(t, y, p):\n",
    "    P, C, H, B, q = y\n",
    "    r0P, rHP, r0C, K_M, gamma, c, d, gH, u, K_u, pL, pH, H_on, H_off, tau, K_B = p\n",
    "    \n",
    "    pB = pL + (pH - pL) * np.clip(q, 0, 1)\n",
    "    \n",
    "    # Ecology\n",
    "    dP = P * (r0P + rHP * H - c * pB - (P + gamma * C) / K_M)\n",
    "    dC = C * (r0C - (C + gamma * P) / K_M)\n",
    "    \n",
    "    # Butyrate & Host (Using HILL_N=3)\n",
    "    uptake = u * H * B / (K_u + B + 1e-9)\n",
    "    dB = pB * P - uptake\n",
    "    dH = gH * (B**HILL_N / (K_B**HILL_N + B**HILL_N)) * (1 - H) - d * H\n",
    "    \n",
    "    # --- Simplified Memory Rule ---\n",
    "    if H < H_on:\n",
    "        q_inf_target = 1.0\n",
    "    elif H > H_off:\n",
    "        q_inf_target = 0.0\n",
    "    else:\n",
    "        q_inf_target = q # \"Hold\"\n",
    "    \n",
    "    dq = (q_inf_target - q) / tau\n",
    "    return [dP, dC, dH, dB, dq]\n",
    "\n",
    "def simulate(ts, y0, p):\n",
    "    try:\n",
    "        sol = solve_ivp(lambda t, z: rhs_simple_hold(t, z, p), (ts[0], ts[-1]), y0, t_eval=ts,\n",
    "                      rtol=1e-6, atol=1e-8, max_step=0.5)\n",
    "        if not sol.success: return np.vstack([np.full(len(ts), np.nan)] * 5)\n",
    "        return sol.y\n",
    "    except Exception:\n",
    "        return np.vstack([np.full(len(ts), np.nan)] * 5)\n",
    "\n",
    "# per-subject obs maps\n",
    "x0s = []; LBs = []; UBs = []\n",
    "for _ in subs: x0s += [1.0, 0.0, 1.0]; LBs += [0.6, -0.2, 0.8]; UBs += [1.6, 0.2, 1.2]\n",
    "x0 = np.concatenate([x0g, np.array(x0s, float)])\n",
    "LB = np.concatenate([LBg, np.array(LBs, float)])\n",
    "UB = np.concatenate([UBg, np.array(UBs, float)])\n",
    "\n",
    "NAMES = [\"r0P\", \"rHP\", \"r0C\", \"K_M\", \"gamma\", \"c\", \"d\", \"g\", \"u\", \"K_u\", \"p_low\", \"p_high\", \"H_on\", \"H_off\", \"tau_q\", \"K_B\"]\n",
    "def unpack(x):\n",
    "    gpar = x[:len(NAMES)]\n",
    "    triples = np.split(x[len(NAMES):], len(subs))\n",
    "    return gpar, triples\n",
    "\n",
    "W_B, W_H = 0.6, 1.2\n",
    "\n",
    "# ---\n",
    "# === NEW BISTABILITY CHECKER ===\n",
    "# ---\n",
    "def check_bistability(pvec):\n",
    "    \"\"\"\n",
    "    Directly simulates two points to check for bistability.\n",
    "    Returns True if bistable, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get baseline 'd' from the parameter vector\n",
    "        d_baseline = pvec[NAMES.index('d')]\n",
    "        \n",
    "        # --- Simulate \"Healthy\" Start ---\n",
    "        # Start: High H (0.9), Low q (0.0)\n",
    "        y0_healthy = np.array([0.1, 0.1, 0.9, 0.1, 0.0], float)\n",
    "        sol_h = solve_ivp(lambda t, z: rhs_simple_hold(t, z, pvec), (0, 360), y0_healthy,\n",
    "                          t_eval=[360], rtol=1e-6, atol=1e-8)\n",
    "        H_final_healthy = sol_h.y[2, -1] if sol_h.success else -99\n",
    "\n",
    "        # --- Simulate \"Sick\" Start ---\n",
    "        # Start: Low H (0.2), High q (1.0)\n",
    "        y0_sick = np.array([0.1, 0.1, 0.2, 0.1, 1.0], float)\n",
    "        sol_s = solve_ivp(lambda t, z: rhs_simple_hold(t, z, pvec), (0, 360), y0_sick,\n",
    "                          t_eval=[360], rtol=1e-6, atol=1e-8)\n",
    "        H_final_sick = sol_s.y[2, -1] if sol_s.success else -99\n",
    "        \n",
    "        # --- Check for two distinct states ---\n",
    "        # Healthy state must be > 0.8\n",
    "        # Sick state must be < 0.5\n",
    "        # They must be clearly separate\n",
    "        if (H_final_healthy > 0.8) and (H_final_sick < 0.5) and ((H_final_healthy - H_final_sick) > 0.3):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "            \n",
    "    except Exception:\n",
    "        # If simulation fails for any reason, it's not a good parameter set\n",
    "        return False\n",
    "\n",
    "# ---\n",
    "# === NEW RESIDUALS FUNCTION ===\n",
    "# ---\n",
    "def residuals(x):\n",
    "    gpar, triples = unpack(x)\n",
    "    \n",
    "    # Basic parameter checks\n",
    "    if not (gpar[NAMES.index('H_off')] > gpar[NAMES.index('H_on')]): \n",
    "        return np.ones(100) * PENALTY\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    # --- 1. Data-fitting cost (same as before) ---\n",
    "    for S, tr in zip(subs, triples):\n",
    "        aB, b0, b1 = tr\n",
    "        ts = S[\"t\"]; H0 = np.clip(S[\"H0\"], 0, 1); B0 = max(0.05, S[\"B0\"])\n",
    "        P0 = C0 = 0.12; q0 = 1.0 if H0 < gpar[NAMES.index('H_on')] else 0.0\n",
    "        y0 = [P0, C0, H0, B0, q0]\n",
    "        Y = simulate(ts, y0, gpar)\n",
    "        \n",
    "        if np.any(~np.isfinite(Y)):\n",
    "            res += [W_B * np.full(S[\"nB\"], PENALTY), W_H * np.full(S[\"nH\"], PENALTY)]\n",
    "            continue\n",
    "            \n",
    "        P, C, H, B, q = Y\n",
    "        Bh = aB * B; Hh = np.clip(b0 + b1 * H, 0, 1)\n",
    "        res += [W_B * (Bh[S[\"maskB\"]] - S[\"B\"][S[\"maskB\"]]),\n",
    "                W_H * (Hh[S[\"maskH\"]] - S[\"H\"][S[\"maskH\"]])]\n",
    "        \n",
    "    # --- 2. Prior cost (same as before) ---\n",
    "    idx = {nm: i for i, nm in enumerate(NAMES)}\n",
    "    for nm, (mu, sd) in PRIOR.items():\n",
    "        res.append(np.array([(gpar[idx[nm]] - mu) / (sd + 1e-9)]))\n",
    "    \n",
    "    # --- 3. NEW: Bistability Penalty ---\n",
    "    if not check_bistability(gpar):\n",
    "        # If the parameters are NOT bistable, add a huge penalty\n",
    "        res.append(np.array([BISTABILITY_PENALTY]))\n",
    "        \n",
    "    return np.concatenate(res)\n",
    "\n",
    "# ---\n",
    "# === RUN THE FIT ===\n",
    "# ---\n",
    "print(\"--- Starting new fit (v4)... ---\")\n",
    "print(\"This will be slower, as it checks for bistability on each step.\")\n",
    "fit = least_squares(residuals, x0, bounds=(LB, UB), verbose=2, \n",
    "                    max_nfev=2000, # Increased max steps\n",
    "                    loss=\"soft_l1\", f_scale=1.0)\n",
    "print(\"--- Fit complete. ---\")\n",
    "\n",
    "gpar_hat, _ = unpack(fit.x)\n",
    "pd.Series(gpar_hat, index=NAMES).to_csv(NEW_PARAMS_FILE, header=False)\n",
    "print(\"[info] new globals (v4):\", dict(zip(NAMES, gpar_hat)))\n",
    "print(f\"‚úÖ Saved new parameters to: {NEW_PARAMS_FILE}\")\n",
    "\n",
    "# ---\n",
    "# === PART 2: FINAL VALIDATION ===\n",
    "# ---\n",
    "print(\"\\n\" + \"=\"*30 + \"\\n\")\n",
    "print(f\"--- PART 2: Validating new parameters ---\")\n",
    "\n",
    "# Check the final parameters one last time\n",
    "final_params_are_bistable = check_bistability(gpar_hat)\n",
    "\n",
    "if final_params_are_bistable:\n",
    "    print(\"‚úÖ SUCCESS: The final fitted parameters are BISTABLE.\")\n",
    "    print(\"You can now use the corrected 4.txt script on this new parameter file.\")\n",
    "else:\n",
    "    print(\"‚ùå FAILURE: The fitter could not find a bistable solution.\")\n",
    "    print(\"This indicates a deeper problem, possibly with the model structure or data.\")\n",
    "\n",
    "print(f\"\\n--- üéâ 'Fit-and-Test' v4 complete! ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71835335-b9d9-4a06-b1cc-bb94c15c6073",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üöÄ Starting 'Global Simple Model Fit' (v6) ---\n",
      "--- This will be VERY SLOW. Please be patient. ---\n",
      "Loaded 70 subjects for fitting.\n",
      "--- Starting Global Fit (using 221 parameters)... ---\n",
      "This may take 30-60+ minutes. Start time: Mon Oct 20 23:32:06 2025\n",
      "differential_evolution step 1: f(x)= 1302.9393959503668\n",
      "differential_evolution step 2: f(x)= 1282.5413532692903\n",
      "differential_evolution step 3: f(x)= 1254.4060867207904\n",
      "differential_evolution step 4: f(x)= 1251.5384225864632\n",
      "differential_evolution step 5: f(x)= 1191.9077480414733\n",
      "differential_evolution step 6: f(x)= 1162.7302900343445\n",
      "differential_evolution step 7: f(x)= 1130.1318300123316\n",
      "differential_evolution step 8: f(x)= 1129.6418554687439\n",
      "differential_evolution step 9: f(x)= 1129.6418554687439\n",
      "differential_evolution step 10: f(x)= 1129.6418554687439\n",
      "differential_evolution step 11: f(x)= 1116.8478398210145\n",
      "differential_evolution step 12: f(x)= 1116.8478398210145\n",
      "differential_evolution step 13: f(x)= 1116.8478398210145\n",
      "differential_evolution step 14: f(x)= 1116.8478398210145\n",
      "differential_evolution step 15: f(x)= 1116.8478398210145\n",
      "differential_evolution step 16: f(x)= 1097.1238481835203\n",
      "differential_evolution step 17: f(x)= 1097.1238481835203\n",
      "differential_evolution step 18: f(x)= 1097.1238481835203\n",
      "differential_evolution step 19: f(x)= 1097.1238481835203\n",
      "differential_evolution step 20: f(x)= 1093.3995567457905\n",
      "differential_evolution step 21: f(x)= 1085.8126683214198\n",
      "differential_evolution step 22: f(x)= 1085.8126683214198\n",
      "differential_evolution step 23: f(x)= 1085.8126683214198\n",
      "differential_evolution step 24: f(x)= 1085.8126683214198\n",
      "differential_evolution step 25: f(x)= 1081.3863708384113\n",
      "differential_evolution step 26: f(x)= 1081.3863708384113\n",
      "differential_evolution step 27: f(x)= 1081.3863708384113\n",
      "differential_evolution step 28: f(x)= 1081.3863708384113\n",
      "differential_evolution step 29: f(x)= 1081.3863708384113\n",
      "differential_evolution step 30: f(x)= 1081.3863708384113\n",
      "differential_evolution step 31: f(x)= 1081.3863708384113\n",
      "differential_evolution step 32: f(x)= 1081.3863708384113\n",
      "differential_evolution step 33: f(x)= 1072.858466125285\n",
      "differential_evolution step 34: f(x)= 1072.858466125285\n",
      "differential_evolution step 35: f(x)= 1072.858466125285\n",
      "differential_evolution step 36: f(x)= 1055.7946510301997\n",
      "differential_evolution step 37: f(x)= 1055.4059773883675\n",
      "differential_evolution step 38: f(x)= 1055.4059773883675\n",
      "differential_evolution step 39: f(x)= 1055.4059773883675\n",
      "differential_evolution step 40: f(x)= 1055.4059773883675\n",
      "differential_evolution step 41: f(x)= 1055.4059773883675\n",
      "differential_evolution step 42: f(x)= 1055.4059773883675\n",
      "differential_evolution step 43: f(x)= 1052.490350892856\n",
      "differential_evolution step 44: f(x)= 1052.490350892856\n",
      "differential_evolution step 45: f(x)= 1052.490350892856\n",
      "differential_evolution step 46: f(x)= 1048.8339607302148\n",
      "differential_evolution step 47: f(x)= 1048.8339607302148\n",
      "differential_evolution step 48: f(x)= 1048.8339607302148\n",
      "differential_evolution step 49: f(x)= 1048.8339607302148\n",
      "differential_evolution step 50: f(x)= 1040.408280125582\n",
      "differential_evolution step 51: f(x)= 1040.408280125582\n",
      "differential_evolution step 52: f(x)= 1040.408280125582\n",
      "differential_evolution step 53: f(x)= 1040.408280125582\n",
      "differential_evolution step 54: f(x)= 1040.408280125582\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.optimize import differential_evolution # GLOBAL OPTIMIZER\n",
    "import time\n",
    "\n",
    "# ---\n",
    "# === PART 1: FITTING SCRIPT (v6 - SIMPLE MODEL + GLOBAL FIT) ===\n",
    "# ---\n",
    "print(\"--- üöÄ Starting 'Global Simple Model Fit' (v6) ---\")\n",
    "print(\"--- This will be VERY SLOW. Please be patient. ---\")\n",
    "\n",
    "INPATH = \"timeseries/combined_scfas_table_scored.csv\"\n",
    "OUTDIR = \"mw_fit_out_v6_SIMPLE_GLOBAL\" # New output directory\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "NEW_PARAMS_FILE = os.path.join(OUTDIR, \"fitted_global_params_v6.csv\")\n",
    "\n",
    "H_COLS = [\"H_proxy_meta_smooth\", \"H_proxy_meta\"]\n",
    "SCFA = [\"butyrate\"]\n",
    "MIN_ROWS = 4\n",
    "PENALTY = 1e3\n",
    "BISTABILITY_PENALTY = 1e4 # Massive penalty for non-bistable solutions\n",
    "\n",
    "# ---\n",
    "# === MODEL & PARAMETERS from your 1.txt SCRIPT ===\n",
    "# ---\n",
    "PARAM_NAMES = [\"r_max\",\"K_M\",\"c\",\"d\",\"g\",\"u\",\"p_low\",\"p_high\",\"H_on\",\"H_off\",\"tau_q\"]\n",
    "\n",
    "# Priors (wide, for global search)\n",
    "# We use the parameters from your 1.txt 'x0g' as the center of our priors\n",
    "PRIOR = {\n",
    "    \"r_max\": (0.32, 0.15), \"K_M\": (1.0, 0.3), \"c\": (0.10, 0.05),\n",
    "    \"d\": (0.12, 0.06), \"g\": (0.5, 0.2), \"u\": (0.6, 0.2),\n",
    "    \"p_low\": (0.1, 0.05), \"p_high\": (2.5, 0.8), \"H_on\": (0.55, 0.1),\n",
    "    \"H_off\": (0.70, 0.1), \"tau_q\": (4.0, 2.0)\n",
    "}\n",
    "\n",
    "# Bounds (LBg/UBg from 1.txt)\n",
    "LBg_simple = np.array([0.1, 0.4, 0.02, 0.01, 0.05, 0.2, 0.0, 0.5, 0.2, 0.3, 0.5])\n",
    "UBg_simple = np.array([0.6, 1.5, 0.25, 0.5 , 2.0 , 1.2, 0.8, 4.0, 0.8, 0.95, 24.0])\n",
    "\n",
    "# --- Data Prep (unchanged) ---\n",
    "df = pd.read_csv(INPATH)\n",
    "Hcol = next((c for c in H_COLS if c in df.columns), None)\n",
    "if Hcol is None: raise ValueError(\"Need H proxy col\")\n",
    "df = df[[\"subject_id\", \"sample_id\", Hcol] + SCFA].dropna(subset=[\"subject_id\", \"sample_id\"]).copy()\n",
    "df[\"t_idx\"] = df.groupby(\"subject_id\").cumcount().astype(float)\n",
    "\n",
    "def robust_z(s): # Renamed from robust_mad_scale\n",
    "    x = s.astype(float).to_numpy(); m = np.isfinite(x)\n",
    "    if m.sum() == 0: return pd.Series(np.zeros_like(x), index=s.index)\n",
    "    xm = x[m]; med = np.median(xm); mad = np.median(np.abs(xm - med))\n",
    "    scale = mad if mad > 1e-9 else (np.percentile(xm, 75) - np.percentile(xm, 25) or np.std(xm) + 1e-9)\n",
    "    return pd.Series((x - med) / (scale + 1e-9), index=s.index)\n",
    "\n",
    "df[\"B_z\"] = df.groupby(\"subject_id\")[SCFA[0]].transform(robust_z)\n",
    "df[\"H_obs\"] = df[Hcol].clip(0, 1)\n",
    "\n",
    "subs = []\n",
    "for sid, sub in df.groupby(\"subject_id\"):\n",
    "    sub = sub.sort_values(\"t_idx\")\n",
    "    if len(sub) < MIN_ROWS: continue\n",
    "    t = sub[\"t_idx\"].to_numpy(float)\n",
    "    B = sub[\"B_z\"].to_numpy(float); H = sub[\"H_obs\"].to_numpy(float)\n",
    "    mB = np.isfinite(B); mH = np.isfinite(H)\n",
    "    if mB.sum() < 3 or mH.sum() < 3: continue\n",
    "    def first(a, d):\n",
    "        a = np.asarray(a, float); idx = np.where(np.isfinite(a))[0]\n",
    "        return float(a[idx[0]]) if len(idx) else float(d)\n",
    "    subs.append({\"sid\": sid, \"t\": t, \"B\": B, \"H\": H, \"maskB\": mB, \"maskH\": mH,\n",
    "                 \"nB\": int(mB.sum()), \"nH\": int(mH.sum()),\n",
    "                 \"H0\": float(np.clip(first(H, 0.6), 0, 1)),\n",
    "                 \"B0\": float(max(0.05, first(B, 0.1)))})\n",
    "if not subs: raise RuntimeError(\"no subjects\")\n",
    "print(f\"Loaded {len(subs)} subjects for fitting.\")\n",
    "\n",
    "# --- Model (RHS from 1.txt) ---\n",
    "def rhs_simple_model(t, y, p):\n",
    "    M, H, B, q = y\n",
    "    r_max, K_M, c, d, g, u, pL, pH, H_on, H_off, tau = p\n",
    "    pB = pL + (pH - pL)*np.clip(q, 0, 1)\n",
    "    dM = (r_max - c*pB)*M*(1 - M/K_M)\n",
    "    dH = g*B*(1 - H) - d*H\n",
    "    dB = pB*M - u*H*B\n",
    "    if H < H_on:\n",
    "        q_inf = 1.0\n",
    "    elif H > H_off:\n",
    "        q_inf = 0.0\n",
    "    else:\n",
    "        q_inf = q # Hold\n",
    "    dq = (q_inf - q) / tau\n",
    "    return [dM, dH, dB, dq]\n",
    "\n",
    "def simulate(ts, y0, p):\n",
    "    try:\n",
    "        sol = solve_ivp(lambda t, z: rhs_simple_model(t, z, p), (ts[0], ts[-1]), y0, t_eval=ts,\n",
    "                      rtol=1e-6, atol=1e-8, max_step=0.5)\n",
    "        if not sol.success: return np.vstack([np.full(len(ts), np.nan)] * 4)\n",
    "        return sol.y\n",
    "    except Exception:\n",
    "        return np.vstack([np.full(len(ts), np.nan)] * 4)\n",
    "\n",
    "# per-subject obs maps\n",
    "x0s = []; LBs_s = []; UBs_s = []\n",
    "for _ in subs: x0s += [1.0, 0.0, 1.0]; LBs_s += [0.1, -0.5,  0.1]; UBs_s += [5.0,  0.5,  2.0]\n",
    "# Combine ALL bounds into a single list of tuples\n",
    "LB = np.concatenate([LBg_simple, np.array(LBs_s, float)])\n",
    "UB = np.concatenate([UBg_simple, np.array(UBs_s, float)])\n",
    "full_bounds_list = list(zip(LB, UB))\n",
    "\n",
    "def unpack(x):\n",
    "    gpar = x[:len(PARAM_NAMES)]\n",
    "    triples = np.split(x[len(PARAM_NAMES):], len(subs))\n",
    "    return gpar, triples\n",
    "\n",
    "W_B, W_H = 0.6, 1.2 # Weights from 3.txt (seem reasonable)\n",
    "\n",
    "# --- Bistability Checker (adapted for 4-state model) ---\n",
    "def check_bistability(pvec):\n",
    "    try:\n",
    "        d_baseline = pvec[PARAM_NAMES.index('d')]\n",
    "        # y = [M, H, B, q]\n",
    "        y0_healthy = np.array([0.1, 0.9, 0.1, 0.0], float)\n",
    "        sol_h = solve_ivp(lambda t, z: rhs_simple_model(t, z, pvec), (0, 360), y0_healthy,\n",
    "                          t_eval=[360], rtol=1e-6, atol=1e-8)\n",
    "        H_final_healthy = sol_h.y[1, -1] if sol_h.success else -99\n",
    "        \n",
    "        y0_sick = np.array([0.1, 0.2, 0.1, 1.0], float)\n",
    "        sol_s = solve_ivp(lambda t, z: rhs_simple_model(t, z, pvec), (0, 360), y0_sick,\n",
    "                          t_eval=[360], rtol=1e-6, atol=1e-8)\n",
    "        H_final_sick = sol_s.y[1, -1] if sol_s.success else -99\n",
    "        \n",
    "        if (H_final_healthy > 0.8) and (H_final_sick < 0.5) and ((H_final_healthy - H_final_sick) > 0.3):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "# ---\n",
    "# === NEW COST FUNCTION for differential_evolution ===\n",
    "# ---\n",
    "def cost_function_for_de(x):\n",
    "    gpar, triples = unpack(x)\n",
    "    total_cost = 0.0\n",
    "    \n",
    "    # --- 1. Bistability Penalty ---\n",
    "    if not (gpar[PARAM_NAMES.index('H_off')] > gpar[PARAM_NAMES.index('H_on')]): \n",
    "        return PENALTY * 1e6 # Base parameter violation\n",
    "    \n",
    "    if not check_bistability(gpar):\n",
    "        total_cost += BISTABILITY_PENALTY\n",
    "\n",
    "    # --- 2. Data-fitting cost ---\n",
    "    for S, tr in zip(subs, triples):\n",
    "        alpha_B, beta0, beta1 = tr\n",
    "        ts = S[\"t\"]; H0 = np.clip(S[\"H0\"], 0, 1); B0 = max(0.05, S[\"B0\"])\n",
    "        M0 = 0.1; q0 = 1.0 if H0 < gpar[PARAM_NAMES.index('H_on')] else 0.0\n",
    "        y0 = [M0, H0, B0, q0] # [M, H, B, q]\n",
    "        Y = simulate(ts, y0, gpar)\n",
    "        \n",
    "        if np.any(~np.isfinite(Y)):\n",
    "            total_cost += PENALTY * (S[\"nB\"] + S[\"nH\"])\n",
    "            continue\n",
    "            \n",
    "        M, H, B, q = Y\n",
    "        Bhat = alpha_B * B\n",
    "        Hhat = np.clip(beta0 + beta1*H, 0, 1)\n",
    "        \n",
    "        res_B = W_B * (Bhat[S[\"maskB\"]] - S[\"B\"][S[\"maskB\"]])\n",
    "        res_H = W_H * (Hhat[S[\"maskH\"]] - S[\"H\"][S[\"maskH\"]])\n",
    "        total_cost += np.sum(res_B**2) + np.sum(res_H**2)\n",
    "\n",
    "    # --- 3. Prior cost ---\n",
    "    idx = {nm: i for i, nm in enumerate(PARAM_NAMES)}\n",
    "    for nm, (mu, sd) in PRIOR.items():\n",
    "        prior_cost = ((gpar[idx[nm]] - mu) / (sd + 1e-9))**2\n",
    "        total_cost += prior_cost\n",
    "        \n",
    "    return total_cost\n",
    "\n",
    "# ---\n",
    "# === RUN THE GLOBAL FIT ===\n",
    "# ---\n",
    "print(f\"--- Starting Global Fit (using {len(full_bounds_list)} parameters)... ---\")\n",
    "print(f\"This may take 30-60+ minutes. Start time: {time.ctime()}\")\n",
    "\n",
    "fit = differential_evolution(\n",
    "    cost_function_for_de, \n",
    "    bounds=full_bounds_list,\n",
    "    strategy='best1bin',\n",
    "    maxiter=500,       # Max iterations\n",
    "    popsize=15,        \n",
    "    tol=0.01, \n",
    "    mutation=(0.5, 1), \n",
    "    recombination=0.7, \n",
    "    seed=1,\n",
    "    disp=True,         # Print progress\n",
    "    polish=True        \n",
    ")\n",
    "\n",
    "print(\"\\n--- Fit complete. ---\")\n",
    "\n",
    "gpar_hat, _ = unpack(fit.x)\n",
    "pd.Series(gpar_hat, index=PARAM_NAMES).to_csv(NEW_PARAMS_FILE, header=False)\n",
    "print(\"[info] new globals (v6):\", dict(zip(PARAM_NAMES, gpar_hat)))\n",
    "print(f\"‚úÖ Saved new parameters to: {NEW_PARAMS_FILE}\")\n",
    "\n",
    "# ---\n",
    "# === PART 2: FINAL VALIDATION ===\n",
    "# ---\n",
    "print(\"\\n\" + \"=\"*30 + \"\\n\")\n",
    "print(f\"--- PART 2: Validating new parameters ---\")\n",
    "\n",
    "final_params_are_bistable = check_bistability(gpar_hat)\n",
    "\n",
    "if final_params_are_bistable:\n",
    "    print(\"‚úÖ‚úÖ‚úÖ SUCCESS: The final fitted parameters are BISTABLE.\")\n",
    "    print(\"You can now write a simple analysis script (like your 2.txt) to plot the hysteresis loop.\")\n",
    "else:\n",
    "    print(\"‚ùå‚ùå‚ùå FAILURE: The Global Optimizer could not find a bistable solution.\")\n",
    "    print(\"If this failed, it is the strongest evidence that your data does not support your hypothesis with this model.\")\n",
    "\n",
    "print(f\"\\n--- üéâ 'Fit-and-Test' v6 complete! ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57515039-846c-4a56-b9b7-47d8a86ead80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benpyenv",
   "language": "python",
   "name": "benpyenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
