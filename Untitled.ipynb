{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b231293-9ef4-4542-812e-d881be2584cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate_hysteresis_from_scored_updated_v3.py >>>>>>>>> smooth hysteresis:: rhs_smooth and q_inf smooth \n",
    "\n",
    "\n",
    "\n",
    "# calibrate_hysteresis_from_scored_smooth.py\n",
    "# ------------------------------------------------------------\n",
    "# Smooth-hysteresis calibration to SCFA intensities and an H proxy.\n",
    "# Fixes the variable-length residual issue by precomputing fixed masks.\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "# ----------------- Config -----------------\n",
    "INPATH  = \"timeseries/combined_scfas_table_scored.csv\"\n",
    "OUTDIR  = \"mw_fit_out_smooth\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "USE_H_COL  = \"H_proxy_meta_smooth\"   # fallback to \"H_proxy_meta\" if needed\n",
    "USE_B_COLS = [\"butyrate\"]            # add other SCFAs if desired\n",
    "\n",
    "MIN_POINTS_PER_SUBJECT = 4\n",
    "PENALTY = 1e3                  # finite penalty for pathological cases\n",
    "KQ      = 40.0                 # steepness of the smooth hysteretic switch sigma(k*(H-theta(q)))\n",
    "\n",
    "# ----------------- Load & checks -----------------\n",
    "df = pd.read_csv(INPATH)\n",
    "needed = {\"subject_id\",\"sample_id\"}\n",
    "missing = [c for c in needed if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns in CSV: {missing}\")\n",
    "\n",
    "if USE_H_COL not in df.columns:\n",
    "    alt = \"H_proxy_meta\"\n",
    "    if alt in df.columns:\n",
    "        print(f\"[info] {USE_H_COL} not found; using {alt} instead.\")\n",
    "        USE_H_COL = alt\n",
    "    else:\n",
    "        raise ValueError(\"No usable H proxy column found (need H_proxy_meta_smooth or H_proxy_meta).\")\n",
    "\n",
    "for c in USE_B_COLS:\n",
    "    if c not in df.columns:\n",
    "        raise ValueError(f\"SCFA column '{c}' not found in CSV.\")\n",
    "\n",
    "keep = [\"subject_id\",\"sample_id\", USE_H_COL] + USE_B_COLS\n",
    "df = df[keep].dropna(subset=[\"subject_id\",\"sample_id\"]).copy()\n",
    "\n",
    "# ----------------- Time indexing -----------------\n",
    "df[\"t_idx\"] = df.groupby(\"subject_id\").cumcount().astype(float)\n",
    "\n",
    "# ----------------- Robust scaling (MAD) -----------------\n",
    "def robust_mad_scale(x: pd.Series) -> pd.Series:\n",
    "    x_valid = x.dropna().astype(float)\n",
    "    if len(x_valid) == 0:\n",
    "        return pd.Series(np.zeros_like(x), index=x.index)\n",
    "    med = np.median(x_valid)\n",
    "    mad = np.median(np.abs(x_valid - med))\n",
    "    if mad < 1e-9:\n",
    "        q75, q25 = np.percentile(x_valid, [75, 25])\n",
    "        iqr = q75 - q25\n",
    "        scale = iqr if iqr > 1e-9 else (np.std(x_valid) + 1e-9)\n",
    "    else:\n",
    "        scale = mad\n",
    "    return (x.astype(float) - med) / (scale + 1e-9)\n",
    "\n",
    "for c in USE_B_COLS:\n",
    "    df[c + \"_z\"] = df.groupby(\"subject_id\")[c].transform(robust_mad_scale)\n",
    "\n",
    "if len(USE_B_COLS) == 1:\n",
    "    df[\"B_obs\"] = df[USE_B_COLS[0] + \"_z\"]\n",
    "else:\n",
    "    zcols = [c + \"_z\" for c in USE_B_COLS]\n",
    "    df[\"B_obs\"] = df[zcols].mean(axis=1)\n",
    "\n",
    "df[\"H_obs\"] = df[USE_H_COL].clip(0, 1)\n",
    "\n",
    "# ----------------- Pack per-subject series (with fixed masks) -----------------\n",
    "def first_finite(x: np.ndarray, default: float) -> float:\n",
    "    idx = np.where(np.isfinite(x))[0]\n",
    "    if len(idx) > 0:\n",
    "        return float(x[idx[0]])\n",
    "    return float(default)\n",
    "\n",
    "subjects = df[\"subject_id\"].unique().tolist()\n",
    "subs = []\n",
    "\n",
    "for s in subjects:\n",
    "    sub = df[df[\"subject_id\"]==s].sort_values(\"t_idx\").copy()\n",
    "    t_all = sub[\"t_idx\"].values.astype(float)\n",
    "    B_all = sub[\"B_obs\"].values.astype(float)\n",
    "    H_all = sub[\"H_obs\"].values.astype(float)\n",
    "\n",
    "    # must have enough rows\n",
    "    if sub.shape[0] < MIN_POINTS_PER_SUBJECT:\n",
    "        continue\n",
    "\n",
    "    # finite masks (FIXED over the entire optimization)\n",
    "    maskB = np.isfinite(B_all)\n",
    "    maskH = np.isfinite(H_all)\n",
    "    if maskB.sum() < 3 or maskH.sum() < 3:\n",
    "        continue\n",
    "\n",
    "    # store\n",
    "    subs.append({\n",
    "        \"sid\": s,\n",
    "        \"t\": t_all,                 # times to simulate at (same grid for model)\n",
    "        \"B_all\": B_all, \"H_all\": H_all,\n",
    "        \"maskB\": maskB, \"maskH\": maskH,\n",
    "        \"nB\": int(maskB.sum()), \"nH\": int(maskH.sum()),\n",
    "        # init values determined from first finite entries\n",
    "        \"H0\": float(np.clip(first_finite(H_all, 0.5), 0, 1)),\n",
    "        \"B0\": float(max(0.05, first_finite(B_all, 0.1))),\n",
    "    })\n",
    "\n",
    "if not subs:\n",
    "    raise RuntimeError(\"No subject has enough finite points to fit (need ≥4 rows and ≥3 finite in both B & H).\")\n",
    "\n",
    "print(f\"[info] Fitting {len(subs)} subjects...\")\n",
    "print(\"[info] Per-subject usable points (finite counts):\")\n",
    "for S in subs[:10]:\n",
    "    print(f\"  - {S['sid']}: B={S['nB']}, H={S['nH']} (of {len(S['t'])})\")\n",
    "if len(subs) > 10:\n",
    "    print(\"  ...\")\n",
    "\n",
    "# ----------------- Smooth hysteretic model -----------------\n",
    "# y = [M, H, B, q]\n",
    "# p = [r_max,K_M,c,d,g,u,p_low,p_high,H_on,H_off,tau_q]\n",
    "\n",
    "def q_inf_smooth(H, q, H_on, H_off, k=KQ):\n",
    "    theta = (1.0 - q) * H_on + q * H_off   # moving threshold between H_on and H_off\n",
    "    return 1.0 / (1.0 + np.exp(-k * (H - theta)))\n",
    "\n",
    "def rhs_smooth(t, y, p):\n",
    "    M, H, B, q = y\n",
    "    r_max, K_M, c, d, g, u, pL, pH, H_on, H_off, tau = p\n",
    "    pB = pL + (pH - pL)*np.clip(q, 0, 1)\n",
    "    dM = (r_max - c*pB)*M*(1 - M/K_M)\n",
    "    dH = g*B*(1 - H) - d*H\n",
    "    dB = pB*M - u*H*B\n",
    "    qinf = q_inf_smooth(H, q, H_on, H_off, k=KQ)\n",
    "    dq   = (qinf - q) / tau\n",
    "    return [dM, dH, dB, dq]\n",
    "\n",
    "def simulate(ts, y0, p):\n",
    "    y0 = np.array(y0, dtype=float)\n",
    "    if not np.all(np.isfinite(y0)):\n",
    "        T = len(ts)\n",
    "        return np.vstack([np.full(T, np.nan)]*4)\n",
    "    try:\n",
    "        sol = solve_ivp(lambda t,y: rhs_smooth(t,y,p), (ts[0], ts[-1]), y0, t_eval=ts,\n",
    "                        rtol=1e-6, atol=1e-8, max_step=0.5)\n",
    "        if not sol.success:\n",
    "            T = len(ts)\n",
    "            return np.vstack([np.full(T, np.nan)]*4)\n",
    "        return sol.y\n",
    "    except Exception:\n",
    "        T = len(ts)\n",
    "        return np.vstack([np.full(T, np.nan)]*4)\n",
    "\n",
    "# ----------------- Parameters -----------------\n",
    "# global parameters (11)\n",
    "LBg = np.array([0.1, 0.4, 0.02, 0.01, 0.05, 0.2, 0.0, 0.5, 0.2, 0.3, 0.5])\n",
    "UBg = np.array([0.6, 1.5, 0.25, 0.5 , 2.0 , 1.2, 0.8, 4.0, 0.8, 0.95,24.0])\n",
    "x0g = np.array([0.32, 1.0, 0.10, 0.12, 0.5, 0.6, 0.1, 2.5, 0.55, 0.80, 4.0])  # slightly higher H_off start\n",
    "\n",
    "# per-subject linear links: Bhat = alpha_B * B ; Hhat = clip(beta0 + beta1*H, 0,1)\n",
    "x0s, LBs, UBs = [], [], []\n",
    "for _ in subs:\n",
    "    x0s += [1.0, 0.0, 1.0]  # alpha_B, beta0_H, beta1_H\n",
    "    LBs += [0.1, -0.5,  0.1]\n",
    "    UBs += [5.0,  0.5,  2.0]\n",
    "\n",
    "x0 = np.concatenate([x0g, np.array(x0s, dtype=float)])\n",
    "LB = np.concatenate([LBg, np.array(LBs, dtype=float)])\n",
    "UB = np.concatenate([UBg, np.array(UBs, dtype=float)])\n",
    "\n",
    "def unpack(x):\n",
    "    gpar = x[:11]\n",
    "    spar = x[11:]\n",
    "    triples = np.split(spar, len(subs))\n",
    "    return gpar, triples\n",
    "\n",
    "# ----------------- Residuals (fixed length) -----------------\n",
    "def residuals(x):\n",
    "    gpar, triples = unpack(x)\n",
    "\n",
    "    # soft constraint to keep H_off > H_on\n",
    "    if gpar[9] <= gpar[8]:\n",
    "        return np.full(total_length, PENALTY, dtype=float)\n",
    "\n",
    "    res_list = []   # collect fixed-length chunks in precomputed order\n",
    "\n",
    "    for (S,tr) in zip(subs, triples):\n",
    "        alpha_B, beta0, beta1 = tr\n",
    "        ts = S[\"t\"]\n",
    "\n",
    "        # initial conditions (robust)\n",
    "        H0 = float(np.clip(S[\"H0\"], 0, 1))\n",
    "        B0 = float(max(0.05, S[\"B0\"]))\n",
    "        M0 = 0.1\n",
    "        # choose initial q based on H0 relative to mid-threshold to help solver\n",
    "        q0 = 1.0 if H0 < (0.5*(gpar[8]+gpar[9])) else 0.0\n",
    "        y0 = [M0, H0, B0, q0]\n",
    "\n",
    "        Y = simulate(ts, y0, gpar)\n",
    "        _, H, B, _ = Y\n",
    "\n",
    "        # If integration failed -> fill with penalties of FIXED lengths\n",
    "        if np.any(~np.isfinite(H)) or np.any(~np.isfinite(B)):\n",
    "            res_list.append(np.full(S[\"nB\"], PENALTY, dtype=float))\n",
    "            res_list.append(np.full(S[\"nH\"], PENALTY, dtype=float))\n",
    "            continue\n",
    "\n",
    "        # observation models evaluated at the same time grid, then masked\n",
    "        Bhat = alpha_B * B\n",
    "        Hhat = np.clip(beta0 + beta1*H, 0, 1)\n",
    "\n",
    "        # apply FIXED masks\n",
    "        b_res = (Bhat[S[\"maskB\"]] - S[\"B_all\"][S[\"maskB\"]])\n",
    "        h_res = (Hhat[S[\"maskH\"]] - S[\"H_all\"][S[\"maskH\"]])\n",
    "\n",
    "        # make sure we always push finite values\n",
    "        if not np.all(np.isfinite(b_res)):\n",
    "            b_res = np.where(np.isfinite(b_res), b_res, PENALTY)\n",
    "        if not np.all(np.isfinite(h_res)):\n",
    "            h_res = np.where(np.isfinite(h_res), h_res, PENALTY)\n",
    "\n",
    "        # ensure fixed lengths (by construction)\n",
    "        res_list.append(b_res.astype(float))\n",
    "        res_list.append(h_res.astype(float))\n",
    "\n",
    "    return np.concatenate(res_list)\n",
    "\n",
    "# compute the total residual length ONCE so we can return fixed penalties if needed\n",
    "total_length = sum(S[\"nB\"] + S[\"nH\"] for S in subs)\n",
    "\n",
    "# ----------------- Fit -----------------\n",
    "fit = least_squares(\n",
    "    residuals, x0, bounds=(LB, UB),\n",
    "    verbose=2, max_nfev=800,\n",
    "    loss=\"soft_l1\", f_scale=1.0,\n",
    ")\n",
    "gpar_hat, triples_hat = unpack(fit.x)\n",
    "\n",
    "param_names = [\"r_max\",\"K_M\",\"c\",\"d\",\"g\",\"u\",\"p_low\",\"p_high\",\"H_on\",\"H_off\",\"tau_q\"]\n",
    "pd.Series(gpar_hat, index=param_names).to_csv(os.path.join(OUTDIR, \"fitted_global_params.csv\"))\n",
    "\n",
    "pd.DataFrame(\n",
    "    [{\"subject_id\": S[\"sid\"], \"alpha_B\": tr[0], \"beta0_H\": tr[1], \"beta1_H\": tr[2]}\n",
    "     for S,tr in zip(subs, triples_hat)]\n",
    ").to_csv(os.path.join(OUTDIR, \"fitted_subject_scales.csv\"), index=False)\n",
    "\n",
    "print(\"[info] Fitted global params:\", dict(zip(param_names, gpar_hat)))\n",
    "\n",
    "# ----------------- Diagnostics (first few subjects) -----------------\n",
    "for S,tr in list(zip(subs, triples_hat))[:8]:\n",
    "    alpha_B, beta0, beta1 = tr\n",
    "\n",
    "    H0 = float(np.clip(S[\"H0\"], 0, 1))\n",
    "    B0 = float(max(0.05, S[\"B0\"]))\n",
    "    M0 = 0.1\n",
    "    q0 = 1.0 if H0 < (0.5*(gpar_hat[8]+gpar_hat[9])) else 0.0\n",
    "    y0 = [M0, H0, B0, q0]\n",
    "\n",
    "    Y = simulate(S[\"t\"], y0, gpar_hat)\n",
    "    M,H,B,q = Y\n",
    "    if np.any(~np.isfinite(H)) or np.any(~np.isfinite(B)):\n",
    "        continue\n",
    "    Bhat = alpha_B*B\n",
    "    Hhat = np.clip(beta0 + beta1*H, 0, 1)\n",
    "\n",
    "    maskB = S[\"maskB\"]; maskH = S[\"maskH\"]\n",
    "\n",
    "    fig, ax = plt.subplots(2,1, figsize=(7,6), sharex=True)\n",
    "    ax[0].plot(S[\"t\"][maskB], Bhat[maskB], label=\"Model B (scaled)\")\n",
    "    ax[0].scatter(S[\"t\"][maskB], S[\"B_all\"][maskB], s=18, c=\"k\", label=\"Obs B (z)\")\n",
    "    ax[0].set_ylabel(\"B intensity (scaled)\")\n",
    "    ax[0].legend(); ax[0].grid(True, ls=\":\")\n",
    "\n",
    "    ax[1].plot(S[\"t\"][maskH], Hhat[maskH], label=\"Model H\")\n",
    "    ax[1].scatter(S[\"t\"][maskH], S[\"H_all\"][maskH], s=18, c=\"k\", label=\"H proxy\")\n",
    "    ax[1].axhline(gpar_hat[8], ls=\":\", c=\"gray\", label=\"H_on\")\n",
    "    ax[1].axhline(gpar_hat[9], ls=\"--\", c=\"gray\", label=\"H_off\")\n",
    "    ax[1].set_xlabel(\"time index\"); ax[1].set_ylabel(\"H\")\n",
    "    ax[1].legend(); ax[1].grid(True, ls=\":\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTDIR, f\"diag_{S['sid']}.png\"), dpi=180)\n",
    "    plt.close()\n",
    "\n",
    "print(\"✅ Done. See outputs in:\", OUTDIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259d25a9-19c6-46e0-8c03-165b2871c606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e70667b-504a-4bfa-ba68-444ca079d172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bifurcation_and_basins_smooth.py\n",
    "# ------------------------------------------------------------\n",
    "# Uses the smooth-hysteresis model you just fitted to:\n",
    "#   (A) continue equilibria vs d and test stability (Jacobian eigs)\n",
    "#   (B) check if the baseline d lies in a bistable region\n",
    "#   (C) draw a basin-of-attraction map at baseline\n",
    "#   (D) (optional) repeat with weak positive feedback r_H\n",
    "#\n",
    "# Input:  mw_fit_out/fitted_global_params.csv  (from your smooth calibration)\n",
    "# Output: mw_bif_smooth/\n",
    "#   - branches.csv\n",
    "#   - bifurcation_H_vs_d.png\n",
    "#   - basins_heatmap.png\n",
    "#   - hysteresis_sweep.png\n",
    "#   - diagnosis.txt\n",
    "# (and *_pf.* counterparts if POS_FEEDBACK=True)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.optimize import root\n",
    "\n",
    "# ----------------- Config -----------------\n",
    "FIT_CSV       = \"mw_fit_out_smooth/fitted_global_params.csv\"\n",
    "OUTDIR        = \"mw_bif_smooth\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "# Smooth switch sharpness (same k you used in calibration; 30–60 works)\n",
    "KQ            = 40.0\n",
    "\n",
    "# Continuation range around baseline d (you can widen if needed)\n",
    "D_SPAN_FACTOR = (0.6, 1.5)      # explore from 0.6×d_fit to 1.5×d_fit\n",
    "N_D_POINTS    = 80\n",
    "\n",
    "# Basins grid at baseline\n",
    "H_GRID = np.linspace(0.2, 0.95, 17)\n",
    "Q_GRID = np.linspace(0.0, 1.0, 17)\n",
    "\n",
    "# Optional: add weak positive feedback r_H into microbe growth\n",
    "POS_FEEDBACK  = True    # <-- set True to test the r_H model\n",
    "R_H_VALUE     = 0.2     # h^-1 contribution to growth per unit H (small)\n",
    "\n",
    "# ----------------- Load fitted globals -----------------\n",
    "g = pd.read_csv(FIT_CSV, index_col=0).squeeze(\"columns\")\n",
    "# params (smooth model without PF): [r_max,K_M,c,d,g,u,p_low,p_high,H_on,H_off,tau_q]\n",
    "pars = np.array([\n",
    "    float(g.get(\"r_max\", 0.32)),\n",
    "    float(g.get(\"K_M\", 1.0)),\n",
    "    float(g.get(\"c\", 0.10)),\n",
    "    float(g.get(\"d\", 0.12)),\n",
    "    float(g.get(\"g\", 0.5)),\n",
    "    float(g.get(\"u\", 0.6)),\n",
    "    float(g.get(\"p_low\", 0.1)),\n",
    "    float(g.get(\"p_high\", 2.5)),\n",
    "    float(g.get(\"H_on\", 0.55)),\n",
    "    float(g.get(\"H_off\", 0.80)),   # you likely refit; read what’s in CSV\n",
    "    float(g.get(\"tau_q\", 4.0)),\n",
    "], float)\n",
    "\n",
    "# ----------------- Smooth hysteresis helpers -----------------\n",
    "def q_inf_smooth(H, q, H_on, H_off, k=KQ):\n",
    "    theta = (1.0 - q) * H_on + q * H_off\n",
    "    return 1.0 / (1.0 + np.exp(-k * (H - theta)))\n",
    "\n",
    "def rhs_smooth(y, p, d_override=None):\n",
    "    \"\"\"No positive feedback (baseline smooth model).\"\"\"\n",
    "    M, H, B, q = y\n",
    "    r_max,K_M,c,d,gH,u,pL,pH,H_on,H_off,tau = p.copy()\n",
    "    if d_override is not None: d = d_override\n",
    "    pB = pL + (pH - pL)*np.clip(q,0,1)\n",
    "    dM = (r_max - c*pB)*M*(1 - M/K_M)\n",
    "    dH = gH*B*(1 - H) - d*H\n",
    "    dB = pB*M - u*H*B\n",
    "    qinf = q_inf_smooth(H, q, H_on, H_off, k=KQ)\n",
    "    dq   = (qinf - q)/tau\n",
    "    return np.array([dM,dH,dB,dq], float)\n",
    "\n",
    "def rhs_pf(y, p, d_override=None, rH=R_H_VALUE):\n",
    "    \"\"\"With weak positive feedback r_H: r_eff = r_max + rH*H.\"\"\"\n",
    "    M, H, B, q = y\n",
    "    r_max,K_M,c,d,gH,u,pL,pH,H_on,H_off,tau = p.copy()\n",
    "    if d_override is not None: d = d_override\n",
    "    pB = pL + (pH - pL)*np.clip(q,0,1)\n",
    "    r_eff = r_max + rH*H\n",
    "    dM = (r_eff - c*pB)*M*(1 - M/K_M)\n",
    "    dH = gH*B*(1 - H) - d*H\n",
    "    dB = pB*M - u*H*B\n",
    "    qinf = q_inf_smooth(H, q, H_on, H_off, k=KQ)\n",
    "    dq   = (qinf - q)/tau\n",
    "    return np.array([dM,dH,dB,dq], float)\n",
    "\n",
    "# choose which RHS to use\n",
    "RHS = rhs_pf if POS_FEEDBACK else rhs_smooth\n",
    "\n",
    "# ----------------- Utilities -----------------\n",
    "def jacobian_fd(fun, y, p, d_val=None, eps=1e-7):\n",
    "    f0 = fun(y, p, d_val)\n",
    "    J = np.zeros((4,4))\n",
    "    for i in range(4):\n",
    "        y2 = y.copy(); y2[i] += eps\n",
    "        J[:,i] = (fun(y2, p, d_val) - f0)/eps\n",
    "    return J\n",
    "\n",
    "def find_equilibrium(fun, p, d_val, guess):\n",
    "    sol = root(lambda yy: fun(yy, p, d_val), guess, method=\"hybr\")\n",
    "    if not sol.success:\n",
    "        return guess, False\n",
    "    y = sol.x\n",
    "    # project to physical range\n",
    "    y = np.array([\n",
    "        max(0.0, y[0]),\n",
    "        np.clip(y[1], 0.0, 1.2),\n",
    "        max(0.0, y[2]),\n",
    "        np.clip(y[3], 0.0, 1.2),\n",
    "    ], float)\n",
    "    if not np.all(np.isfinite(y)):\n",
    "        return guess, False\n",
    "    return y, True\n",
    "\n",
    "def relax_to_ss(fun, p, d_val, y0, T=240):\n",
    "    sol = solve_ivp(lambda t,yy: fun(yy, p, d_val), (0,T), y0,\n",
    "                    t_eval=np.linspace(0,T,900), rtol=1e-6, atol=1e-8, max_step=0.5)\n",
    "    return sol.y[:,-1], sol\n",
    "\n",
    "# ----------------- (A) Continuation in d -----------------\n",
    "d_fit = float(pars[3])\n",
    "d_vals = np.linspace(d_fit*D_SPAN_FACTOR[0], d_fit*D_SPAN_FACTOR[1], N_D_POINTS)\n",
    "\n",
    "seeds = [\n",
    "    np.array([0.2, 0.2, 0.05, 1.0]),   # low-H / q≈1\n",
    "    np.array([0.2, 0.9, 0.10, 0.0]),   # high-H / q≈0\n",
    "    np.array([0.6, 0.6, 0.20, 0.5]),   # mid\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for d in d_vals:\n",
    "    for wi, y0 in enumerate(seeds):\n",
    "        y_eq, ok = find_equilibrium(RHS, pars, d, y0)\n",
    "        if ok:\n",
    "            J = jacobian_fd(RHS, y_eq, pars, d_val=d)\n",
    "            eigs = np.linalg.eigvals(J)\n",
    "            stable = bool(np.max(np.real(eigs)) < 0)\n",
    "            rows.append({\"d\": d, \"H\": float(y_eq[1]), \"q\": float(y_eq[3]),\n",
    "                         \"seed\": wi, \"stable\": stable})\n",
    "branches = pd.DataFrame(rows)\n",
    "branches.to_csv(os.path.join(OUTDIR, \"branches.csv\"), index=False)\n",
    "\n",
    "# plot branches\n",
    "plt.figure(figsize=(7.2,5.2))\n",
    "for wi in sorted(branches[\"seed\"].unique()):\n",
    "    sub = branches[branches[\"seed\"]==wi]\n",
    "    plt.plot(sub[\"d\"], sub[\"H\"], \".\", ms=3, alpha=0.7, label=f\"seed{wi}\")\n",
    "for st, mk in [(True, \"o\"), (False, \"x\")]:\n",
    "    sub = branches[branches[\"stable\"]==st]\n",
    "    plt.scatter(sub[\"d\"], sub[\"H\"], s=22, marker=mk, alpha=0.6,\n",
    "                label=(\"stable\" if st else \"unstable\"))\n",
    "plt.axvline(d_fit, ls=\"--\", c=\"gray\", label=\"baseline d\")\n",
    "plt.xlabel(\"d (1/h)\"); plt.ylabel(\"H* at equilibrium\")\n",
    "plt.legend(); plt.grid(True, ls=\":\", alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTDIR, \"bifurcation_H_vs_d.png\"), dpi=180)\n",
    "plt.close()\n",
    "\n",
    "# ----------------- (B) Is baseline d inside a bistable band? -----------------\n",
    "near = branches[np.isclose(branches[\"d\"], d_fit, atol=1e-3)]\n",
    "# count distinct stable points (tolerance to avoid duplicate seeds converging to same eq)\n",
    "if not near.empty:\n",
    "    Hs = np.sort(near.loc[near[\"stable\"], \"H\"].values)\n",
    "    distinct = 0\n",
    "    if Hs.size:\n",
    "        distinct = 1\n",
    "        for i in range(1, len(Hs)):\n",
    "            if abs(Hs[i] - Hs[i-1]) > 1e-3:  # distinct H*\n",
    "                distinct += 1\n",
    "else:\n",
    "    distinct = 0\n",
    "bistable = bool(distinct >= 2)\n",
    "\n",
    "# ----------------- (C) Basin-of-attraction map at baseline -----------------\n",
    "Z = np.zeros((len(H_GRID), len(Q_GRID)))\n",
    "for i, H0 in enumerate(H_GRID):\n",
    "    for j, q0 in enumerate(Q_GRID):\n",
    "        y0 = np.array([0.2, H0, 0.1, q0], float)\n",
    "        yss, _ = relax_to_ss(RHS, pars, d_fit, y0, T=300)\n",
    "        Z[i, j] = yss[1]\n",
    "\n",
    "plt.figure(figsize=(6.6,5.4))\n",
    "plt.imshow(Z, origin=\"lower\",\n",
    "           extent=[Q_GRID[0], Q_GRID[-1], H_GRID[0], H_GRID[-1]],\n",
    "           aspect=\"auto\", vmin=0.5, vmax=1.0, cmap=\"viridis\")\n",
    "plt.colorbar(label=\"Final H (steady)\")\n",
    "plt.xlabel(\"initial q\"); plt.ylabel(\"initial H\")\n",
    "plt.title(f\"Basins at baseline d={d_fit:.3f}\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTDIR, \"basins_heatmap.png\"), dpi=180)\n",
    "plt.close()\n",
    "\n",
    "# ----------------- (D) Dynamic hysteresis sweep (for comparison) -----------------\n",
    "def sweep(fun, p, H0, q0, d_lo, d_hi, T=160):\n",
    "    y = np.array([0.1, H0, 0.1, q0], float)\n",
    "    grid = np.linspace(d_lo, d_hi, 28)\n",
    "    fwd, bwd = [], []\n",
    "    for d in grid:\n",
    "        y, _ = relax_to_ss(fun, p, d, y, T=T)\n",
    "        fwd.append((d, *y))\n",
    "    for d in grid[::-1]:\n",
    "        y, _ = relax_to_ss(fun, p, d, y, T=T)\n",
    "        bwd.append((d, *y))\n",
    "    return pd.DataFrame(fwd, columns=[\"d\",\"M\",\"H\",\"B\",\"q\"]), \\\n",
    "           pd.DataFrame(bwd, columns=[\"d\",\"M\",\"H\",\"B\",\"q\"])\n",
    "\n",
    "fwd, bwd = sweep(RHS, pars, H0=0.8, q0=0.0,\n",
    "                 d_lo=d_fit*D_SPAN_FACTOR[0], d_hi=d_fit*D_SPAN_FACTOR[1], T=180)\n",
    "\n",
    "plt.figure(figsize=(7.6,4.2))\n",
    "plt.plot(fwd[\"d\"], fwd[\"H\"], \"-o\", ms=3, label=\"forward (d↑)\")\n",
    "plt.plot(bwd[\"d\"], bwd[\"H\"], \"-s\", ms=3, label=\"backward (d↓)\")\n",
    "plt.axhline(pars[8], ls=\":\", c=\"gray\", label=\"H_on\")\n",
    "plt.axhline(pars[9], ls=\"--\", c=\"gray\", label=\"H_off\")\n",
    "plt.xlabel(\"d (1/h)\"); plt.ylabel(\"H* (dynamic SS)\"); plt.legend()\n",
    "plt.grid(True, ls=\":\", alpha=0.6); plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTDIR, \"hysteresis_sweep.png\"), dpi=180)\n",
    "plt.close()\n",
    "\n",
    "# ----------------- Report -----------------\n",
    "with open(os.path.join(OUTDIR, \"diagnosis.txt\"), \"w\") as f:\n",
    "    f.write(f\"Baseline d = {d_fit:.5f}\\n\")\n",
    "    f.write(f\"Distinct stable equilibria at baseline (by H*): {distinct}\\n\")\n",
    "    f.write(f\"Bistable at baseline? {'YES' if bistable else 'NO'}\\n\")\n",
    "    f.write(f\"Model used: {'smooth + positive feedback (r_H={R_H_VALUE})' if POS_FEEDBACK else 'smooth, no PF'}\\n\")\n",
    "\n",
    "print(\"Saved results to:\", OUTDIR)\n",
    "print(\"Bistable at baseline? \", \"YES\" if bistable else \"NO\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eb08bc-7137-4d76-a6dd-b41486d7d75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate_hysteresis_from_scored_pf_prior.py\n",
    "# ------------------------------------------------------------\n",
    "# Calibrate smooth-hysteresis model with host->microbe positive feedback (r_H)\n",
    "# and gentle priors; fixed-length residuals; corrected priors block.\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "# ----------------- Paths & config -----------------\n",
    "INPATH  = \"timeseries/combined_scfas_table_scored.csv\"\n",
    "OUTDIR  = \"mw_fit_out_pf\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "USE_H_COL  = \"H_proxy_meta_smooth\"     # fallback to \"H_proxy_meta\" if not found\n",
    "USE_B_COLS = [\"butyrate\"]\n",
    "\n",
    "MIN_POINTS_PER_SUBJECT = 4\n",
    "KQ      = 40.0     # smooth switch steepness\n",
    "PENALTY = 1e3      # finite penalty fallback (keeps residual length fixed)\n",
    "\n",
    "# ---- Priors (edit here if desired) ----\n",
    "H_OFF_TARGET   = 0.85\n",
    "H_OFF_SD       = 0.05\n",
    "R_EFF_H_REF    = 0.8\n",
    "R_EFF_TARGET   = 0.35   # ~ your earlier r_max\n",
    "R_EFF_SD       = 0.05\n",
    "U_SD           = 0.25\n",
    "\n",
    "# ----------------- Load data -----------------\n",
    "df = pd.read_csv(INPATH)\n",
    "needed = {\"subject_id\",\"sample_id\"}\n",
    "if missing := [c for c in needed if c not in df.columns]:\n",
    "    raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "if USE_H_COL not in df.columns:\n",
    "    alt = \"H_proxy_meta\"\n",
    "    if alt in df.columns:\n",
    "        print(f\"[info] {USE_H_COL} not found; using {alt} instead.\")\n",
    "        USE_H_COL = alt\n",
    "    else:\n",
    "        raise ValueError(\"No usable H proxy column (need H_proxy_meta_smooth or H_proxy_meta).\")\n",
    "\n",
    "for c in USE_B_COLS:\n",
    "    if c not in df.columns:\n",
    "        raise ValueError(f\"SCFA column '{c}' not in data.\")\n",
    "\n",
    "keep = [\"subject_id\",\"sample_id\", USE_H_COL] + USE_B_COLS\n",
    "df = df[keep].dropna(subset=[\"subject_id\",\"sample_id\"]).copy()\n",
    "df[\"t_idx\"] = df.groupby(\"subject_id\").cumcount().astype(float)\n",
    "\n",
    "# ----------------- Robust scaling -----------------\n",
    "def robust_mad_scale(series: pd.Series) -> pd.Series:\n",
    "    x = series.astype(float).to_numpy()\n",
    "    m = np.isfinite(x)\n",
    "    if m.sum() == 0:\n",
    "        return pd.Series(np.zeros_like(x), index=series.index)\n",
    "    xm = x[m]\n",
    "    med = np.median(xm)\n",
    "    mad = np.median(np.abs(xm - med))\n",
    "    if mad < 1e-9:\n",
    "        q75, q25 = np.percentile(xm, [75, 25])\n",
    "        iqr = q75 - q25\n",
    "        scale = iqr if iqr > 1e-9 else (np.std(xm) + 1e-9)\n",
    "    else:\n",
    "        scale = mad\n",
    "    return pd.Series((x - med) / (scale + 1e-9), index=series.index)\n",
    "\n",
    "for c in USE_B_COLS:\n",
    "    df[c+\"_z\"] = df.groupby(\"subject_id\")[c].transform(robust_mad_scale)\n",
    "\n",
    "df[\"B_obs\"] = df[USE_B_COLS[0] + \"_z\"] if len(USE_B_COLS)==1 else df[[c+\"_z\" for c in USE_B_COLS]].mean(axis=1)\n",
    "df[\"H_obs\"] = df[USE_H_COL].clip(0,1)\n",
    "\n",
    "# ----------------- Pack per-subject with fixed masks -----------------\n",
    "def first_finite(a, default):\n",
    "    idx = np.where(np.isfinite(a))[0]\n",
    "    return float(a[idx[0]]) if len(idx) else float(default)\n",
    "\n",
    "subjects = df[\"subject_id\"].unique().tolist()\n",
    "subs = []\n",
    "for sid in subjects:\n",
    "    sub = df[df[\"subject_id\"]==sid].sort_values(\"t_idx\").copy()\n",
    "    if len(sub) < MIN_POINTS_PER_SUBJECT:\n",
    "        continue\n",
    "    t  = sub[\"t_idx\"].values.astype(float)\n",
    "    H  = sub[\"H_obs\"].values.astype(float)\n",
    "    B  = sub[\"B_obs\"].values.astype(float)\n",
    "    mH = np.isfinite(H)\n",
    "    mB = np.isfinite(B)\n",
    "    if mH.sum() < 3 or mB.sum() < 3:\n",
    "        continue\n",
    "    subs.append({\n",
    "        \"sid\": sid,\n",
    "        \"t\": t,\n",
    "        \"H\": H,\n",
    "        \"B\": B,\n",
    "        \"maskH\": mH, \"maskB\": mB,\n",
    "        \"nH\": int(mH.sum()), \"nB\": int(mB.sum()),\n",
    "        \"H0\": float(np.clip(first_finite(H, 0.6), 0, 1)),\n",
    "        \"B0\": float(max(0.05, first_finite(B, 0.1))),\n",
    "    })\n",
    "\n",
    "if not subs:\n",
    "    raise RuntimeError(\"No subject has enough finite points to fit.\")\n",
    "\n",
    "print(f\"[info] Fitting {len(subs)} subjects...\")\n",
    "for S in subs[:10]:\n",
    "    print(f\"  - {S['sid']}: B={S['nB']} H={S['nH']} (of {len(S['t'])})\")\n",
    "if len(subs)>10: print(\"  ...\")\n",
    "\n",
    "# ----------------- Smooth hysteresis + positive feedback -----------------\n",
    "# y=[M,H,B,q]\n",
    "# global p = [r0, rH, K_M, c, d, g, u, p_low, p_high, H_on, H_off, tau_q]\n",
    "\n",
    "def q_inf_smooth(H, q, H_on, H_off, k=KQ):\n",
    "    theta = (1.0 - q)*H_on + q*H_off\n",
    "    return 1.0 / (1.0 + np.exp(-k*(H - theta)))\n",
    "\n",
    "def rhs_pf(t, y, p):\n",
    "    M, H, B, q = y\n",
    "    r0, rH, K_M, c, d, gH, u, pL, pH, H_on, H_off, tau = p\n",
    "    pB  = pL + (pH - pL)*np.clip(q,0,1)\n",
    "    r_eff = r0 + rH*H\n",
    "    dM = (r_eff - c*pB)*M*(1 - M/K_M)\n",
    "    dH = gH*B*(1 - H) - d*H\n",
    "    dB = pB*M - u*H*B\n",
    "    qinf = q_inf_smooth(H, q, H_on, H_off, k=KQ)\n",
    "    dq  = (qinf - q)/tau\n",
    "    return [dM,dH,dB,dq]\n",
    "\n",
    "def simulate(ts, y0, p):\n",
    "    try:\n",
    "        sol = solve_ivp(lambda t,y: rhs_pf(t,y,p), (ts[0], ts[-1]), y0,\n",
    "                        t_eval=ts, rtol=1e-6, atol=1e-8, max_step=0.5)\n",
    "        if not sol.success:\n",
    "            T=len(ts); return np.vstack([np.full(T,np.nan)]*4)\n",
    "        return sol.y\n",
    "    except Exception:\n",
    "        T=len(ts); return np.vstack([np.full(T,np.nan)]*4)\n",
    "\n",
    "# ----------------- Parameter boxes -----------------\n",
    "LBg = np.array([0.05, 0.00, 0.4, 0.02, 0.01, 0.05, 0.2, 0.0, 0.5, 0.2, 0.60, 0.5])\n",
    "UBg = np.array([0.60, 0.20, 1.6, 0.25, 0.50, 2.00, 1.2, 0.8, 4.0, 0.8, 0.95, 24.0])\n",
    "x0g = np.array([0.30, 0.08, 1.0, 0.10, 0.12, 0.55, 0.65, 0.10, 2.2, 0.55, 0.85, 4.0])\n",
    "\n",
    "x0s, LBs, UBs = [], [], []\n",
    "for _ in subs:\n",
    "    x0s += [1.0, 0.0, 1.0]   # alpha_B, beta0_H, beta1_H\n",
    "    LBs += [0.1, -0.5, 0.1]\n",
    "    UBs += [5.0,  0.5,  2.0]\n",
    "\n",
    "x0 = np.concatenate([x0g, np.array(x0s, float)])\n",
    "LB = np.concatenate([LBg, np.array(LBs, float)])\n",
    "UB = np.concatenate([UBg, np.array(UBs, float)])\n",
    "\n",
    "def unpack(x):\n",
    "    gpar = x[:12]\n",
    "    triples = np.split(x[12:], len(subs))\n",
    "    return gpar, triples\n",
    "\n",
    "# ----------------- Fixed-length residuals + priors -----------------\n",
    "N_PRIORS = 3  # H_off, r_eff at H=0.8, u regularization\n",
    "total_len = sum(S[\"nB\"] + S[\"nH\"] for S in subs) + N_PRIORS\n",
    "\n",
    "def residuals(x):\n",
    "    gpar, triples = unpack(x)\n",
    "\n",
    "    # enforce H_off > H_on\n",
    "    if not (gpar[10] > gpar[9]):\n",
    "        return np.full(total_len, PENALTY, float)\n",
    "\n",
    "    res = []\n",
    "\n",
    "    # data residuals\n",
    "    for S, tr in zip(subs, triples):\n",
    "        alpha_B, beta0, beta1 = tr\n",
    "        ts = S[\"t\"]\n",
    "        H0 = float(np.clip(S[\"H0\"], 0, 1))\n",
    "        B0 = float(max(0.05, S[\"B0\"]))\n",
    "        M0 = 0.1\n",
    "        q0 = 1.0 if H0 < 0.5*(gpar[9] + gpar[10]) else 0.0\n",
    "        y0 = [M0, H0, B0, q0]\n",
    "\n",
    "        Y = simulate(ts, y0, gpar)\n",
    "        _, H, B, _ = Y\n",
    "\n",
    "        if np.any(~np.isfinite(H)) or np.any(~np.isfinite(B)):\n",
    "            res.append(np.full(S[\"nB\"], PENALTY))\n",
    "            res.append(np.full(S[\"nH\"], PENALTY))\n",
    "            continue\n",
    "\n",
    "        Bhat = alpha_B * B\n",
    "        Hhat = np.clip(beta0 + beta1*H, 0, 1)\n",
    "\n",
    "        b_res = (Bhat[S[\"maskB\"]] - S[\"B\"][S[\"maskB\"]])\n",
    "        h_res = (Hhat[S[\"maskH\"]] - S[\"H\"][S[\"maskH\"]])\n",
    "\n",
    "        b_res = np.where(np.isfinite(b_res), b_res, PENALTY)\n",
    "        h_res = np.where(np.isfinite(h_res), h_res, PENALTY)\n",
    "\n",
    "        res.append(b_res.astype(float))\n",
    "        res.append(h_res.astype(float))\n",
    "\n",
    "    # ---- Priors (3 numbers, fixed length) ----\n",
    "    # Indices: r0=0, rH=1, u=6, H_on=9, H_off=10\n",
    "    res_Hoff = (gpar[10] - H_OFF_TARGET) / (H_OFF_SD + 1e-9)\n",
    "    r_eff    = gpar[0] + gpar[1] * R_EFF_H_REF\n",
    "    res_reff = (r_eff - R_EFF_TARGET) / (R_EFF_SD + 1e-9)\n",
    "    res_u    = (gpar[6] - 0.6) / (U_SD + 1e-9)\n",
    "\n",
    "    res.append(np.array([res_Hoff, res_reff, res_u], float))\n",
    "\n",
    "    return np.concatenate(res)\n",
    "\n",
    "# ----------------- Fit -----------------\n",
    "fit = least_squares(\n",
    "    residuals, x0, bounds=(LB, UB),\n",
    "    verbose=2, max_nfev=900,\n",
    "    loss=\"soft_l1\", f_scale=1.0\n",
    ")\n",
    "gpar_hat, triples_hat = unpack(fit.x)\n",
    "\n",
    "param_names = [\"r0\",\"rH\",\"K_M\",\"c\",\"d\",\"g\",\"u\",\"p_low\",\"p_high\",\"H_on\",\"H_off\",\"tau_q\"]\n",
    "pd.Series(gpar_hat, index=param_names).to_csv(os.path.join(OUTDIR, \"fitted_global_params.csv\"))\n",
    "\n",
    "pd.DataFrame(\n",
    "    [{\"subject_id\": S[\"sid\"], \"alpha_B\": tr[0], \"beta0_H\": tr[1], \"beta1_H\": tr[2]}\n",
    "     for S,tr in zip(subs, triples_hat)]\n",
    ").to_csv(os.path.join(OUTDIR, \"fitted_subject_scales.csv\"), index=False)\n",
    "\n",
    "print(\"[info] Fitted global params:\", dict(zip(param_names, gpar_hat)))\n",
    "\n",
    "# ----------------- Quick diagnostics -----------------\n",
    "for S,tr in list(zip(subs, triples_hat))[:8]:\n",
    "    alpha_B, beta0, beta1 = tr\n",
    "    H0 = float(np.clip(S[\"H0\"], 0, 1))\n",
    "    B0 = float(max(0.05, S[\"B0\"]))\n",
    "    M0 = 0.1\n",
    "    q0 = 1.0 if H0 < 0.5*(gpar_hat[9] + gpar_hat[10]) else 0.0\n",
    "    y0 = [M0, H0, B0, q0]\n",
    "\n",
    "    def rhs_for_plot(t, y): return rhs_pf(t, y, gpar_hat)\n",
    "    try:\n",
    "        sol = solve_ivp(rhs_for_plot, (S[\"t\"][0], S[\"t\"][-1]), y0,\n",
    "                        t_eval=S[\"t\"], rtol=1e-6, atol=1e-8, max_step=0.5)\n",
    "        M,H,B,q = sol.y\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "    Bhat = alpha_B*B\n",
    "    Hhat = np.clip(beta0 + beta1*H, 0, 1)\n",
    "    mB, mH = S[\"maskB\"], S[\"maskH\"]\n",
    "\n",
    "    fig, ax = plt.subplots(2,1, figsize=(7,6), sharex=True)\n",
    "    ax[0].plot(S[\"t\"][mB], Bhat[mB], label=\"Model B (scaled)\")\n",
    "    ax[0].scatter(S[\"t\"][mB], S[\"B\"][mB], s=18, c=\"k\", label=\"Obs B (z)\")\n",
    "    ax[0].set_ylabel(\"B intensity (scaled)\"); ax[0].legend(); ax[0].grid(True, ls=\":\")\n",
    "\n",
    "    ax[1].plot(S[\"t\"][mH], Hhat[mH], label=\"Model H\")\n",
    "    ax[1].scatter(S[\"t\"][mH], S[\"H\"][mH], s=18, c=\"k\", label=\"H proxy\")\n",
    "    ax[1].axhline(gpar_hat[9], ls=\":\", c=\"gray\", label=\"H_on\")\n",
    "    ax[1].axhline(gpar_hat[10], ls=\"--\", c=\"gray\", label=\"H_off\")\n",
    "    ax[1].set_xlabel(\"time idx\"); ax[1].set_ylabel(\"H\"); ax[1].legend(); ax[1].grid(True, ls=\":\")\n",
    "\n",
    "    plt.tight_layout(); plt.savefig(os.path.join(OUTDIR, f\"diag_{S['sid']}.png\"), dpi=180); plt.close()\n",
    "\n",
    "print(\"✅ Done. Outputs in:\", OUTDIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704d054b-f845-4dce-a6b3-97e138fbae3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bifurcation_and_basins_pf.py\n",
    "# ------------------------------------------------------------\n",
    "# Uses the smooth-hysteresis model you just fitted to:\n",
    "#   (A) continue equilibria vs d and test stability (Jacobian eigs)\n",
    "#   (B) check if the baseline d lies in a bistable region\n",
    "#   (C) draw a basin-of-attraction map at baseline\n",
    "#   (D) (optional) repeat with weak positive feedback r_H\n",
    "#\n",
    "# Input:  mw_fit_out/fitted_global_params.csv  (from your smooth calibration)\n",
    "# Output: mw_bif_smooth/\n",
    "#   - branches.csv\n",
    "#   - bifurcation_H_vs_d.png\n",
    "#   - basins_heatmap.png\n",
    "#   - hysteresis_sweep.png\n",
    "#   - diagnosis.txt\n",
    "# (and *_pf.* counterparts if POS_FEEDBACK=True)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.optimize import root\n",
    "\n",
    "# ----------------- Config -----------------\n",
    "FIT_CSV       = \"mw_fit_out_pf/fitted_global_params.csv\"\n",
    "OUTDIR        = \"mw_bif_pf\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "# Smooth switch sharpness (same k you used in calibration; 30–60 works)\n",
    "KQ            = 40.0\n",
    "\n",
    "# Continuation range around baseline d (you can widen if needed)\n",
    "D_SPAN_FACTOR = (0.6, 1.5)      # explore from 0.6×d_fit to 1.5×d_fit\n",
    "N_D_POINTS    = 80\n",
    "\n",
    "# Basins grid at baseline\n",
    "H_GRID = np.linspace(0.2, 0.95, 17)\n",
    "Q_GRID = np.linspace(0.0, 1.0, 17)\n",
    "\n",
    "# Optional: add weak positive feedback r_H into microbe growth\n",
    "POS_FEEDBACK  = True    # <-- set True to test the r_H model\n",
    "R_H_VALUE     = 0.05     # h^-1 contribution to growth per unit H (small)\n",
    "\n",
    "# ----------------- Load fitted globals -----------------\n",
    "g = pd.read_csv(FIT_CSV, index_col=0).squeeze(\"columns\")\n",
    "# params (smooth model without PF): [r_max,K_M,c,d,g,u,p_low,p_high,H_on,H_off,tau_q]\n",
    "pars = np.array([\n",
    "    float(g.get(\"r_max\", 0.32)),\n",
    "    float(g.get(\"K_M\", 1.0)),\n",
    "    float(g.get(\"c\", 0.10)),\n",
    "    float(g.get(\"d\", 0.12)),\n",
    "    float(g.get(\"g\", 0.5)),\n",
    "    float(g.get(\"u\", 0.6)),\n",
    "    float(g.get(\"p_low\", 0.1)),\n",
    "    float(g.get(\"p_high\", 2.5)),\n",
    "    float(g.get(\"H_on\", 0.55)),\n",
    "    float(g.get(\"H_off\", 0.85)),   # you likely refit; read what’s in CSV\n",
    "    float(g.get(\"tau_q\", 4.0)),\n",
    "], float)\n",
    "\n",
    "# ----------------- Smooth hysteresis helpers -----------------\n",
    "def q_inf_smooth(H, q, H_on, H_off, k=KQ):\n",
    "    theta = (1.0 - q) * H_on + q * H_off\n",
    "    return 1.0 / (1.0 + np.exp(-k * (H - theta)))\n",
    "\n",
    "def rhs_smooth(y, p, d_override=None):\n",
    "    \"\"\"No positive feedback (baseline smooth model).\"\"\"\n",
    "    M, H, B, q = y\n",
    "    r_max,K_M,c,d,gH,u,pL,pH,H_on,H_off,tau = p.copy()\n",
    "    if d_override is not None: d = d_override\n",
    "    pB = pL + (pH - pL)*np.clip(q,0,1)\n",
    "    dM = (r_max - c*pB)*M*(1 - M/K_M)\n",
    "    dH = gH*B*(1 - H) - d*H\n",
    "    dB = pB*M - u*H*B\n",
    "    qinf = q_inf_smooth(H, q, H_on, H_off, k=KQ)\n",
    "    dq   = (qinf - q)/tau\n",
    "    return np.array([dM,dH,dB,dq], float)\n",
    "\n",
    "def rhs_pf(y, p, d_override=None, rH=R_H_VALUE):\n",
    "    \"\"\"With weak positive feedback r_H: r_eff = r_max + rH*H.\"\"\"\n",
    "    M, H, B, q = y\n",
    "    r_max,K_M,c,d,gH,u,pL,pH,H_on,H_off,tau = p.copy()\n",
    "    if d_override is not None: d = d_override\n",
    "    pB = pL + (pH - pL)*np.clip(q,0,1)\n",
    "    r_eff = r_max + rH*H\n",
    "    dM = (r_eff - c*pB)*M*(1 - M/K_M)\n",
    "    dH = gH*B*(1 - H) - d*H\n",
    "    dB = pB*M - u*H*B\n",
    "    qinf = q_inf_smooth(H, q, H_on, H_off, k=KQ)\n",
    "    dq   = (qinf - q)/tau\n",
    "    return np.array([dM,dH,dB,dq], float)\n",
    "\n",
    "# choose which RHS to use\n",
    "RHS = rhs_pf if POS_FEEDBACK else rhs_smooth\n",
    "\n",
    "# ----------------- Utilities -----------------\n",
    "def jacobian_fd(fun, y, p, d_val=None, eps=1e-7):\n",
    "    f0 = fun(y, p, d_val)\n",
    "    J = np.zeros((4,4))\n",
    "    for i in range(4):\n",
    "        y2 = y.copy(); y2[i] += eps\n",
    "        J[:,i] = (fun(y2, p, d_val) - f0)/eps\n",
    "    return J\n",
    "\n",
    "def find_equilibrium(fun, p, d_val, guess):\n",
    "    sol = root(lambda yy: fun(yy, p, d_val), guess, method=\"hybr\")\n",
    "    if not sol.success:\n",
    "        return guess, False\n",
    "    y = sol.x\n",
    "    # project to physical range\n",
    "    y = np.array([\n",
    "        max(0.0, y[0]),\n",
    "        np.clip(y[1], 0.0, 1.2),\n",
    "        max(0.0, y[2]),\n",
    "        np.clip(y[3], 0.0, 1.2),\n",
    "    ], float)\n",
    "    if not np.all(np.isfinite(y)):\n",
    "        return guess, False\n",
    "    return y, True\n",
    "\n",
    "def relax_to_ss(fun, p, d_val, y0, T=240):\n",
    "    sol = solve_ivp(lambda t,yy: fun(yy, p, d_val), (0,T), y0,\n",
    "                    t_eval=np.linspace(0,T,900), rtol=1e-6, atol=1e-8, max_step=0.5)\n",
    "    return sol.y[:,-1], sol\n",
    "\n",
    "# ----------------- (A) Continuation in d -----------------\n",
    "d_fit = float(pars[3])\n",
    "d_vals = np.linspace(d_fit*D_SPAN_FACTOR[0], d_fit*D_SPAN_FACTOR[1], N_D_POINTS)\n",
    "\n",
    "seeds = [\n",
    "    np.array([0.2, 0.2, 0.05, 1.0]),   # low-H / q≈1\n",
    "    np.array([0.2, 0.9, 0.10, 0.0]),   # high-H / q≈0\n",
    "    np.array([0.6, 0.6, 0.20, 0.5]),   # mid\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for d in d_vals:\n",
    "    for wi, y0 in enumerate(seeds):\n",
    "        y_eq, ok = find_equilibrium(RHS, pars, d, y0)\n",
    "        if ok:\n",
    "            J = jacobian_fd(RHS, y_eq, pars, d_val=d)\n",
    "            eigs = np.linalg.eigvals(J)\n",
    "            stable = bool(np.max(np.real(eigs)) < 0)\n",
    "            rows.append({\"d\": d, \"H\": float(y_eq[1]), \"q\": float(y_eq[3]),\n",
    "                         \"seed\": wi, \"stable\": stable})\n",
    "branches = pd.DataFrame(rows)\n",
    "branches.to_csv(os.path.join(OUTDIR, \"branches.csv\"), index=False)\n",
    "\n",
    "# plot branches\n",
    "plt.figure(figsize=(7.2,5.2))\n",
    "for wi in sorted(branches[\"seed\"].unique()):\n",
    "    sub = branches[branches[\"seed\"]==wi]\n",
    "    plt.plot(sub[\"d\"], sub[\"H\"], \".\", ms=3, alpha=0.7, label=f\"seed{wi}\")\n",
    "for st, mk in [(True, \"o\"), (False, \"x\")]:\n",
    "    sub = branches[branches[\"stable\"]==st]\n",
    "    plt.scatter(sub[\"d\"], sub[\"H\"], s=22, marker=mk, alpha=0.6,\n",
    "                label=(\"stable\" if st else \"unstable\"))\n",
    "plt.axvline(d_fit, ls=\"--\", c=\"gray\", label=\"baseline d\")\n",
    "plt.xlabel(\"d (1/h)\"); plt.ylabel(\"H* at equilibrium\")\n",
    "plt.legend(); plt.grid(True, ls=\":\", alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTDIR, \"bifurcation_H_vs_d.png\"), dpi=180)\n",
    "plt.close()\n",
    "\n",
    "# ----------------- (B) Is baseline d inside a bistable band? -----------------\n",
    "near = branches[np.isclose(branches[\"d\"], d_fit, atol=1e-3)]\n",
    "# count distinct stable points (tolerance to avoid duplicate seeds converging to same eq)\n",
    "if not near.empty:\n",
    "    Hs = np.sort(near.loc[near[\"stable\"], \"H\"].values)\n",
    "    distinct = 0\n",
    "    if Hs.size:\n",
    "        distinct = 1\n",
    "        for i in range(1, len(Hs)):\n",
    "            if abs(Hs[i] - Hs[i-1]) > 1e-3:  # distinct H*\n",
    "                distinct += 1\n",
    "else:\n",
    "    distinct = 0\n",
    "bistable = bool(distinct >= 2)\n",
    "\n",
    "# ----------------- (C) Basin-of-attraction map at baseline -----------------\n",
    "Z = np.zeros((len(H_GRID), len(Q_GRID)))\n",
    "for i, H0 in enumerate(H_GRID):\n",
    "    for j, q0 in enumerate(Q_GRID):\n",
    "        y0 = np.array([0.2, H0, 0.1, q0], float)\n",
    "        yss, _ = relax_to_ss(RHS, pars, d_fit, y0, T=300)\n",
    "        Z[i, j] = yss[1]\n",
    "\n",
    "plt.figure(figsize=(6.6,5.4))\n",
    "plt.imshow(Z, origin=\"lower\",\n",
    "           extent=[Q_GRID[0], Q_GRID[-1], H_GRID[0], H_GRID[-1]],\n",
    "           aspect=\"auto\", vmin=0.5, vmax=1.0, cmap=\"viridis\")\n",
    "plt.colorbar(label=\"Final H (steady)\")\n",
    "plt.xlabel(\"initial q\"); plt.ylabel(\"initial H\")\n",
    "plt.title(f\"Basins at baseline d={d_fit:.3f}\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTDIR, \"basins_heatmap.png\"), dpi=180)\n",
    "plt.close()\n",
    "\n",
    "# ----------------- (D) Dynamic hysteresis sweep (for comparison) -----------------\n",
    "def sweep(fun, p, H0, q0, d_lo, d_hi, T=160):\n",
    "    y = np.array([0.1, H0, 0.1, q0], float)\n",
    "    grid = np.linspace(d_lo, d_hi, 28)\n",
    "    fwd, bwd = [], []\n",
    "    for d in grid:\n",
    "        y, _ = relax_to_ss(fun, p, d, y, T=T)\n",
    "        fwd.append((d, *y))\n",
    "    for d in grid[::-1]:\n",
    "        y, _ = relax_to_ss(fun, p, d, y, T=T)\n",
    "        bwd.append((d, *y))\n",
    "    return pd.DataFrame(fwd, columns=[\"d\",\"M\",\"H\",\"B\",\"q\"]), \\\n",
    "           pd.DataFrame(bwd, columns=[\"d\",\"M\",\"H\",\"B\",\"q\"])\n",
    "\n",
    "fwd, bwd = sweep(RHS, pars, H0=0.8, q0=0.0,\n",
    "                 d_lo=d_fit*D_SPAN_FACTOR[0], d_hi=d_fit*D_SPAN_FACTOR[1], T=180)\n",
    "\n",
    "plt.figure(figsize=(7.6,4.2))\n",
    "plt.plot(fwd[\"d\"], fwd[\"H\"], \"-o\", ms=3, label=\"forward (d↑)\")\n",
    "plt.plot(bwd[\"d\"], bwd[\"H\"], \"-s\", ms=3, label=\"backward (d↓)\")\n",
    "plt.axhline(pars[8], ls=\":\", c=\"gray\", label=\"H_on\")\n",
    "plt.axhline(pars[9], ls=\"--\", c=\"gray\", label=\"H_off\")\n",
    "plt.xlabel(\"d (1/h)\"); plt.ylabel(\"H* (dynamic SS)\"); plt.legend()\n",
    "plt.grid(True, ls=\":\", alpha=0.6); plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTDIR, \"hysteresis_sweep.png\"), dpi=180)\n",
    "plt.close()\n",
    "\n",
    "# ----------------- Report -----------------\n",
    "with open(os.path.join(OUTDIR, \"diagnosis.txt\"), \"w\") as f:\n",
    "    f.write(f\"Baseline d = {d_fit:.5f}\\n\")\n",
    "    f.write(f\"Distinct stable equilibria at baseline (by H*): {distinct}\\n\")\n",
    "    f.write(f\"Bistable at baseline? {'YES' if bistable else 'NO'}\\n\")\n",
    "    f.write(f\"Model used: {'smooth + positive feedback (r_H={R_H_VALUE})' if POS_FEEDBACK else 'smooth, no PF'}\\n\")\n",
    "\n",
    "print(\"Saved results to:\", OUTDIR)\n",
    "print(\"Bistable at baseline? \", \"YES\" if bistable else \"NO\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426e690f-3d14-47ef-93a1-b6d2f43978ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_bistable_regions.py\n",
    "# Scans a small neighborhood around your current fit to find parameter sets\n",
    "# that yield TWO distinct stable equilibria at the baseline d (true bistability).\n",
    "# Uses the smooth hysteretic switch (same as your current model) and optional PF.\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "from scipy.optimize import root\n",
    "from numpy.linalg import eigvals\n",
    "\n",
    "FIT = \"mw_fit_out_pf/fitted_global_params.csv\"   # or mw_fit_out/... if you're using the smooth-no-PF fit\n",
    "OUT = \"mw_scan_bistability.csv\"\n",
    "\n",
    "# ----- Model toggles -----\n",
    "USE_PF = False       # True: dot M = (r0 + rH*H - c*pB) M (1 - M/KM); False: rH ignored, use r_max\n",
    "KQ     = 40.0       # smooth switch steepness\n",
    "\n",
    "g = pd.read_csv(FIT, index_col=0).squeeze(\"columns\")\n",
    "\n",
    "if USE_PF:\n",
    "    # params: [r0, rH, K_M, c, d, g, u, p_low, p_high, H_on, H_off, tau_q]\n",
    "    pars0 = np.array([\n",
    "        float(g.get(\"r0\", g.get(\"r_max\", 0.30))),\n",
    "        float(g.get(\"rH\", 0.08)),\n",
    "        float(g.get(\"K_M\", 1.0)),\n",
    "        float(g.get(\"c\", 0.10)),\n",
    "        float(g.get(\"d\", 0.12)),\n",
    "        float(g.get(\"g\", 0.55)),\n",
    "        float(g.get(\"u\", 0.60)),\n",
    "        float(g.get(\"p_low\", 0.10)),\n",
    "        float(g.get(\"p_high\", 2.20)),\n",
    "        float(g.get(\"H_on\", 0.55)),\n",
    "        float(g.get(\"H_off\", 0.85)),\n",
    "        float(g.get(\"tau_q\", 4.0)),\n",
    "    ], float)\n",
    "else:\n",
    "    # fall back to smooth-no-PF; map to the same slots (rH=0)\n",
    "    pars0 = np.array([\n",
    "        float(g.get(\"r_max\", 0.35)),\n",
    "        0.0,\n",
    "        float(g.get(\"K_M\", 1.0)),\n",
    "        float(g.get(\"c\", 0.10)),\n",
    "        float(g.get(\"d\", 0.12)),\n",
    "        float(g.get(\"g\", 0.55)),\n",
    "        float(g.get(\"u\", 0.60)),\n",
    "        float(g.get(\"p_low\", 0.10)),\n",
    "        float(g.get(\"p_high\", 2.20)),\n",
    "        float(g.get(\"H_on\", 0.55)),\n",
    "        float(g.get(\"H_off\", 0.85)),\n",
    "        float(g.get(\"tau_q\", 4.0)),\n",
    "    ], float)\n",
    "\n",
    "def q_inf_smooth(H,q,H_on,H_off,k=KQ):\n",
    "    theta = (1-q)*H_on + q*H_off\n",
    "    return 1.0/(1.0 + np.exp(-k*(H - theta)))\n",
    "\n",
    "def rhs(y, p, d_override=None):\n",
    "    M,H,B,q = y\n",
    "    r0,rH,K_M,c,d,gH,u,pL,pH,H_on,H_off,tau = p.copy()\n",
    "    if d_override is not None: d = d_override\n",
    "    pB = pL + (pH - pL)*np.clip(q,0,1)\n",
    "    r_eff = (r0 + rH*H)  # rH may be 0 if USE_PF=False\n",
    "    dM = (r_eff - c*pB)*M*(1 - M/K_M)\n",
    "    dH = gH*B*(1 - H) - d*H\n",
    "    dB = pB*M - u*H*B\n",
    "    qinf = q_inf_smooth(H,q,H_on,H_off)\n",
    "    dq   = (qinf - q)/tau\n",
    "    return np.array([dM,dH,dB,dq], float)\n",
    "\n",
    "def jac_fd(fun,y,p,dval,eps=1e-7):\n",
    "    f0=fun(y,p,dval); J=np.zeros((4,4))\n",
    "    for i in range(4):\n",
    "        y2=y.copy(); y2[i]+=eps\n",
    "        J[:,i]=(fun(y2,p,dval)-f0)/eps\n",
    "    return J\n",
    "\n",
    "def find_eq(p, dval, guess):\n",
    "    sol = root(lambda yy: rhs(yy,p,dval), guess, method=\"hybr\")\n",
    "    if not sol.success: return None, False\n",
    "    y = sol.x\n",
    "    y = np.array([max(0,y[0]), np.clip(y[1],0,1.2), max(0,y[2]), np.clip(y[3],0,1.2)], float)\n",
    "    if not np.all(np.isfinite(y)): return None, False\n",
    "    return y, True\n",
    "\n",
    "# ---- Scan hyper-rectangle around the fit (tight first; enlarge if empty)\n",
    "rH_grid    = [pars0[1]] if not USE_PF else np.linspace(max(0,pars0[1]-0.06), pars0[1]+0.06, 5)\n",
    "u_grid     = np.linspace(max(0.3,pars0[6]-0.2), pars0[6]+0.2, 7)\n",
    "Hoff_grid  = np.linspace(max(0.75,pars0[10]-0.08), min(0.95,pars0[10]+0.04), 7)\n",
    "pH_grid    = np.linspace(max(1.2,pars0[8]-0.7), pars0[8]+0.7, 7)\n",
    "c_grid     = np.linspace(max(0.05,pars0[3]-0.05), pars0[3]+0.05, 5)\n",
    "\n",
    "d_fit = float(pars0[4])\n",
    "seeds = [\n",
    "    np.array([0.2, 0.25, 0.05, 1.0]),\n",
    "    np.array([0.2, 0.90, 0.10, 0.0]),\n",
    "    np.array([0.6, 0.60, 0.20, 0.5]),\n",
    "]\n",
    "\n",
    "rows=[]\n",
    "for rH in rH_grid:\n",
    "    for u in u_grid:\n",
    "        for H_off in Hoff_grid:\n",
    "            for pH in pH_grid:\n",
    "                for c in c_grid:\n",
    "                    p = pars0.copy()\n",
    "                    p[1]=rH; p[6]=u; p[10]=H_off; p[8]=pH; p[3]=c\n",
    "                    H_stables=[]\n",
    "                    for y0 in seeds:\n",
    "                        y, ok = find_eq(p, d_fit, y0)\n",
    "                        if not ok: continue\n",
    "                        J = jac_fd(rhs, y, p, d_fit)\n",
    "                        st = (np.max(np.real(eigvals(J)))<0)\n",
    "                        if st: H_stables.append(float(y[1]))\n",
    "                    H_stables = np.array(sorted(H_stables))\n",
    "                    # count distinct stable points by H* separation\n",
    "                    distinct=0\n",
    "                    if H_stables.size>0:\n",
    "                        distinct=1\n",
    "                        for i in range(1,len(H_stables)):\n",
    "                            if abs(H_stables[i]-H_stables[i-1])>1e-3:\n",
    "                                distinct+=1\n",
    "                    bistable = (distinct>=2)\n",
    "                    rows.append({\n",
    "                        \"rH\":rH, \"u\":u, \"H_off\":H_off, \"p_high\":pH, \"c\":c,\n",
    "                        \"distinct_stable\":distinct, \"bistable\":bistable\n",
    "                    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(OUT, index=False)\n",
    "print(\"Saved grid results ->\", OUT)\n",
    "print(\"Bistable combos at baseline d:\", int(df[\"bistable\"].sum()))\n",
    "if df[\"bistable\"].any():\n",
    "    print(df[df[\"bistable\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b36dc6-4780-4fb5-b519-5b67514e7a6a",
   "metadata": {},
   "source": [
    "## Hill host benefit + smooth hysteresis + weak positive feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207f6774-1f7b-4cd4-94bd-72dacac1e16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate_hysteresis_from_scored_hill_pf.py\n",
    "# -------------------------------------------------------------------\n",
    "# Fits a Hill nonlinearity in host benefit, smooth hysteresis memory,\n",
    "# and weak host->microbe positive feedback to your scored time series.\n",
    "# Fixed-length residuals; gentle priors to avoid monostable extremes.\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "# ----------------- Paths & basic config -----------------\n",
    "INPATH = \"timeseries/combined_scfas_table_scored.csv\"\n",
    "OUTDIR = \"mw_fit_out_hill_pf\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "H_COL_CANDIDATES = [\"H_proxy_meta_smooth\", \"H_proxy_meta\"]\n",
    "SCFA_COLS = [\"butyrate\"]   # you can add more (will average z-scores)\n",
    "MIN_ROWS = 4\n",
    "KQ = 40.0                  # smooth switch steepness\n",
    "PENALTY = 1e3              # finite penalty for failed integration\n",
    "\n",
    "# ---- Priors (soft, data-friendly) ----\n",
    "H_OFF_TARGET = 0.85; H_OFF_SD = 0.05\n",
    "R_EFF_H_REF = 0.8;   R_EFF_SD = 0.05\n",
    "U_TARGET = 0.6;      U_SD = 0.25\n",
    "K_B_TARGET = 0.20;   K_B_SD = 0.08   # Hill half-saturation (in \"B\" units)\n",
    "N_PRIORS = 4                           # total pseudo-residuals\n",
    "\n",
    "# ----------------- Load data -----------------\n",
    "df = pd.read_csv(INPATH)\n",
    "if not {\"subject_id\",\"sample_id\"}.issubset(df.columns):\n",
    "    raise ValueError(\"CSV must contain 'subject_id' and 'sample_id'.\")\n",
    "\n",
    "Hcol = next((c for c in H_COL_CANDIDATES if c in df.columns), None)\n",
    "if Hcol is None:\n",
    "    raise ValueError(\"Need H_proxy_meta_smooth or H_proxy_meta in the CSV.\")\n",
    "\n",
    "for c in SCFA_COLS:\n",
    "    if c not in df.columns:\n",
    "        raise ValueError(f\"Missing SCFA column '{c}' in CSV.\")\n",
    "\n",
    "keep = [\"subject_id\",\"sample_id\", Hcol] + SCFA_COLS\n",
    "df = df[keep].dropna(subset=[\"subject_id\",\"sample_id\"]).copy()\n",
    "df[\"t_idx\"] = df.groupby(\"subject_id\").cumcount().astype(float)\n",
    "\n",
    "# robust (MAD) z-scoring per subject for SCFA intensities\n",
    "def robust_z(series: pd.Series) -> pd.Series:\n",
    "    x = series.astype(float).to_numpy()\n",
    "    m = np.isfinite(x)\n",
    "    if m.sum() == 0:\n",
    "        return pd.Series(np.zeros_like(x), index=series.index)\n",
    "    xm = x[m]\n",
    "    med = np.median(xm)\n",
    "    mad = np.median(np.abs(xm - med))\n",
    "    if mad < 1e-9:\n",
    "        q75, q25 = np.percentile(xm, [75, 25]); iqr = q75 - q25\n",
    "        scale = iqr if iqr > 1e-9 else (np.std(xm) + 1e-9)\n",
    "    else:\n",
    "        scale = mad\n",
    "    return pd.Series((x - med) / (scale + 1e-9), index=series.index)\n",
    "\n",
    "for c in SCFA_COLS:\n",
    "    df[c+\"_z\"] = df.groupby(\"subject_id\")[c].transform(robust_z)\n",
    "\n",
    "if len(SCFA_COLS) == 1:\n",
    "    df[\"B_obs\"] = df[SCFA_COLS[0] + \"_z\"]\n",
    "else:\n",
    "    df[\"B_obs\"] = df[[c+\"_z\" for c in SCFA_COLS]].mean(axis=1)\n",
    "\n",
    "df[\"H_obs\"] = df[Hcol].clip(0,1)\n",
    "\n",
    "# ----------------- Build per-subject series (fixed masks) -----------------\n",
    "def first_finite(a, default):\n",
    "    a = np.asarray(a, float)\n",
    "    idx = np.where(np.isfinite(a))[0]\n",
    "    return float(a[idx[0]]) if len(idx) else float(default)\n",
    "\n",
    "subs = []\n",
    "for sid, sub in df.groupby(\"subject_id\"):\n",
    "    sub = sub.sort_values(\"t_idx\").copy()\n",
    "    if len(sub) < MIN_ROWS:\n",
    "        continue\n",
    "    t = sub[\"t_idx\"].values.astype(float)\n",
    "    B = sub[\"B_obs\"].values.astype(float)\n",
    "    H = sub[\"H_obs\"].values.astype(float)\n",
    "    mB = np.isfinite(B)\n",
    "    mH = np.isfinite(H)\n",
    "    if mB.sum() < 3 or mH.sum() < 3:\n",
    "        continue\n",
    "    subs.append({\n",
    "        \"sid\": sid,\n",
    "        \"t\": t,\n",
    "        \"B\": B, \"H\": H,\n",
    "        \"maskB\": mB, \"maskH\": mH,\n",
    "        \"nB\": int(mB.sum()), \"nH\": int(mH.sum()),\n",
    "        \"H0\": float(np.clip(first_finite(H, 0.6), 0, 1)),\n",
    "        \"B0\": float(max(0.05, first_finite(B, 0.1))),\n",
    "    })\n",
    "\n",
    "if not subs:\n",
    "    raise RuntimeError(\"No subject passed the minimal data filters (need ≥4 rows, ≥3 finite B & H).\")\n",
    "\n",
    "print(f\"[info] Fitting {len(subs)} subjects...\")\n",
    "for S in subs[:10]:\n",
    "    print(f\"  - {S['sid']}: B={S['nB']} H={S['nH']} (of {len(S['t'])})\")\n",
    "if len(subs) > 10: print(\"  ...\")\n",
    "\n",
    "# ----------------- Model: Hill host benefit + smooth hysteresis + PF -----------------\n",
    "# y = [M, H, B, q]\n",
    "# global params p = [r0, rH, K_M, c, d, g, u, p_low, p_high, H_on, H_off, tau_q, K_B]\n",
    "NAMES = [\"r0\",\"rH\",\"K_M\",\"c\",\"d\",\"g\",\"u\",\"p_low\",\"p_high\",\"H_on\",\"H_off\",\"tau_q\",\"K_B\"]\n",
    "\n",
    "def q_inf_smooth(H, q, H_on, H_off, k=KQ):\n",
    "    theta = (1.0 - q)*H_on + q*H_off\n",
    "    return 1.0 / (1.0 + np.exp(-k * (H - theta)))\n",
    "\n",
    "def dH_term_hill(B, H, gH, d, K_B, n=2):\n",
    "    # Hill benefit in B (monotone, saturating), multiplied by (1-H)\n",
    "    ben = gH * (B**n / (K_B**n + B**n)) * (1.0 - H)\n",
    "    return ben - d*H\n",
    "\n",
    "def rhs_hill_pf(t, y, p):\n",
    "    M,H,B,q = y\n",
    "    r0,rH,K_M,c,d,gH,u,pL,pH,H_on,H_off,tau,K_B = p\n",
    "    pB = pL + (pH - pL)*np.clip(q,0,1)\n",
    "    r_eff = r0 + rH*H\n",
    "    dM = (r_eff - c*pB)*M*(1 - M/K_M)\n",
    "    dH = dH_term_hill(B, H, gH, d, K_B, n=2)\n",
    "    dB = pB*M - u*H*B\n",
    "    qinf = q_inf_smooth(H, q, H_on, H_off, k=KQ)\n",
    "    dq   = (qinf - q)/tau\n",
    "    return [dM,dH,dB,dq]\n",
    "\n",
    "def simulate(ts, y0, p):\n",
    "    try:\n",
    "        sol = solve_ivp(lambda t,z: rhs_hill_pf(t,z,p),\n",
    "                        (ts[0], ts[-1]), y0, t_eval=ts,\n",
    "                        rtol=1e-6, atol=1e-8, max_step=0.5)\n",
    "        if not sol.success:\n",
    "            T=len(ts); return np.vstack([np.full(T,np.nan)]*4)\n",
    "        return sol.y\n",
    "    except Exception:\n",
    "        T=len(ts); return np.vstack([np.full(T,np.nan)]*4)\n",
    "\n",
    "# ----------------- Parameter boxes & initials -----------------\n",
    "LBg = np.array([0.05, 0.00, 0.4, 0.02, 0.01, 0.05, 0.15, 0.0, 0.8, 0.2, 0.70, 0.5, 0.05])\n",
    "UBg = np.array([0.60, 0.25, 1.8, 0.30, 0.60, 2.50, 1.20, 0.8, 4.0, 0.9,  0.95, 24.0, 0.40])\n",
    "x0g = np.array([0.30, 0.08, 1.0, 0.10, 0.12, 0.55, 0.60, 0.10, 2.2, 0.55, 0.85, 4.0, 0.20])\n",
    "\n",
    "# Optional per-subject linear observation maps (often ~identity; leave in for flexibility)\n",
    "x0s, LBs, UBs = [], [], []\n",
    "for _ in subs:\n",
    "    x0s += [1.0, 0.0, 1.0]  # alpha_B, beta0_H, beta1_H\n",
    "    LBs += [0.1, -0.5, 0.1]\n",
    "    UBs += [5.0,  0.5,  2.0]\n",
    "\n",
    "x0 = np.concatenate([x0g, np.array(x0s, float)])\n",
    "LB = np.concatenate([LBg, np.array(LBs, float)])\n",
    "UB = np.concatenate([UBg, np.array(UBs, float)])\n",
    "\n",
    "def unpack(x):\n",
    "    gpar = x[:len(NAMES)]\n",
    "    triples = np.split(x[len(NAMES):], len(subs))\n",
    "    return gpar, triples\n",
    "\n",
    "# Fixed-length residual accounting\n",
    "TOTLEN = sum(S[\"nB\"] + S[\"nH\"] for S in subs) + N_PRIORS\n",
    "\n",
    "def residuals(x):\n",
    "    gpar, triples = unpack(x)\n",
    "    # enforce H_off > H_on; K_B > small\n",
    "    if not (gpar[10] > gpar[9]) or (gpar[12] <= 0.02):\n",
    "        return np.full(TOTLEN, PENALTY, float)\n",
    "\n",
    "    res = []\n",
    "    for S, tr in zip(subs, triples):\n",
    "        alpha_B, beta0, beta1 = tr\n",
    "        ts = S[\"t\"]\n",
    "        H0 = float(np.clip(S[\"H0\"], 0, 1))\n",
    "        B0 = float(max(0.05, S[\"B0\"]))\n",
    "        M0 = 0.1\n",
    "        q0 = 1.0 if H0 < 0.5*(gpar[9]+gpar[10]) else 0.0\n",
    "        y0 = [M0, H0, B0, q0]\n",
    "        Y = simulate(ts, y0, gpar)\n",
    "        _, Hm, Bm, _ = Y\n",
    "\n",
    "        if np.any(~np.isfinite(Hm)) or np.any(~np.isfinite(Bm)):\n",
    "            res += [np.full(S[\"nB\"], PENALTY), np.full(S[\"nH\"], PENALTY)]\n",
    "            continue\n",
    "\n",
    "        Bhat = alpha_B*Bm\n",
    "        Hhat = np.clip(beta0 + beta1*Hm, 0, 1)\n",
    "\n",
    "        b = (Bhat[S[\"maskB\"]] - S[\"B\"][S[\"maskB\"]])\n",
    "        h = (Hhat[S[\"maskH\"]] - S[\"H\"][S[\"maskH\"]])\n",
    "        b = np.where(np.isfinite(b), b, PENALTY)\n",
    "        h = np.where(np.isfinite(h), h, PENALTY)\n",
    "        res += [b.astype(float), h.astype(float)]\n",
    "\n",
    "    # --- Priors (4 scalars) ---\n",
    "    r0, rH, u = gpar[0], gpar[1], gpar[6]\n",
    "    H_on, H_off, tau, K_B = gpar[9], gpar[10], gpar[11], gpar[12]\n",
    "    # 1) H_off prior\n",
    "    rHoff = (H_off - H_OFF_TARGET) / (H_OFF_SD + 1e-9)\n",
    "    # 2) effective growth at H=0.8 ~ target (keeps r0+rH*H in a plausible range)\n",
    "    r_eff = r0 + rH * R_EFF_H_REF\n",
    "    rReff = (r_eff - 0.35) / (R_EFF_SD + 1e-9)\n",
    "    # 3) uptake u regularization (wide)\n",
    "    rU = (u - U_TARGET) / (U_SD + 1e-9)\n",
    "    # 4) Hill K_B prior (keeps half-sat in a plausible range for scaled B)\n",
    "    rKB = (K_B - K_B_TARGET) / (K_B_SD + 1e-9)\n",
    "    res.append(np.array([rHoff, rReff, rU, rKB], float))\n",
    "\n",
    "    return np.concatenate(res)\n",
    "\n",
    "fit = least_squares(residuals, x0, bounds=(LB, UB),\n",
    "                    verbose=2, max_nfev=900, loss=\"soft_l1\", f_scale=1.0)\n",
    "\n",
    "gpar_hat, triples_hat = unpack(fit.x)\n",
    "pd.Series(gpar_hat, index=NAMES).to_csv(os.path.join(OUTDIR, \"fitted_global_params.csv\"), header=False)\n",
    "pd.DataFrame(\n",
    "    [{\"subject_id\": S[\"sid\"], \"alpha_B\": tr[0], \"beta0_H\": tr[1], \"beta1_H\": tr[2]}\n",
    "     for S,tr in zip(subs, triples_hat)]\n",
    ").to_csv(os.path.join(OUTDIR, \"fitted_subject_scales.csv\"), index=False)\n",
    "\n",
    "print(\"[info] Fitted globals:\", dict(zip(NAMES, gpar_hat)))\n",
    "\n",
    "# quick diagnostics (first few)\n",
    "for S,tr in list(zip(subs, triples_hat))[:8]:\n",
    "    alpha_B, beta0, beta1 = tr\n",
    "    ts = S[\"t\"]\n",
    "    H0 = float(np.clip(S[\"H0\"], 0, 1))\n",
    "    B0 = float(max(0.05, S[\"B0\"]))\n",
    "    M0 = 0.1\n",
    "    q0 = 1.0 if H0 < 0.5*(gpar_hat[9]+gpar_hat[10]) else 0.0\n",
    "    y0 = [M0, H0, B0, q0]\n",
    "    sol = solve_ivp(lambda t,z: rhs_hill_pf(t,z,gpar_hat),\n",
    "                    (ts[0], ts[-1]), y0, t_eval=ts,\n",
    "                    rtol=1e-6, atol=1e-8, max_step=0.5)\n",
    "    M,H,B,q = sol.y\n",
    "    Bhat = alpha_B*B\n",
    "    Hhat = np.clip(beta0 + beta1*H, 0, 1)\n",
    "    mB, mH = S[\"maskB\"], S[\"maskH\"]\n",
    "\n",
    "    fig, ax = plt.subplots(2,1, figsize=(7,6), sharex=True)\n",
    "    ax[0].plot(ts[mB], Bhat[mB], label=\"Model B (scaled)\")\n",
    "    ax[0].scatter(ts[mB], S[\"B\"][mB], s=18, c=\"k\", label=\"Obs B (z)\")\n",
    "    ax[0].legend(); ax[0].grid(True, ls=\":\")\n",
    "\n",
    "    ax[1].plot(ts[mH], Hhat[mH], label=\"Model H\")\n",
    "    ax[1].scatter(ts[mH], S[\"H\"][mH], s=18, c=\"k\", label=\"H proxy\")\n",
    "    ax[1].axhline(gpar_hat[9], ls=\":\", c=\"gray\", label=\"H_on\")\n",
    "    ax[1].axhline(gpar_hat[10], ls=\"--\", c=\"gray\", label=\"H_off\")\n",
    "    ax[1].legend(); ax[1].grid(True, ls=\":\")\n",
    "    ax[1].set_xlabel(\"time\"); ax[0].set_ylabel(\"B\"); ax[1].set_ylabel(\"H\")\n",
    "    plt.tight_layout(); plt.savefig(os.path.join(OUTDIR, f\"diag_{S['sid']}.png\"), dpi=180); plt.close()\n",
    "\n",
    "print(\"✅ Done. Outputs in:\", OUTDIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f799080b-a653-4c92-acee-b6f08a76f8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bifurcation_and_basins_hill.py\n",
    "# ------------------------------------------------------------\n",
    "# Continuation in d; stability via Jacobian eigs; basins at baseline\n",
    "# for the Hill + smooth hysteresis + PF model fitted above.\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.optimize import root\n",
    "\n",
    "FIT = \"mw_fit_out_hill_pf/fitted_global_params.csv\"\n",
    "OUT = \"mw_bif_hill\"; os.makedirs(OUT, exist_ok=True)\n",
    "\n",
    "KQ = 40.0\n",
    "g = pd.read_csv(FIT, index_col=0, header=None).squeeze(\"columns\")\n",
    "# p = [r0,rH,K_M,c,d,g,u,p_low,p_high,H_on,H_off,tau_q,K_B]\n",
    "p = np.array([float(g[k]) for k in g.index.values], float)\n",
    "d_fit = float(p[4])\n",
    "\n",
    "def q_inf(H,q,H_on,H_off,k=KQ):\n",
    "    th = (1-q)*H_on + q*H_off\n",
    "    return 1.0/(1.0 + np.exp(-k*(H - th)))\n",
    "\n",
    "def dH_hill(B,H,gH,d,K_B,n=2):\n",
    "    return gH*(B**n/(K_B**n + B**n))*(1-H) - d*H\n",
    "\n",
    "def rhs(y, pvec, d_override=None):\n",
    "    M,H,B,q = y\n",
    "    r0,rH,K_M,c,d,gH,u,pL,pH,H_on,H_off,tau,K_B = pvec.copy()\n",
    "    if d_override is not None: d = d_override\n",
    "    pB = pL + (pH - pL)*np.clip(q,0,1)\n",
    "    r_eff = r0 + rH*H\n",
    "    dM = (r_eff - c*pB)*M*(1 - M/K_M)\n",
    "    dH = dH_hill(B,H,gH,d,K_B, n=2)\n",
    "    dB = pB*M - u*H*B\n",
    "    dq = (q_inf(H,q,H_on,H_off) - q)/tau\n",
    "    return np.array([dM,dH,dB,dq], float)\n",
    "\n",
    "def jac_fd(fun,y,pvec,dval,eps=1e-7):\n",
    "    f0=fun(y,pvec,dval); J=np.zeros((4,4))\n",
    "    for i in range(4):\n",
    "        y2=y.copy(); y2[i]+=eps\n",
    "        J[:,i]=(fun(y2,pvec,dval)-f0)/eps\n",
    "    return J\n",
    "\n",
    "def find_eq(pvec, dval, guess):\n",
    "    sol = root(lambda yy: rhs(yy, pvec, dval), guess, method=\"hybr\")\n",
    "    if not sol.success: return None, False\n",
    "    y = sol.x\n",
    "    y = np.array([max(0,y[0]), np.clip(y[1],0,1.2), max(0,y[2]), np.clip(y[3],0,1.2)], float)\n",
    "    if not np.all(np.isfinite(y)): return None, False\n",
    "    return y, True\n",
    "\n",
    "# (A) continuation in d\n",
    "D_SPAN = (0.6*d_fit, 1.5*d_fit)\n",
    "d_vals = np.linspace(D_SPAN[0], D_SPAN[1], 90)\n",
    "seeds = [np.array([0.2,0.25,0.05,1.0]), np.array([0.2,0.9,0.1,0.0]), np.array([0.6,0.6,0.2,0.5])]\n",
    "\n",
    "rows=[]\n",
    "for d in d_vals:\n",
    "    for wi,y0 in enumerate(seeds):\n",
    "        y, ok = find_eq(p, d, y0)\n",
    "        if not ok: continue\n",
    "        J=jac_fd(rhs,y,p,d)\n",
    "        stable = (np.max(np.real(np.linalg.eigvals(J)))<0)\n",
    "        rows.append({\"d\":d,\"H\":float(y[1]),\"q\":float(y[3]),\"seed\":wi,\"stable\":stable})\n",
    "branches = pd.DataFrame(rows)\n",
    "branches.to_csv(os.path.join(OUT,\"branches.csv\"), index=False)\n",
    "\n",
    "plt.figure(figsize=(7.2,5.2))\n",
    "for wi in sorted(branches[\"seed\"].unique()):\n",
    "    sub=branches[branches[\"seed\"]==wi]\n",
    "    plt.plot(sub[\"d\"], sub[\"H\"], \".\", ms=3, alpha=0.7, label=f\"seed{wi}\")\n",
    "for st, mk in [(True,\"o\"),(False,\"x\")]:\n",
    "    sub=branches[branches[\"stable\"]==st]\n",
    "    plt.scatter(sub[\"d\"], sub[\"H\"], s=22, marker=mk, alpha=0.6, label=(\"stable\" if st else \"unstable\"))\n",
    "plt.axvline(d_fit, ls=\"--\", c=\"gray\", label=\"baseline d\")\n",
    "plt.xlabel(\"d (1/h)\"); plt.ylabel(\"H*\"); plt.legend(); plt.grid(True, ls=\":\")\n",
    "plt.tight_layout(); plt.savefig(os.path.join(OUT,\"bifurcation_H_vs_d.png\"), dpi=180); plt.close()\n",
    "\n",
    "# (B) bistable at baseline?\n",
    "near = branches[np.isclose(branches[\"d\"], d_fit, atol=1e-3)]\n",
    "distinct=0\n",
    "if not near.empty:\n",
    "    Hs = np.sort(near.loc[near[\"stable\"], \"H\"].values)\n",
    "    if Hs.size:\n",
    "        distinct=1\n",
    "        for i in range(1,len(Hs)):\n",
    "            if abs(Hs[i]-Hs[i-1])>1e-3:\n",
    "                distinct+=1\n",
    "bistable = (distinct>=2)\n",
    "\n",
    "# (C) basins at baseline\n",
    "Hs = np.linspace(0.2, 0.95, 17)\n",
    "qs = np.linspace(0.0, 1.0, 17)\n",
    "Z = np.zeros((len(Hs), len(qs)))\n",
    "def relax(y0,T=300):\n",
    "    sol=solve_ivp(lambda t,z: rhs(z,p,d_fit),(0,T),y0,t_eval=np.linspace(0,T,900),\n",
    "                  rtol=1e-6,atol=1e-8,max_step=0.5)\n",
    "    return sol.y[:,-1]\n",
    "for i,H0 in enumerate(Hs):\n",
    "    for j,q0 in enumerate(qs):\n",
    "        y0=np.array([0.2,H0,0.1,q0],float)\n",
    "        yss=relax(y0)\n",
    "        Z[i,j]=yss[1]\n",
    "\n",
    "plt.figure(figsize=(6.6,5.2))\n",
    "plt.imshow(Z, origin=\"lower\", extent=[qs[0],qs[-1],Hs[0],Hs[-1]], aspect=\"auto\", vmin=0.5, vmax=1.0, cmap=\"viridis\")\n",
    "plt.colorbar(label=\"Final H (steady)\")\n",
    "plt.xlabel(\"initial q\"); plt.ylabel(\"initial H\")\n",
    "plt.title(f\"Basins at baseline d={d_fit:.3f}\")\n",
    "plt.tight_layout(); plt.savefig(os.path.join(OUT,\"basins_heatmap.png\"), dpi=180); plt.close()\n",
    "\n",
    "with open(os.path.join(OUT,\"diagnosis.txt\"),\"w\") as f:\n",
    "    f.write(f\"Baseline d = {d_fit:.5f}\\n\")\n",
    "    f.write(f\"Distinct stable equilibria at baseline: {distinct}\\n\")\n",
    "    f.write(f\"Bistable at baseline? {'YES' if bistable else 'NO'}\\n\")\n",
    "\n",
    "print(\"Saved ->\", OUT, \"| Bistable at baseline? \", \"YES\" if bistable else \"NO\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e31b818-5ce5-4c61-8482-6e361eaa2f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_bistable_regions_hill.py  >>>> Optional\n",
    "# Scan a small hyper-rectangle around the Hill+PF fit for true bistability at baseline d.\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "from scipy.optimize import root\n",
    "import numpy.linalg as npl\n",
    "\n",
    "FIT = \"mw_fit_out_hill_pf/fitted_global_params.csv\"\n",
    "OUT = \"mw_scan_bistability_hill.csv\"\n",
    "\n",
    "g = pd.read_csv(FIT, index_col=0, header=None).squeeze(\"columns\")\n",
    "p0 = np.array([float(g[k]) for k in g.index.values], float)\n",
    "d_fit = float(p0[4])\n",
    "KQ = 40.0\n",
    "\n",
    "def q_inf(H,q,H_on,H_off): th=(1-q)*H_on+q*H_off; return 1.0/(1.0+np.exp(-KQ*(H-th)))\n",
    "def dH(B,H,gH,d,K_B,n=2): return gH*(B**n/(K_B**n + B**n))*(1-H) - d*H\n",
    "def rhs(y,p,dval=None):\n",
    "    M,H,B,q=y\n",
    "    r0,rH,K_M,c,d,gH,u,pL,pH,H_on,H_off,tau,K_B=p.copy()\n",
    "    if dval is not None: d=dval\n",
    "    pB=pL+(pH-pL)*np.clip(q,0,1)\n",
    "    r_eff=r0+rH*H\n",
    "    return np.array([\n",
    "        (r_eff - c*pB)*M*(1 - M/K_M),\n",
    "        dH(B,H,gH,d,K_B,2),\n",
    "        pB*M - u*H*B,\n",
    "        (q_inf(H,q,H_on,H_off) - q)/tau\n",
    "    ], float)\n",
    "\n",
    "def jac_fd(fun,y,p,dval,eps=1e-7):\n",
    "    f0=fun(y,p,dval); J=np.zeros((4,4))\n",
    "    for i in range(4):\n",
    "        y2=y.copy(); y2[i]+=eps\n",
    "        J[:,i]=(fun(y2,p,dval)-f0)/eps\n",
    "    return J\n",
    "\n",
    "def find_eq(p,dval,guess):\n",
    "    sol=root(lambda yy: rhs(yy,p,dval), guess, method=\"hybr\")\n",
    "    if not sol.success: return None, False\n",
    "    y=sol.x\n",
    "    y=np.array([max(0,y[0]), np.clip(y[1],0,1.2), max(0,y[2]), np.clip(y[3],0,1.2)], float)\n",
    "    if not np.all(np.isfinite(y)): return None, False\n",
    "    return y, True\n",
    "\n",
    "# small grids (tight first; widen if empty)\n",
    "rH_grid   = np.linspace(max(0.0, p0[1]-0.06), p0[1]+0.06, 5)\n",
    "u_grid    = np.linspace(max(0.2, p0[6]-0.25), p0[6]+0.25, 7)\n",
    "Hoff_grid = np.linspace(max(0.75, p0[10]-0.08), min(0.95, p0[10]+0.04), 7)\n",
    "pH_grid   = np.linspace(max(1.0, p0[8]-0.8), p0[8]+0.8, 7)\n",
    "c_grid    = np.linspace(max(0.05, p0[3]-0.06), p0[3]+0.06, 5)\n",
    "KB_grid   = np.linspace(max(0.08, p0[12]-0.10), min(0.40, p0[12]+0.10), 7)\n",
    "\n",
    "seeds=[np.array([0.2,0.25,0.05,1.0]), np.array([0.2,0.90,0.10,0.0]), np.array([0.6,0.60,0.20,0.5])]\n",
    "\n",
    "rows=[]\n",
    "for rH in rH_grid:\n",
    "    for u in u_grid:\n",
    "        for H_off in Hoff_grid:\n",
    "            for pH in pH_grid:\n",
    "                for c in c_grid:\n",
    "                    for KB in KB_grid:\n",
    "                        p=p0.copy(); p[1]=rH; p[6]=u; p[10]=H_off; p[8]=pH; p[3]=c; p[12]=KB\n",
    "                        Hs=[]\n",
    "                        for y0 in seeds:\n",
    "                            y, ok = find_eq(p, d_fit, y0)\n",
    "                            if not ok: continue\n",
    "                            J=jac_fd(rhs,y,p,d_fit)\n",
    "                            if np.max(np.real(npl.eigvals(J)))<0:\n",
    "                                Hs.append(float(y[1]))\n",
    "                        Hs=np.array(sorted(Hs))\n",
    "                        distinct=0\n",
    "                        if Hs.size:\n",
    "                            distinct=1\n",
    "                            for i in range(1,len(Hs)):\n",
    "                                if abs(Hs[i]-Hs[i-1])>1e-3:\n",
    "                                    distinct+=1\n",
    "                        rows.append({\"rH\":rH,\"u\":u,\"H_off\":H_off,\"p_high\":pH,\"c\":c,\"K_B\":KB,\n",
    "                                     \"distinct_stable\":distinct,\"bistable\":distinct>=2})\n",
    "\n",
    "df=pd.DataFrame(rows)\n",
    "df.to_csv(OUT, index=False)\n",
    "print(\"Saved ->\", OUT, \"| bistable rows:\", int(df[\"bistable\"].sum()))\n",
    "if df[\"bistable\"].any():\n",
    "    print(df[df[\"bistable\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe095d85-6567-4d18-852a-8d114fa41f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c4f4c3-7b93-428c-87f2-3b075708544f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate_hysteresis_from_scored_hill_pf_constrained.py\n",
    "# -------------------------------------------------------------------\n",
    "# Hill host benefit + smooth hysteretic memory + weak host->microbe PF\n",
    "# Refit with biologically plausible priors and tighter bounds to avoid\n",
    "# degenerate edge solutions that destroy bistability.\n",
    "# Fixed-length residuals. Save outputs to mw_fit_out_hill_pf_constrained/\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "import os, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "# ----------------- Paths & config -----------------\n",
    "INPATH = \"timeseries/combined_scfas_table_scored.csv\"\n",
    "OUTDIR = \"mw_fit_out_hill_pf_constrained\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "H_COLS = [\"H_proxy_meta_smooth\",\"H_proxy_meta\"]\n",
    "SCFA_COLS = [\"butyrate\"]   # can average multiple if you like\n",
    "\n",
    "MIN_ROWS = 4\n",
    "KQ = 40.0\n",
    "PENALTY = 1e3\n",
    "\n",
    "# ---- Priors (centers & widths; edit if you have better anchors) ----\n",
    "PRIOR = {\n",
    "    \"d\":      (0.12, 0.05),    # decay/inflammation\n",
    "    \"g\":      (0.60, 0.30),    # host benefit gain\n",
    "    \"u\":      (0.60, 0.20),    # uptake (linear model; Hill uptake can be added later)\n",
    "    \"p_low\":  (0.10, 0.05),\n",
    "    \"c\":      (0.10, 0.05),\n",
    "    \"rH\":     (0.08, 0.05),    # weak PF\n",
    "    \"H_off\":  (0.85, 0.05),\n",
    "    \"K_B\":    (0.20, 0.08),    # Hill half-saturation in B units (z-scored per subject)\n",
    "}\n",
    "\n",
    "# ---- Bounds (tighter than before; still permissive) ----\n",
    "LBg = np.array([0.08, 0.00, 0.6, 0.05, 0.03, 0.10, 0.25, 0.02, 0.9, 0.40, 0.75, 1.0, 0.08])\n",
    "UBg = np.array([0.55, 0.20, 1.6, 0.22, 0.35, 1.20, 0.95, 0.35, 3.2, 0.70, 0.93, 12.0, 0.35])\n",
    "\n",
    "# Initial guess near priors\n",
    "x0g = np.array([\n",
    "    0.30, 0.08, 1.0, 0.10, 0.12, 0.60, 0.60, 0.10, 2.0, 0.55, 0.85, 4.0, 0.20\n",
    "], float)\n",
    "\n",
    "# ----------------- Load & prep data -----------------\n",
    "df = pd.read_csv(INPATH)\n",
    "if not {\"subject_id\",\"sample_id\"}.issubset(df.columns):\n",
    "    raise ValueError(\"CSV must contain 'subject_id' and 'sample_id'.\")\n",
    "\n",
    "Hcol = next((c for c in H_COLS if c in df.columns), None)\n",
    "if Hcol is None:\n",
    "    raise ValueError(\"Need H_proxy_meta_smooth or H_proxy_meta in the CSV.\")\n",
    "\n",
    "for c in SCFA_COLS:\n",
    "    if c not in df.columns:\n",
    "        raise ValueError(f\"Missing SCFA column '{c}'.\")\n",
    "\n",
    "keep = [\"subject_id\",\"sample_id\",Hcol] + SCFA_COLS\n",
    "df = df[keep].dropna(subset=[\"subject_id\",\"sample_id\"]).copy()\n",
    "df[\"t_idx\"] = df.groupby(\"subject_id\").cumcount().astype(float)\n",
    "\n",
    "def robust_z(series: pd.Series) -> pd.Series:\n",
    "    x = series.astype(float).to_numpy()\n",
    "    m = np.isfinite(x)\n",
    "    if m.sum()==0: return pd.Series(np.zeros_like(x), index=series.index)\n",
    "    xm = x[m]; med = np.median(xm)\n",
    "    mad = np.median(np.abs(xm - med))\n",
    "    if mad < 1e-9:\n",
    "        q75,q25 = np.percentile(xm,[75,25]); iqr = q75-q25\n",
    "        scale = iqr if iqr>1e-9 else (np.std(xm)+1e-9)\n",
    "    else:\n",
    "        scale = mad\n",
    "    return pd.Series((x - med)/(scale+1e-9), index=series.index)\n",
    "\n",
    "for c in SCFA_COLS:\n",
    "    df[c+\"_z\"] = df.groupby(\"subject_id\")[c].transform(robust_z)\n",
    "\n",
    "df[\"B_obs\"] = df[SCFA_COLS[0] + \"_z\"] if len(SCFA_COLS)==1 else df[[c+\"_z\" for c in SCFA_COLS]].mean(axis=1)\n",
    "df[\"H_obs\"] = df[Hcol].clip(0,1)\n",
    "\n",
    "subs=[]\n",
    "for sid, sub in df.groupby(\"subject_id\"):\n",
    "    sub=sub.sort_values(\"t_idx\").copy()\n",
    "    if len(sub)<MIN_ROWS: continue\n",
    "    t=sub[\"t_idx\"].values.astype(float)\n",
    "    B=sub[\"B_obs\"].values.astype(float)\n",
    "    H=sub[\"H_obs\"].values.astype(float)\n",
    "    mB=np.isfinite(B); mH=np.isfinite(H)\n",
    "    if mB.sum()<3 or mH.sum()<3: continue\n",
    "    def first(a,d):\n",
    "        a=np.asarray(a,float); idx=np.where(np.isfinite(a))[0]\n",
    "        return float(a[idx[0]]) if len(idx) else float(d)\n",
    "    subs.append({\n",
    "        \"sid\":sid,\n",
    "        \"t\":t,\"B\":B,\"H\":H,\n",
    "        \"maskB\":mB,\"maskH\":mH,\n",
    "        \"nB\":int(mB.sum()),\"nH\":int(mH.sum()),\n",
    "        \"H0\":float(np.clip(first(H,0.6),0,1)),\n",
    "        \"B0\":float(max(0.05, first(B,0.1))),\n",
    "    })\n",
    "if not subs:\n",
    "    raise RuntimeError(\"No subject passed minimal data filters.\")\n",
    "\n",
    "print(f\"[info] Fitting {len(subs)} subjects ...\")\n",
    "\n",
    "# ----------------- Model (Hill + PF + smooth memory) -----------------\n",
    "# y = [M,H,B,q]\n",
    "# p = [r0,rH,K_M,c,d,g,u,p_low,p_high,H_on,H_off,tau_q,K_B]\n",
    "NAMES = [\"r0\",\"rH\",\"K_M\",\"c\",\"d\",\"g\",\"u\",\"p_low\",\"p_high\",\"H_on\",\"H_off\",\"tau_q\",\"K_B\"]\n",
    "\n",
    "def q_inf_smooth(H,q,H_on,H_off,k=KQ):\n",
    "    th=(1.0-q)*H_on + q*H_off\n",
    "    return 1.0/(1.0 + np.exp(-k*(H - th)))\n",
    "\n",
    "def dH_hill(B,H,gH,d,K_B,n=2):\n",
    "    ben = gH*(B**n / (K_B**n + B**n))*(1.0 - H)\n",
    "    return ben - d*H\n",
    "\n",
    "def rhs(t,y,p):\n",
    "    M,H,B,q = y\n",
    "    r0,rH,K_M,c,d,gH,u,pL,pH,H_on,H_off,tau,K_B = p\n",
    "    pB = pL + (pH - pL)*np.clip(q,0,1)\n",
    "    r_eff = r0 + rH*H\n",
    "    dM = (r_eff - c*pB)*M*(1 - M/K_M)\n",
    "    dH = dH_hill(B,H,gH,d,K_B, n=2)\n",
    "    dB = pB*M - u*H*B\n",
    "    dq = (q_inf_smooth(H,q,H_on,H_off) - q)/tau\n",
    "    return [dM,dH,dB,dq]\n",
    "\n",
    "def simulate(ts,y0,p):\n",
    "    try:\n",
    "        sol=solve_ivp(lambda t,z: rhs(t,z,p),(ts[0],ts[-1]),y0,t_eval=ts,\n",
    "                      rtol=1e-6,atol=1e-8,max_step=0.5)\n",
    "        if not sol.success:\n",
    "            T=len(ts); return np.vstack([np.full(T,np.nan)]*4)\n",
    "        return sol.y\n",
    "    except Exception:\n",
    "        T=len(ts); return np.vstack([np.full(T,np.nan)]*4)\n",
    "\n",
    "# Per-subject simple observation maps (kept; but we’ll weight H higher)\n",
    "x0s=[]; LBs=[]; UBs=[]\n",
    "for _ in subs:\n",
    "    x0s += [1.0, 0.0, 1.0]   # alpha_B, beta0_H, beta1_H\n",
    "    LBs += [0.2, -0.4, 0.5]\n",
    "    UBs += [4.0,  0.4, 1.5]\n",
    "\n",
    "x0 = np.concatenate([x0g, np.array(x0s,float)])\n",
    "LB = np.concatenate([LBg, np.array(LBs,float)])\n",
    "UB = np.concatenate([UBg, np.array(UBs,float)])\n",
    "\n",
    "def unpack(x):\n",
    "    gpar = x[:len(NAMES)]\n",
    "    triples = np.split(x[len(NAMES):], len(subs))\n",
    "    return gpar, triples\n",
    "\n",
    "# residual weighting (downweight B a little to prevent d->0)\n",
    "W_B = 0.6\n",
    "W_H = 1.0\n",
    "\n",
    "# fixed-length residual vector size (+ priors)\n",
    "TOTLEN = sum(S[\"nB\"] + S[\"nH\"] for S in subs) + len(PRIOR)\n",
    "\n",
    "def residuals(x):\n",
    "    gpar, triples = unpack(x)\n",
    "    # guards\n",
    "    if not (gpar[10] > gpar[9]):  # H_off > H_on\n",
    "        return np.full(TOTLEN, PENALTY)\n",
    "    if gpar[12] <= 0.05:\n",
    "        return np.full(TOTLEN, PENALTY)\n",
    "\n",
    "    res=[]\n",
    "    for S, tr in zip(subs, triples):\n",
    "        aB, b0H, b1H = tr\n",
    "        ts=S[\"t\"]; H0=np.clip(S[\"H0\"],0,1); B0=max(0.05,S[\"B0\"])\n",
    "        M0=0.12\n",
    "        q0 = 1.0 if H0 < 0.5*(gpar[9]+gpar[10]) else 0.0\n",
    "        y0=[M0, H0, B0, q0]\n",
    "        Y=simulate(ts, y0, gpar)\n",
    "        _, Hm, Bm, _ = Y\n",
    "\n",
    "        if np.any(~np.isfinite(Hm)) or np.any(~np.isfinite(Bm)):\n",
    "            res += [W_B*np.full(S[\"nB\"],PENALTY), W_H*np.full(S[\"nH\"],PENALTY)]\n",
    "            continue\n",
    "\n",
    "        Bhat = aB*Bm\n",
    "        Hhat = np.clip(b0H + b1H*Hm, 0, 1)\n",
    "\n",
    "        b = (Bhat[S[\"maskB\"]] - S[\"B\"][S[\"maskB\"]])\n",
    "        h = (Hhat[S[\"maskH\"]] - S[\"H\"][S[\"maskH\"]])\n",
    "\n",
    "        b = np.where(np.isfinite(b), b, PENALTY)\n",
    "        h = np.where(np.isfinite(h), h, PENALTY)\n",
    "\n",
    "        res += [W_B*b.astype(float), W_H*h.astype(float)]\n",
    "\n",
    "    # ---- Priors as pseudo-residuals (one per entry in PRIOR) ----\n",
    "    prior_terms=[]\n",
    "    index = {name:i for i,name in enumerate(NAMES)}\n",
    "    for name,(mu,sd) in PRIOR.items():\n",
    "        i = index[name]\n",
    "        prior_terms.append( (gpar[i]-mu)/ (sd + 1e-9) )\n",
    "    res.append(np.array(prior_terms, float))\n",
    "\n",
    "    return np.concatenate(res)\n",
    "\n",
    "fit = least_squares(residuals, x0, bounds=(LB,UB),\n",
    "                    verbose=2, max_nfev=1000, loss=\"soft_l1\", f_scale=1.0)\n",
    "\n",
    "gpar_hat, triples_hat = unpack(fit.x)\n",
    "\n",
    "pd.Series(gpar_hat, index=NAMES).to_csv(os.path.join(OUTDIR,\"fitted_global_params.csv\"), header=False)\n",
    "pd.DataFrame(\n",
    "    [{\"subject_id\": S[\"sid\"], \"alpha_B\": tr[0], \"beta0_H\": tr[1], \"beta1_H\": tr[2]}\n",
    "     for S,tr in zip(subs, triples_hat)]\n",
    ").to_csv(os.path.join(OUTDIR,\"fitted_subject_scales.csv\"), index=False)\n",
    "\n",
    "print(\"[info] Fitted globals:\", dict(zip(NAMES, gpar_hat)))\n",
    "\n",
    "# quick small diagnostics (first few subjects)\n",
    "for S,tr in list(zip(subs, triples_hat))[:8]:\n",
    "    aB, b0, b1 = tr\n",
    "    ts=S[\"t\"]; H0=np.clip(S[\"H0\"],0,1); B0=max(0.05,S[\"B0\"])\n",
    "    M0=0.12; q0 = 1.0 if H0 < 0.5*(gpar_hat[9]+gpar_hat[10]) else 0.0\n",
    "    y0=[M0,H0,B0,q0]\n",
    "    sol=solve_ivp(lambda t,z: rhs(t,z,gpar_hat),(ts[0],ts[-1]),y0,t_eval=ts,\n",
    "                  rtol=1e-6,atol=1e-8,max_step=0.5)\n",
    "    M,H,B,q = sol.y\n",
    "    Bhat=aB*B; Hhat=np.clip(b0 + b1*H,0,1)\n",
    "    mB,mH=S[\"maskB\"],S[\"maskH\"]\n",
    "\n",
    "    fig,ax=plt.subplots(2,1,figsize=(7,6),sharex=True)\n",
    "    ax[0].plot(ts[mB],Bhat[mB],label=\"Model B (scaled)\")\n",
    "    ax[0].scatter(ts[mB],S[\"B\"][mB],s=18,c=\"k\",label=\"Obs B (z)\")\n",
    "    ax[0].legend(); ax[0].grid(True,ls=\":\")\n",
    "\n",
    "    ax[1].plot(ts[mH],Hhat[mH],label=\"Model H\")\n",
    "    ax[1].scatter(ts[mH],S[\"H\"][mH],s=18,c=\"k\",label=\"H proxy\")\n",
    "    ax[1].axhline(gpar_hat[9],ls=\":\",c=\"gray\",label=\"H_on\")\n",
    "    ax[1].axhline(gpar_hat[10],ls=\"--\",c=\"gray\",label=\"H_off\")\n",
    "    ax[1].legend(); ax[1].grid(True,ls=\":\")\n",
    "    ax[1].set_xlabel(\"time\"); ax[0].set_ylabel(\"B\"); ax[1].set_ylabel(\"H\")\n",
    "    plt.tight_layout(); plt.savefig(os.path.join(OUTDIR,f\"diag_{S['sid']}.png\"),dpi=170); plt.close()\n",
    "\n",
    "print(\"✅ Done. Outputs in:\", OUTDIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3c4486-da96-47d5-bca6-6e5a76aa00e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bifurcation_and_basins_hill.py >> constrained\n",
    "# ------------------------------------------------------------\n",
    "# Continuation in d; stability via Jacobian eigs; basins at baseline\n",
    "# for the Hill + smooth hysteresis + PF model fitted above.\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.optimize import root\n",
    "\n",
    "FIT = \"mw_fit_out_hill_pf_constrained/fitted_global_params.csv\"\n",
    "OUT = \"mw_bif_hill\"; os.makedirs(OUT, exist_ok=True)\n",
    "\n",
    "KQ = 40.0\n",
    "g = pd.read_csv(FIT, index_col=0, header=None).squeeze(\"columns\")\n",
    "# p = [r0,rH,K_M,c,d,g,u,p_low,p_high,H_on,H_off,tau_q,K_B]\n",
    "p = np.array([float(g[k]) for k in g.index.values], float)\n",
    "d_fit = float(p[4])\n",
    "\n",
    "def q_inf(H,q,H_on,H_off,k=KQ):\n",
    "    th = (1-q)*H_on + q*H_off\n",
    "    return 1.0/(1.0 + np.exp(-k*(H - th)))\n",
    "\n",
    "def dH_hill(B,H,gH,d,K_B,n=2):\n",
    "    return gH*(B**n/(K_B**n + B**n))*(1-H) - d*H\n",
    "\n",
    "def rhs(y, pvec, d_override=None):\n",
    "    M,H,B,q = y\n",
    "    r0,rH,K_M,c,d,gH,u,pL,pH,H_on,H_off,tau,K_B = pvec.copy()\n",
    "    if d_override is not None: d = d_override\n",
    "    pB = pL + (pH - pL)*np.clip(q,0,1)\n",
    "    r_eff = r0 + rH*H\n",
    "    dM = (r_eff - c*pB)*M*(1 - M/K_M)\n",
    "    dH = dH_hill(B,H,gH,d,K_B, n=2)\n",
    "    dB = pB*M - u*H*B\n",
    "    dq = (q_inf(H,q,H_on,H_off) - q)/tau\n",
    "    return np.array([dM,dH,dB,dq], float)\n",
    "\n",
    "def jac_fd(fun,y,pvec,dval,eps=1e-7):\n",
    "    f0=fun(y,pvec,dval); J=np.zeros((4,4))\n",
    "    for i in range(4):\n",
    "        y2=y.copy(); y2[i]+=eps\n",
    "        J[:,i]=(fun(y2,pvec,dval)-f0)/eps\n",
    "    return J\n",
    "\n",
    "def find_eq(pvec, dval, guess):\n",
    "    sol = root(lambda yy: rhs(yy, pvec, dval), guess, method=\"hybr\")\n",
    "    if not sol.success: return None, False\n",
    "    y = sol.x\n",
    "    y = np.array([max(0,y[0]), np.clip(y[1],0,1.2), max(0,y[2]), np.clip(y[3],0,1.2)], float)\n",
    "    if not np.all(np.isfinite(y)): return None, False\n",
    "    return y, True\n",
    "\n",
    "# (A) continuation in d\n",
    "D_SPAN = (0.6*d_fit, 1.5*d_fit)\n",
    "d_vals = np.linspace(D_SPAN[0], D_SPAN[1], 90)\n",
    "seeds = [np.array([0.2,0.25,0.05,1.0]), np.array([0.2,0.9,0.1,0.0]), np.array([0.6,0.6,0.2,0.5])]\n",
    "\n",
    "rows=[]\n",
    "for d in d_vals:\n",
    "    for wi,y0 in enumerate(seeds):\n",
    "        y, ok = find_eq(p, d, y0)\n",
    "        if not ok: continue\n",
    "        J=jac_fd(rhs,y,p,d)\n",
    "        stable = (np.max(np.real(np.linalg.eigvals(J)))<0)\n",
    "        rows.append({\"d\":d,\"H\":float(y[1]),\"q\":float(y[3]),\"seed\":wi,\"stable\":stable})\n",
    "branches = pd.DataFrame(rows)\n",
    "branches.to_csv(os.path.join(OUT,\"branches.csv\"), index=False)\n",
    "\n",
    "plt.figure(figsize=(7.2,5.2))\n",
    "for wi in sorted(branches[\"seed\"].unique()):\n",
    "    sub=branches[branches[\"seed\"]==wi]\n",
    "    plt.plot(sub[\"d\"], sub[\"H\"], \".\", ms=3, alpha=0.7, label=f\"seed{wi}\")\n",
    "for st, mk in [(True,\"o\"),(False,\"x\")]:\n",
    "    sub=branches[branches[\"stable\"]==st]\n",
    "    plt.scatter(sub[\"d\"], sub[\"H\"], s=22, marker=mk, alpha=0.6, label=(\"stable\" if st else \"unstable\"))\n",
    "plt.axvline(d_fit, ls=\"--\", c=\"gray\", label=\"baseline d\")\n",
    "plt.xlabel(\"d (1/h)\"); plt.ylabel(\"H*\"); plt.legend(); plt.grid(True, ls=\":\")\n",
    "plt.tight_layout(); plt.savefig(os.path.join(OUT,\"bifurcation_H_vs_d.png\"), dpi=180); plt.close()\n",
    "\n",
    "# (B) bistable at baseline?\n",
    "near = branches[np.isclose(branches[\"d\"], d_fit, atol=1e-3)]\n",
    "distinct=0\n",
    "if not near.empty:\n",
    "    Hs = np.sort(near.loc[near[\"stable\"], \"H\"].values)\n",
    "    if Hs.size:\n",
    "        distinct=1\n",
    "        for i in range(1,len(Hs)):\n",
    "            if abs(Hs[i]-Hs[i-1])>1e-3:\n",
    "                distinct+=1\n",
    "bistable = (distinct>=2)\n",
    "\n",
    "# (C) basins at baseline\n",
    "Hs = np.linspace(0.2, 0.95, 17)\n",
    "qs = np.linspace(0.0, 1.0, 17)\n",
    "Z = np.zeros((len(Hs), len(qs)))\n",
    "def relax(y0,T=300):\n",
    "    sol=solve_ivp(lambda t,z: rhs(z,p,d_fit),(0,T),y0,t_eval=np.linspace(0,T,900),\n",
    "                  rtol=1e-6,atol=1e-8,max_step=0.5)\n",
    "    return sol.y[:,-1]\n",
    "for i,H0 in enumerate(Hs):\n",
    "    for j,q0 in enumerate(qs):\n",
    "        y0=np.array([0.2,H0,0.1,q0],float)\n",
    "        yss=relax(y0)\n",
    "        Z[i,j]=yss[1]\n",
    "\n",
    "plt.figure(figsize=(6.6,5.2))\n",
    "plt.imshow(Z, origin=\"lower\", extent=[qs[0],qs[-1],Hs[0],Hs[-1]], aspect=\"auto\", vmin=0.5, vmax=1.0, cmap=\"viridis\")\n",
    "plt.colorbar(label=\"Final H (steady)\")\n",
    "plt.xlabel(\"initial q\"); plt.ylabel(\"initial H\")\n",
    "plt.title(f\"Basins at baseline d={d_fit:.3f}\")\n",
    "plt.tight_layout(); plt.savefig(os.path.join(OUT,\"basins_heatmap.png\"), dpi=180); plt.close()\n",
    "\n",
    "with open(os.path.join(OUT,\"diagnosis.txt\"),\"w\") as f:\n",
    "    f.write(f\"Baseline d = {d_fit:.5f}\\n\")\n",
    "    f.write(f\"Distinct stable equilibria at baseline: {distinct}\\n\")\n",
    "    f.write(f\"Bistable at baseline? {'YES' if bistable else 'NO'}\\n\")\n",
    "\n",
    "print(\"Saved ->\", OUT, \"| Bistable at baseline? \", \"YES\" if bistable else \"NO\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ffafc3-cf10-4b45-9b22-8545c4b9b076",
   "metadata": {},
   "source": [
    "### saturable uptake to your Hill+smooth-memory+PF model, keep fixed-length residuals, and use tight, literature-plausible priors/bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226e9744-ee71-4185-abc8-bc30a3803619",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calibrate_hysteresis_from_scored_hill_satpf.py\n",
    "# -------------------------------------------------------------------\n",
    "# Model:\n",
    "#   dM = (r0 + rH*H - c*pB)*M*(1 - M/K_M)\n",
    "#   dH = g * (B^n/(K_B^n + B^n)) * (1 - H) - d*H         [Hill host benefit, n=2]\n",
    "#   dB = pB*M - u*H * B/(K_u + B)                         [SATURABLE uptake]\n",
    "#   dq = (q_inf(H,q) - q)/tau_q,  q_inf = sigmoid_k(H - [(1-q)H_on + q H_off])\n",
    "#\n",
    "# Robust calibration to scored time series (butyrate intensity z-scores, H proxy).\n",
    "# Fixed-length residuals; tight priors/bounds from literature to avoid edge fits.\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "# ----------------- Paths & config -----------------\n",
    "INPATH = \"timeseries/combined_scfas_table_scored.csv\"   # <- your scored file\n",
    "OUTDIR = \"mw_fit_out_hill_satpf\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "H_COLS = [\"H_proxy_meta_smooth\",\"H_proxy_meta\"]\n",
    "SCFA_COLS = [\"butyrate\"]        # can add more; will average per-subject z-scores\n",
    "\n",
    "MIN_ROWS  = 4\n",
    "KQ        = 40.0                # memory smoothness (sigmoid steepness)\n",
    "PENALTY   = 1e3                 # finite penalty for failed sims to keep residual length fixed\n",
    "HILL_N    = 2\n",
    "\n",
    "# ---- Priors (center, sd) — edit if you have better anchors ----\n",
    "PRIOR = {\n",
    "    \"d\":      (0.12, 0.05),   # host decay/inflammation\n",
    "    \"g\":      (0.60, 0.30),   # host benefit gain\n",
    "    \"u\":      (0.60, 0.20),   # uptake scale\n",
    "    \"K_u\":    (0.20, 0.08),   # uptake half-saturation (in B z-units)\n",
    "    \"K_B\":    (0.20, 0.08),   # host benefit half-saturation\n",
    "    \"p_low\":  (0.10, 0.05),\n",
    "    \"c\":      (0.10, 0.05),\n",
    "    \"rH\":     (0.08, 0.05),   # weak PF\n",
    "    \"H_off\":  (0.85, 0.05),\n",
    "}\n",
    "\n",
    "# ---- Bounds (tighter, literature-plausible) ----\n",
    "# p = [r0,rH,K_M,c,d,g,u,K_u,p_low,p_high,H_on,H_off,tau_q,K_B]\n",
    "LBg = np.array([0.08, 0.00, 0.6, 0.06, 0.06, 0.15, 0.40, 0.10, 0.02, 1.2, 0.40, 0.80, 1.0, 0.10])\n",
    "UBg = np.array([0.55, 0.20, 1.7, 0.18, 0.24, 1.50, 0.90, 0.35, 0.35, 3.0, 0.70, 0.90, 12.0, 0.35])\n",
    "\n",
    "# Start near priors/baseline\n",
    "x0g = np.array([0.30, 0.08, 1.0, 0.10, 0.12, 0.60, 0.60, 0.20, 0.10, 2.0, 0.55, 0.85, 4.0, 0.20], float)\n",
    "\n",
    "# ----------------- Load & prep data -----------------\n",
    "df = pd.read_csv(INPATH)\n",
    "if not {\"subject_id\",\"sample_id\"}.issubset(df.columns):\n",
    "    raise ValueError(\"CSV must contain 'subject_id' and 'sample_id'.\")\n",
    "\n",
    "Hcol = next((c for c in H_COLS if c in df.columns), None)\n",
    "if Hcol is None:\n",
    "    raise ValueError(\"Need H_proxy_meta_smooth or H_proxy_meta in the CSV.\")\n",
    "\n",
    "for c in SCFA_COLS:\n",
    "    if c not in df.columns:\n",
    "        raise ValueError(f\"Missing SCFA column '{c}'.\")\n",
    "\n",
    "keep = [\"subject_id\",\"sample_id\",Hcol] + SCFA_COLS\n",
    "df = df[keep].dropna(subset=[\"subject_id\",\"sample_id\"]).copy()\n",
    "df[\"t_idx\"] = df.groupby(\"subject_id\").cumcount().astype(float)\n",
    "\n",
    "def robust_z(series: pd.Series) -> pd.Series:\n",
    "    x=series.astype(float).to_numpy(); m=np.isfinite(x)\n",
    "    if m.sum()==0: return pd.Series(np.zeros_like(x), index=series.index)\n",
    "    xm=x[m]; med=np.median(xm); mad=np.median(np.abs(xm - med))\n",
    "    if mad < 1e-9:\n",
    "        q75,q25=np.percentile(xm,[75,25]); iqr=q75-q25\n",
    "        scale=iqr if iqr>1e-9 else (np.std(xm)+1e-9)\n",
    "    else:\n",
    "        scale=mad\n",
    "    return pd.Series((x - med)/(scale+1e-9), index=series.index)\n",
    "\n",
    "for c in SCFA_COLS:\n",
    "    df[c+\"_z\"] = df.groupby(\"subject_id\")[c].transform(robust_z)\n",
    "\n",
    "df[\"B_obs\"] = df[SCFA_COLS[0]+\"_z\"] if len(SCFA_COLS)==1 else df[[c+\"_z\" for c in SCFA_COLS]].mean(axis=1)\n",
    "df[\"H_obs\"] = df[Hcol].clip(0,1)\n",
    "\n",
    "subs=[]\n",
    "for sid, sub in df.groupby(\"subject_id\"):\n",
    "    sub=sub.sort_values(\"t_idx\").copy()\n",
    "    if len(sub)<MIN_ROWS: continue\n",
    "    t=sub[\"t_idx\"].values.astype(float)\n",
    "    B=sub[\"B_obs\"].values.astype(float)\n",
    "    H=sub[\"H_obs\"].values.astype(float)\n",
    "    mB=np.isfinite(B); mH=np.isfinite(H)\n",
    "    if mB.sum()<3 or mH.sum()<3: continue\n",
    "    def first(a,d):\n",
    "        a=np.asarray(a,float); idx=np.where(np.isfinite(a))[0]\n",
    "        return float(a[idx[0]]) if len(idx) else float(d)\n",
    "    subs.append({\n",
    "        \"sid\":sid, \"t\":t, \"B\":B, \"H\":H,\n",
    "        \"maskB\":mB, \"maskH\":mH,\n",
    "        \"nB\":int(mB.sum()), \"nH\":int(mH.sum()),\n",
    "        \"H0\":float(np.clip(first(H,0.6),0,1)),\n",
    "        \"B0\":float(max(0.05, first(B,0.1))),\n",
    "    })\n",
    "if not subs:\n",
    "    raise RuntimeError(\"No subject passed minimal data filters.\")\n",
    "\n",
    "print(f\"[info] Fitting {len(subs)} subjects ...\")\n",
    "\n",
    "# ----------------- Model (Hill + SAT uptake + PF + smooth memory) -----------------\n",
    "# y=[M,H,B,q]; p=[r0,rH,K_M,c,d,g,u,K_u,p_low,p_high,H_on,H_off,tau_q,K_B]\n",
    "NAMES = [\"r0\",\"rH\",\"K_M\",\"c\",\"d\",\"g\",\"u\",\"K_u\",\"p_low\",\"p_high\",\"H_on\",\"H_off\",\"tau_q\",\"K_B\"]\n",
    "\n",
    "def q_inf_smooth(H, q, H_on, H_off, k=KQ):\n",
    "    th = (1.0 - q)*H_on + q*H_off\n",
    "    return 1.0/(1.0 + np.exp(-k*(H - th)))\n",
    "\n",
    "def dH_hill(B, H, gH, d, K_B, n=HILL_N):\n",
    "    return gH*(B**n/(K_B**n + B**n))*(1 - H) - d*H\n",
    "\n",
    "def rhs(t, y, p):\n",
    "    M,H,B,q = y\n",
    "    r0,rH,K_M,c,d,gH,u,K_u,pL,pH,H_on,H_off,tau,K_B = p\n",
    "    pB = pL + (pH - pL)*np.clip(q,0,1)\n",
    "    r_eff = r0 + rH*H\n",
    "    dM = (r_eff - c*pB)*M*(1 - M/K_M)\n",
    "    dH = dH_hill(B,H,gH,d,K_B)\n",
    "    uptake = u*H*B/(K_u + B + 1e-9)\n",
    "    dB = pB*M - uptake\n",
    "    dq = (q_inf_smooth(H,q,H_on,H_off) - q)/tau\n",
    "    return [dM,dH,dB,dq]\n",
    "\n",
    "def simulate(ts, y0, p):\n",
    "    try:\n",
    "        sol=solve_ivp(lambda t,z: rhs(t,z,p),(ts[0],ts[-1]),y0,t_eval=ts,\n",
    "                      rtol=1e-6, atol=1e-8, max_step=0.5)\n",
    "        if not sol.success:\n",
    "            T=len(ts); return np.vstack([np.full(T,np.nan)]*4)\n",
    "        return sol.y\n",
    "    except Exception:\n",
    "        T=len(ts); return np.vstack([np.full(T,np.nan)]*4)\n",
    "\n",
    "# Per-subject observation maps (keep modest freedom; don’t let them dominate)\n",
    "x0s=[]; LBs=[]; UBs=[]\n",
    "for _ in subs:\n",
    "    x0s += [1.0, 0.0, 1.0]     # alpha_B, beta0_H, beta1_H\n",
    "    LBs += [0.5, -0.3, 0.7]\n",
    "    UBs += [2.0,  0.3, 1.3]\n",
    "\n",
    "x0 = np.concatenate([x0g, np.array(x0s,float)])\n",
    "LB = np.concatenate([LBg, np.array(LBs,float)])\n",
    "UB = np.concatenate([UBg, np.array(UBs,float)])\n",
    "\n",
    "def unpack(x):\n",
    "    gpar = x[:len(NAMES)]\n",
    "    triples = np.split(x[len(NAMES):], len(subs))\n",
    "    return gpar, triples\n",
    "\n",
    "# weights — give H a little more pull than B (intensity/z is noisier)\n",
    "W_B, W_H = 0.6, 1.0\n",
    "\n",
    "# fixed residual length (+ priors)\n",
    "TOTLEN = sum(S[\"nB\"] + S[\"nH\"] for S in subs) + len(PRIOR)\n",
    "\n",
    "def residuals(x):\n",
    "    gpar, triples = unpack(x)\n",
    "    # guards\n",
    "    if not (gpar[11] > gpar[10]):     # H_off > H_on\n",
    "        return np.full(TOTLEN, PENALTY)\n",
    "    if gpar[13] <= 0.06 or gpar[7] <= 0.06:  # K_B, K_u positive lower bounds\n",
    "        return np.full(TOTLEN, PENALTY)\n",
    "\n",
    "    res=[]\n",
    "    for S, tr in zip(subs, triples):\n",
    "        aB, b0H, b1H = tr\n",
    "        ts=S[\"t\"]; H0=np.clip(S[\"H0\"],0,1); B0=max(0.05, S[\"B0\"])\n",
    "        M0=0.12; q0 = 1.0 if H0 < 0.5*(gpar[10]+gpar[11]) else 0.0\n",
    "        y0=[M0,H0,B0,q0]\n",
    "        Y=simulate(ts, y0, gpar)\n",
    "        _, Hm, Bm, _ = Y\n",
    "        if np.any(~np.isfinite(Hm)) or np.any(~np.isfinite(Bm)):\n",
    "            res += [W_B*np.full(S[\"nB\"],PENALTY), W_H*np.full(S[\"nH\"],PENALTY)]\n",
    "            continue\n",
    "\n",
    "        Bhat = aB*Bm\n",
    "        Hhat = np.clip(b0H + b1H*Hm, 0, 1)\n",
    "\n",
    "        b = (Bhat[S[\"maskB\"]] - S[\"B\"][S[\"maskB\"]])\n",
    "        h = (Hhat[S[\"maskH\"]] - S[\"H\"][S[\"maskH\"]])\n",
    "        b = np.where(np.isfinite(b), b, PENALTY)\n",
    "        h = np.where(np.isfinite(h), h, PENALTY)\n",
    "\n",
    "        res += [W_B*b.astype(float), W_H*h.astype(float)]\n",
    "\n",
    "    # priors — one scalar residual each\n",
    "    index = {name:i for i,name in enumerate(NAMES)}\n",
    "    prior_terms=[]\n",
    "    for name,(mu,sd) in PRIOR.items():\n",
    "        i = index[name]\n",
    "        prior_terms.append((gpar[i]-mu)/(sd + 1e-9))\n",
    "    res.append(np.array(prior_terms,float))\n",
    "\n",
    "    return np.concatenate(res)\n",
    "\n",
    "fit = least_squares(residuals, x0, bounds=(LB,UB),\n",
    "                    verbose=2, max_nfev=1000, loss=\"soft_l1\", f_scale=1.0)\n",
    "\n",
    "gpar_hat, triples_hat = unpack(fit.x)\n",
    "pd.Series(gpar_hat, index=NAMES).to_csv(os.path.join(OUTDIR,\"fitted_global_params.csv\"), header=False)\n",
    "pd.DataFrame(\n",
    "    [{\"subject_id\":S[\"sid\"], \"alpha_B\":tr[0], \"beta0_H\":tr[1], \"beta1_H\":tr[2]}\n",
    "     for S,tr in zip(subs, triples_hat)]\n",
    ").to_csv(os.path.join(OUTDIR,\"fitted_subject_scales.csv\"), index=False)\n",
    "\n",
    "print(\"[info] Fitted globals:\", dict(zip(NAMES, gpar_hat)))\n",
    "\n",
    "# quick small diagnostics (first few)\n",
    "for S,tr in list(zip(subs, triples_hat))[:8]:\n",
    "    aB,b0,b1 = tr\n",
    "    ts=S[\"t\"]; H0=np.clip(S[\"H0\"],0,1); B0=max(0.05,S[\"B0\"])\n",
    "    M0=0.12; q0=1.0 if H0 < 0.5*(gpar_hat[10]+gpar_hat[11]) else 0.0\n",
    "    y0=[M0,H0,B0,q0]\n",
    "    sol=solve_ivp(lambda t,z: rhs(t,z,gpar_hat),(ts[0],ts[-1]),y0,t_eval=ts,\n",
    "                  rtol=1e-6,atol=1e-8,max_step=0.5)\n",
    "    M,H,B,q = sol.y\n",
    "    Bhat=aB*B; Hhat=np.clip(b0 + b1*H,0,1)\n",
    "    mB,mH=S[\"maskB\"],S[\"maskH\"]\n",
    "\n",
    "    fig,ax=plt.subplots(2,1,figsize=(7,6),sharex=True)\n",
    "    ax[0].plot(ts[mB],Bhat[mB],label=\"Model B (scaled)\")\n",
    "    ax[0].scatter(ts[mB],S[\"B\"][mB],s=18,c=\"k\",label=\"Obs B (z)\")\n",
    "    ax[0].legend(); ax[0].grid(True,ls=\":\")\n",
    "\n",
    "    ax[1].plot(ts[mH],Hhat[mH],label=\"Model H\")\n",
    "    ax[1].scatter(ts[mH],S[\"H\"][mH],s=18,c=\"k\",label=\"H proxy\")\n",
    "    ax[1].axhline(gpar_hat[10],ls=\":\",c=\"gray\",label=\"H_on\")\n",
    "    ax[1].axhline(gpar_hat[11],ls=\"--\",c=\"gray\",label=\"H_off\")\n",
    "    ax[1].legend(); ax[1].grid(True,ls=\":\")\n",
    "    ax[1].set_xlabel(\"time\"); ax[0].set_ylabel(\"B\"); ax[1].set_ylabel(\"H\")\n",
    "    plt.tight_layout(); plt.savefig(os.path.join(OUTDIR,f\"diag_{S['sid']}.png\"),dpi=170); plt.close()\n",
    "\n",
    "print(\"✅ Done. Outputs in:\", OUTDIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ababfc7-3534-4ce5-982e-637696f9e2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bifurcation_and_basins_hill_sat.py\n",
    "# Continuation in d; stability via Jacobian eigs; basins at baseline\n",
    "# for Hill host module + saturable uptake + PF + smooth memory.\n",
    "\n",
    "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.optimize import root\n",
    "\n",
    "FIT = \"mw_fit_out_hill_satpf/fitted_global_params.csv\"   # <- point to the new fit\n",
    "OUT = \"mw_bif_hill_sat\"; os.makedirs(OUT, exist_ok=True)\n",
    "\n",
    "KQ = 40.0\n",
    "g = pd.read_csv(FIT, index_col=0, header=None).squeeze(\"columns\")\n",
    "# p = [r0,rH,K_M,c,d,g,u,K_u,p_low,p_high,H_on,H_off,tau_q,K_B]\n",
    "p = np.array([float(g[k]) for k in g.index.values], float)\n",
    "d_fit = float(p[4])\n",
    "\n",
    "def q_inf(H,q,H_on,H_off): th=(1-q)*H_on + q*H_off; return 1.0/(1.0 + np.exp(-KQ*(H - th)))\n",
    "def dH_hill(B,H,gH,d,K_B,n=2): return gH*(B**n/(K_B**n + B**n))*(1-H) - d*H\n",
    "\n",
    "def rhs(y, pvec, d_override=None):\n",
    "    M,H,B,q = y\n",
    "    r0,rH,K_M,c,d,gH,u,K_u,pL,pH,H_on,H_off,tau,K_B = pvec.copy()\n",
    "    if d_override is not None: d = d_override\n",
    "    pB = pL + (pH - pL)*np.clip(q,0,1)\n",
    "    r_eff = r0 + rH*H\n",
    "    dM = (r_eff - c*pB)*M*(1 - M/K_M)\n",
    "    dH = dH_hill(B,H,gH,d,K_B,2)\n",
    "    uptake = u*H*B/(K_u + B + 1e-9)\n",
    "    dB = pB*M - uptake\n",
    "    dq = (q_inf(H,q,H_on,H_off) - q)/tau\n",
    "    return np.array([dM,dH,dB,dq], float)\n",
    "\n",
    "def jac_fd(fun,y,pvec,dval,eps=1e-7):\n",
    "    f0=fun(y,pvec,dval); J=np.zeros((4,4))\n",
    "    for i in range(4):\n",
    "        y2=y.copy(); y2[i]+=eps\n",
    "        J[:,i]=(fun(y2,pvec,dval)-f0)/eps\n",
    "    return J\n",
    "\n",
    "def find_eq(pvec, dval, guess):\n",
    "    sol = root(lambda yy: rhs(yy, pvec, dval), guess, method=\"hybr\")\n",
    "    if not sol.success: return None, False\n",
    "    y = sol.x\n",
    "    y = np.array([max(0,y[0]), np.clip(y[1],0,1.2), max(0,y[2]), np.clip(y[3],0,1.2)], float)\n",
    "    if not np.all(np.isfinite(y)): return None, False\n",
    "    return y, True\n",
    "\n",
    "# (A) continuation in d\n",
    "d_vals = np.linspace(0.6*d_fit, 1.6*d_fit, 90)\n",
    "seeds = [np.array([0.2,0.25,0.05,1.0]), np.array([0.2,0.90,0.10,0.0]), np.array([0.6,0.60,0.20,0.5])]\n",
    "\n",
    "rows=[]\n",
    "for d in d_vals:\n",
    "    for wi,y0 in enumerate(seeds):\n",
    "        y, ok = find_eq(p, d, y0)\n",
    "        if not ok: continue\n",
    "        J=jac_fd(rhs,y,p,d)\n",
    "        stable = (np.max(np.real(np.linalg.eigvals(J)))<0)\n",
    "        rows.append({\"d\":d,\"H\":float(y[1]),\"q\":float(y[3]),\"seed\":wi,\"stable\":stable})\n",
    "branches = pd.DataFrame(rows)\n",
    "branches.to_csv(os.path.join(OUT,\"branches.csv\"), index=False)\n",
    "\n",
    "plt.figure(figsize=(7.2,5.0))\n",
    "for wi in sorted(branches[\"seed\"].unique()):\n",
    "    sub=branches[branches[\"seed\"]==wi]\n",
    "    plt.plot(sub[\"d\"], sub[\"H\"], \".\", ms=3, alpha=0.7, label=f\"seed{wi}\")\n",
    "for st, mk in [(True,\"o\"),(False,\"x\")]:\n",
    "    sub=branches[branches[\"stable\"]==st]\n",
    "    plt.scatter(sub[\"d\"], sub[\"H\"], s=22, marker=mk, alpha=0.6, label=(\"stable\" if st else \"unstable\"))\n",
    "plt.axvline(d_fit, ls=\"--\", c=\"gray\", label=\"baseline d\")\n",
    "plt.xlabel(\"d (1/h)\"); plt.ylabel(\"H*\"); plt.legend(); plt.grid(True, ls=\":\")\n",
    "plt.tight_layout(); plt.savefig(os.path.join(OUT,\"bifurcation_H_vs_d.png\"), dpi=180); plt.close()\n",
    "\n",
    "# (B) bistable at baseline?\n",
    "near = branches[np.isclose(branches[\"d\"], d_fit, atol=1e-3)]\n",
    "distinct=0\n",
    "if not near.empty:\n",
    "    Hs = np.sort(near.loc[near[\"stable\"], \"H\"].values)\n",
    "    if Hs.size:\n",
    "        distinct=1\n",
    "        for i in range(1,len(Hs)):\n",
    "            if abs(Hs[i]-Hs[i-1])>1e-3:\n",
    "                distinct+=1\n",
    "bistable = (distinct>=2)\n",
    "\n",
    "# (C) basins at baseline\n",
    "Hs = np.linspace(0.2, 0.95, 17)\n",
    "qs = np.linspace(0.0, 1.0, 17)\n",
    "Z = np.zeros((len(Hs), len(qs)))\n",
    "\n",
    "def relax(y0,T=320):\n",
    "    sol=solve_ivp(lambda t,z: rhs(z,p,d_fit),(0,T),y0,t_eval=np.linspace(0,T,900),\n",
    "                  rtol=1e-6,atol=1e-8,max_step=0.5)\n",
    "    return sol.y[:,-1]\n",
    "\n",
    "for i,H0 in enumerate(Hs):\n",
    "    for j,q0 in enumerate(qs):\n",
    "        y0=np.array([0.2,H0,0.1,q0],float)\n",
    "        yss=relax(y0)\n",
    "        Z[i,j]=yss[1]\n",
    "\n",
    "plt.figure(figsize=(6.6,5.2))\n",
    "plt.imshow(Z, origin=\"lower\", extent=[qs[0],qs[-1],Hs[0],Hs[-1]],\n",
    "           aspect=\"auto\", vmin=0.5, vmax=1.0, cmap=\"viridis\")\n",
    "plt.colorbar(label=\"Final H (steady)\")\n",
    "plt.xlabel(\"initial q\"); plt.ylabel(\"initial H\")\n",
    "plt.title(f\"Basins at baseline d={d_fit:.3f}\")\n",
    "plt.tight_layout(); plt.savefig(os.path.join(OUT,\"basins_heatmap.png\"), dpi=180); plt.close()\n",
    "\n",
    "with open(os.path.join(OUT,\"diagnosis.txt\"),\"w\") as f:\n",
    "    f.write(f\"Baseline d = {d_fit:.5f}\\n\")\n",
    "    f.write(f\"Distinct stable equilibria at baseline: {distinct}\\n\")\n",
    "    f.write(f\"Bistable at baseline? {'YES' if bistable else 'NO'}\\n\")\n",
    "\n",
    "print(\"Saved ->\", OUT, \"| Bistable at baseline? \", \"YES\" if bistable else \"NO\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb386e3-8bec-4453-8dee-ec5fb41dd416",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calibrate_hysteresis_from_scored_hill_satpf_strict.py\n",
    "# Hill host benefit (n=3) + saturable uptake + smooth memory + weak PF\n",
    "# Tighter, literature-plausible bounds/priors to avoid monostable corners.\n",
    "\n",
    "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "# ----------------- Paths & config -----------------\n",
    "INPATH = \"timeseries/combined_scfas_table_scored.csv\"\n",
    "OUTDIR = \"mw_fit_out_hill_satpf_strict\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "H_COLS = [\"H_proxy_meta_smooth\",\"H_proxy_meta\"]\n",
    "SCFA_COLS = [\"butyrate\"]\n",
    "\n",
    "MIN_ROWS  = 4\n",
    "KQ        = 80.0            # sharper memory\n",
    "PENALTY   = 1e3\n",
    "HILL_N    = 3               # stronger curvature in H benefit\n",
    "\n",
    "# ---- Priors (center, sd) ----\n",
    "PRIOR = {\n",
    "    \"r0\":    (0.35, 0.08),\n",
    "    \"rH\":    (0.08, 0.04),\n",
    "    \"d\":     (0.12, 0.05),\n",
    "    \"g\":     (0.60, 0.25),\n",
    "    \"u\":     (0.60, 0.10),   # tighter around 0.6 to avoid u→upper bound\n",
    "    \"K_u\":   (0.20, 0.06),\n",
    "    \"K_B\":   (0.20, 0.06),\n",
    "    \"c\":     (0.12, 0.04),\n",
    "    \"p_low\": (0.12, 0.05),\n",
    "    \"p_high\":(2.30, 0.50),\n",
    "    \"H_on\":  (0.62, 0.08),\n",
    "    \"H_off\": (0.86, 0.04),\n",
    "    \"tau_q\": (5.00, 2.00),\n",
    "}\n",
    "\n",
    "# ---- Bounds (tighter; keep away from the corners you hit) ----\n",
    "# p = [r0,rH,K_M,c,d,g,u,K_u,p_low,p_high,H_on,H_off,tau_q,K_B]\n",
    "LBg = np.array([0.25, 0.02, 0.7, 0.08, 0.06, 0.20, 0.45, 0.12, 0.06, 1.6, 0.55, 0.80, 2.0, 0.10])\n",
    "UBg = np.array([0.45, 0.15, 1.5, 0.18, 0.22, 1.20, 0.75, 0.30, 0.25, 3.0, 0.75, 0.92, 10.0, 0.35])\n",
    "\n",
    "x0g = np.array([\n",
    "    PRIOR[\"r0\"][0], PRIOR[\"rH\"][0], 1.0, PRIOR[\"c\"][0], PRIOR[\"d\"][0], PRIOR[\"g\"][0],\n",
    "    PRIOR[\"u\"][0], PRIOR[\"K_u\"][0], PRIOR[\"p_low\"][0], PRIOR[\"p_high\"][0],\n",
    "    PRIOR[\"H_on\"][0], PRIOR[\"H_off\"][0], PRIOR[\"tau_q\"][0], PRIOR[\"K_B\"][0]\n",
    "], float)\n",
    "\n",
    "# ----------------- Load & prep data -----------------\n",
    "df = pd.read_csv(INPATH)\n",
    "if not {\"subject_id\",\"sample_id\"}.issubset(df.columns):\n",
    "    raise ValueError(\"CSV must contain 'subject_id' and 'sample_id'.\")\n",
    "Hcol = next((c for c in H_COLS if c in df.columns), None)\n",
    "if Hcol is None:\n",
    "    raise ValueError(\"Need H_proxy_meta_smooth or H_proxy_meta in the CSV.\")\n",
    "for c in SCFA_COLS:\n",
    "    if c not in df.columns:\n",
    "        raise ValueError(f\"Missing SCFA column '{c}'.\")\n",
    "\n",
    "keep = [\"subject_id\",\"sample_id\",Hcol] + SCFA_COLS\n",
    "df = df[keep].dropna(subset=[\"subject_id\",\"sample_id\"]).copy()\n",
    "df[\"t_idx\"] = df.groupby(\"subject_id\").cumcount().astype(float)\n",
    "\n",
    "def robust_z(s: pd.Series) -> pd.Series:\n",
    "    x=s.astype(float).to_numpy(); m=np.isfinite(x)\n",
    "    if m.sum()==0: return pd.Series(np.zeros_like(x), index=s.index)\n",
    "    xm=x[m]; med=np.median(xm); mad=np.median(np.abs(xm-med))\n",
    "    if mad<1e-9:\n",
    "        q75,q25=np.percentile(xm,[75,25]); iqr=q75-q25\n",
    "        scale=iqr if iqr>1e-9 else (np.std(xm)+1e-9)\n",
    "    else:\n",
    "        scale=mad\n",
    "    return pd.Series((x-med)/(scale+1e-9), index=s.index)\n",
    "\n",
    "for c in SCFA_COLS:\n",
    "    df[c+\"_z\"] = df.groupby(\"subject_id\")[c].transform(robust_z)\n",
    "\n",
    "df[\"B_obs\"] = df[SCFA_COLS[0]+\"_z\"] if len(SCFA_COLS)==1 else df[[c+\"_z\" for c in SCFA_COLS]].mean(axis=1)\n",
    "df[\"H_obs\"] = df[Hcol].clip(0,1)\n",
    "\n",
    "subs=[]\n",
    "for sid, sub in df.groupby(\"subject_id\"):\n",
    "    sub=sub.sort_values(\"t_idx\").copy()\n",
    "    if len(sub)<MIN_ROWS: continue\n",
    "    t=sub[\"t_idx\"].values.astype(float)\n",
    "    B=sub[\"B_obs\"].values.astype(float)\n",
    "    H=sub[\"H_obs\"].values.astype(float)\n",
    "    mB=np.isfinite(B); mH=np.isfinite(H)\n",
    "    if mB.sum()<3 or mH.sum()<3: continue\n",
    "    def first(a,d):\n",
    "        a=np.asarray(a,float); idx=np.where(np.isfinite(a))[0]\n",
    "        return float(a[idx[0]]) if len(idx) else float(d)\n",
    "    subs.append({\n",
    "        \"sid\":sid, \"t\":t, \"B\":B, \"H\":H,\n",
    "        \"maskB\":mB, \"maskH\":mH,\n",
    "        \"nB\":int(mB.sum()), \"nH\":int(mH.sum()),\n",
    "        \"H0\":float(np.clip(first(H,0.6),0,1)),\n",
    "        \"B0\":float(max(0.05, first(B,0.1))),\n",
    "    })\n",
    "if not subs:\n",
    "    raise RuntimeError(\"No subject passed minimal data filters.\")\n",
    "print(f\"[info] Fitting {len(subs)} subjects...\")\n",
    "\n",
    "# ----------------- Model -----------------\n",
    "# y=[M,H,B,q]; p=[r0,rH,K_M,c,d,g,u,K_u,p_low,p_high,H_on,H_off,tau_q,K_B]\n",
    "NAMES = [\"r0\",\"rH\",\"K_M\",\"c\",\"d\",\"g\",\"u\",\"K_u\",\"p_low\",\"p_high\",\"H_on\",\"H_off\",\"tau_q\",\"K_B\"]\n",
    "\n",
    "def q_inf(H,q,H_on,H_off,k=KQ):\n",
    "    th=(1.0-q)*H_on + q*H_off\n",
    "    return 1.0/(1.0 + np.exp(-k*(H - th)))\n",
    "\n",
    "def dH_hill(B,H,gH,d,K_B,n=HILL_N):\n",
    "    return gH*(B**n/(K_B**n + B**n))*(1 - H) - d*H\n",
    "\n",
    "def rhs(t,y,p):\n",
    "    M,H,B,q=y\n",
    "    r0,rH,K_M,c,d,gH,u,K_u,pL,pH,H_on,H_off,tau,K_B=p\n",
    "    pB = pL + (pH - pL)*np.clip(q,0,1)\n",
    "    r_eff = r0 + rH*H\n",
    "    dM = (r_eff - c*pB)*M*(1 - M/K_M)\n",
    "    dH = dH_hill(B,H,gH,d,K_B)\n",
    "    uptake = u*H*B/(K_u + B + 1e-9)\n",
    "    dB = pB*M - uptake\n",
    "    dq = (q_inf(H,q,H_on,H_off) - q)/tau\n",
    "    return [dM,dH,dB,dq]\n",
    "\n",
    "def simulate(ts,y0,p):\n",
    "    try:\n",
    "        sol=solve_ivp(lambda t,z: rhs(t,z,p),(ts[0],ts[-1]),y0,t_eval=ts,\n",
    "                      rtol=1e-6,atol=1e-8,max_step=0.5)\n",
    "        if not sol.success:\n",
    "            T=len(ts); return np.vstack([np.full(T,np.nan)]*4)\n",
    "        return sol.y\n",
    "    except Exception:\n",
    "        T=len(ts); return np.vstack([np.full(T,np.nan)]*4)\n",
    "\n",
    "# modest per-subject observation maps (don’t let them absorb dynamics)\n",
    "x0s=[]; LBs=[]; UBs=[]\n",
    "for _ in subs:\n",
    "    x0s += [1.0, 0.0, 1.0]   # alpha_B, beta0_H, beta1_H\n",
    "    LBs += [0.6, -0.2, 0.8]\n",
    "    UBs += [1.6,  0.2, 1.2]\n",
    "\n",
    "x0 = np.concatenate([x0g, np.array(x0s,float)])\n",
    "LB = np.concatenate([LBg, np.array(LBs,float)])\n",
    "UB = np.concatenate([UBg, np.array(UBs,float)])\n",
    "\n",
    "def unpack(x):\n",
    "    gpar = x[:len(NAMES)]\n",
    "    triples = np.split(x[len(NAMES):], len(subs))\n",
    "    return gpar, triples\n",
    "\n",
    "# weights — give H more influence than B\n",
    "W_B, W_H = 0.5, 1.3\n",
    "\n",
    "TOTLEN = sum(S[\"nB\"] + S[\"nH\"] for S in subs) + len(PRIOR)\n",
    "\n",
    "def residuals(x):\n",
    "    gpar, triples = unpack(x)\n",
    "    # guards\n",
    "    if not (gpar[11] > gpar[10]):          # H_off > H_on\n",
    "        return np.full(TOTLEN, PENALTY)\n",
    "    if gpar[13] <= 0.08 or gpar[7] <= 0.08:  # K_B, K_u\n",
    "        return np.full(TOTLEN, PENALTY)\n",
    "\n",
    "    res=[]\n",
    "    for S, tr in zip(subs, triples):\n",
    "        aB, b0H, b1H = tr\n",
    "        ts=S[\"t\"]; H0=np.clip(S[\"H0\"],0,1); B0=max(0.05,S[\"B0\"])\n",
    "        M0=0.12; q0 = 1.0 if H0 < 0.5*(gpar[10]+gpar[11]) else 0.0\n",
    "        y0=[M0,H0,B0,q0]\n",
    "        Y=simulate(ts, y0, gpar)\n",
    "        _, Hm, Bm, _ = Y\n",
    "        if np.any(~np.isfinite(Hm)) or np.any(~np.isfinite(Bm)):\n",
    "            res += [W_B*np.full(S[\"nB\"],PENALTY), W_H*np.full(S[\"nH\"],PENALTY)]\n",
    "            continue\n",
    "\n",
    "        Bhat = aB*Bm\n",
    "        Hhat = np.clip(b0H + b1H*Hm, 0, 1)\n",
    "\n",
    "        b = (Bhat[S[\"maskB\"]] - S[\"B\"][S[\"maskB\"]])\n",
    "        h = (Hhat[S[\"maskH\"]] - S[\"H\"][S[\"maskH\"]])\n",
    "        b = np.where(np.isfinite(b), b, PENALTY)\n",
    "        h = np.where(np.isfinite(h), h, PENALTY)\n",
    "\n",
    "        res += [W_B*b.astype(float), W_H*h.astype(float)]\n",
    "\n",
    "    # priors — one scalar residual each\n",
    "    index = {name:i for i,name in enumerate(NAMES)}\n",
    "    prior_terms=[]\n",
    "    for name,(mu,sd) in PRIOR.items():\n",
    "        i=index[name]; prior_terms.append((gpar[i]-mu)/(sd + 1e-9))\n",
    "    res.append(np.array(prior_terms,float))\n",
    "\n",
    "    return np.concatenate(res)\n",
    "\n",
    "fit = least_squares(residuals, x0, bounds=(LB,UB),\n",
    "                    verbose=2, max_nfev=1200, loss=\"soft_l1\", f_scale=1.0)\n",
    "\n",
    "gpar_hat, triples_hat = unpack(fit.x)\n",
    "pd.Series(gpar_hat, index=NAMES).to_csv(os.path.join(OUTDIR,\"fitted_global_params.csv\"), header=False)\n",
    "pd.DataFrame(\n",
    "    [{\"subject_id\":S[\"sid\"], \"alpha_B\":tr[0], \"beta0_H\":tr[1], \"beta1_H\":tr[2]}\n",
    "     for S,tr in zip(subs, triples_hat)]\n",
    ").to_csv(os.path.join(OUTDIR,\"fitted_subject_scales.csv\"), index=False)\n",
    "\n",
    "print(\"[info] Fitted globals:\", dict(zip(NAMES, gpar_hat)))\n",
    "\n",
    "# quick diag for first few\n",
    "for S,tr in list(zip(subs, triples_hat))[:8]:\n",
    "    aB,b0,b1=tr\n",
    "    ts=S[\"t\"]; H0=np.clip(S[\"H0\"],0,1); B0=max(0.05,S[\"B0\"])\n",
    "    M0=0.12; q0=1.0 if H0 < 0.5*(gpar_hat[10]+gpar_hat[11]) else 0.0\n",
    "    y0=[M0,H0,B0,q0]\n",
    "    sol=solve_ivp(lambda t,z: rhs(t,z,gpar_hat),(ts[0],ts[-1]),y0,t_eval=ts,\n",
    "                  rtol=1e-6,atol=1e-8,max_step=0.5)\n",
    "    M,H,B,q=sol.y\n",
    "    Bhat=aB*B; Hhat=np.clip(b0 + b1*H,0,1)\n",
    "    mB,mH=S[\"maskB\"],S[\"maskH\"]\n",
    "    fig,ax=plt.subplots(2,1,figsize=(7,6),sharex=True)\n",
    "    ax[0].plot(ts[mB],Bhat[mB]); ax[0].scatter(ts[mB],S[\"B\"][mB],s=18,c=\"k\")\n",
    "    ax[0].grid(True,ls=\":\")\n",
    "    ax[1].plot(ts[mH],Hhat[mH]); ax[1].scatter(ts[mH],S[\"H\"][mH],s=18,c=\"k\")\n",
    "    ax[1].axhline(gpar_hat[10],ls=\":\",c=\"gray\"); ax[1].axhline(gpar_hat[11],ls=\"--\",c=\"gray\")\n",
    "    ax[1].grid(True,ls=\":\"); ax[1].set_xlabel(\"time\")\n",
    "    plt.tight_layout(); plt.savefig(os.path.join(OUTDIR,f\"diag_{S['sid']}.png\"),dpi=170); plt.close()\n",
    "\n",
    "print(\"✅ Done. Outputs in:\", OUTDIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9ec1a7-a166-4f1e-bec8-1a10387ef166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bifurcation_and_basins_hill_sat_strict.py\n",
    "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.optimize import root\n",
    "\n",
    "FIT = \"mw_fit_out_hill_satpf_strict/fitted_global_params.csv\"\n",
    "OUT = \"mw_bif_hill_sat_strict\"; os.makedirs(OUT, exist_ok=True)\n",
    "\n",
    "KQ=80.0\n",
    "g = pd.read_csv(FIT, index_col=0, header=None).squeeze(\"columns\")\n",
    "# p=[r0,rH,K_M,c,d,g,u,K_u,p_low,p_high,H_on,H_off,tau_q,K_B]\n",
    "p = np.array([float(g[k]) for k in g.index.values], float)\n",
    "d_fit = float(p[4]); HILL_N=3\n",
    "\n",
    "def q_inf(H,q,H_on,H_off): th=(1-q)*H_on+q*H_off; return 1.0/(1.0+np.exp(-KQ*(H-th)))\n",
    "def dH(B,H,gH,d,K_B,n=HILL_N): return gH*(B**n/(K_B**n + B**n))*(1-H) - d*H\n",
    "def rhs(y,pvec,dval=None):\n",
    "    M,H,B,q=y\n",
    "    r0,rH,K_M,c,d,gH,u,K_u,pL,pH,H_on,H_off,tau,K_B=pvec.copy()\n",
    "    if dval is not None: d=dval\n",
    "    pB=pL+(pH-pL)*np.clip(q,0,1)\n",
    "    r_eff=r0+rH*H\n",
    "    uptake=u*H*B/(K_u + B + 1e-9)\n",
    "    return np.array([\n",
    "        (r_eff - c*pB)*M*(1 - M/K_M),\n",
    "        dH(B,H,gH,d,K_B),\n",
    "        pB*M - uptake,\n",
    "        (q_inf(H,q,H_on,H_off)-q)/tau\n",
    "    ], float)\n",
    "\n",
    "def jac_fd(fun,y,pvec,dval,eps=1e-7):\n",
    "    f0=fun(y,pvec,dval); J=np.zeros((4,4))\n",
    "    for i in range(4):\n",
    "        y2=y.copy(); y2[i]+=eps\n",
    "        J[:,i]=(fun(y2,pvec,dval)-f0)/eps\n",
    "    return J\n",
    "\n",
    "def find_eq(pvec,dval,guess):\n",
    "    sol=root(lambda yy: rhs(yy,pvec,dval), guess, method=\"hybr\")\n",
    "    if not sol.success: return None, False\n",
    "    y=sol.x\n",
    "    y=np.array([max(0,y[0]), np.clip(y[1],0,1.2), max(0,y[2]), np.clip(y[3],0,1.2)], float)\n",
    "    if not np.all(np.isfinite(y)): return None, False\n",
    "    return y, True\n",
    "\n",
    "# continuation in d\n",
    "d_vals=np.linspace(0.7*d_fit, 1.6*d_fit, 110)\n",
    "seeds=[np.array([0.2,0.25,0.05,1.0]),\n",
    "       np.array([0.2,0.90,0.10,0.0]),\n",
    "       np.array([0.6,0.60,0.20,0.5]),\n",
    "       np.array([0.1,0.80,0.05,0.8])]\n",
    "rows=[]\n",
    "for d in d_vals:\n",
    "    for wi,y0 in enumerate(seeds):\n",
    "        y,ok=find_eq(p,d,y0)\n",
    "        if not ok: continue\n",
    "        J=jac_fd(rhs,y,p,d)\n",
    "        stable=(np.max(np.real(np.linalg.eigvals(J)))<0)\n",
    "        rows.append({\"d\":d,\"H\":float(y[1]),\"q\":float(y[3]),\"seed\":wi,\"stable\":stable})\n",
    "branches=pd.DataFrame(rows)\n",
    "branches.to_csv(os.path.join(OUT,\"branches.csv\"), index=False)\n",
    "\n",
    "plt.figure(figsize=(7.2,5.0))\n",
    "for wi in sorted(branches[\"seed\"].unique()):\n",
    "    sub=branches[branches[\"seed\"]==wi]\n",
    "    plt.plot(sub[\"d\"], sub[\"H\"], \".\", ms=3, alpha=0.7, label=f\"seed{wi}\")\n",
    "for st, mk in [(True,\"o\"),(False,\"x\")]:\n",
    "    sub=branches[branches[\"stable\"]==st]\n",
    "    plt.scatter(sub[\"d\"], sub[\"H\"], s=22, marker=mk, alpha=0.6, label=(\"stable\" if st else \"unstable\"))\n",
    "plt.axvline(d_fit, ls=\"--\", c=\"gray\", label=\"baseline d\")\n",
    "plt.xlabel(\"d (1/h)\"); plt.ylabel(\"H*\"); plt.legend(); plt.grid(True, ls=\":\")\n",
    "plt.tight_layout(); plt.savefig(os.path.join(OUT,\"bifurcation_H_vs_d.png\"), dpi=180); plt.close()\n",
    "\n",
    "near=branches[np.isclose(branches[\"d\"], d_fit, atol=1e-3)]\n",
    "distinct=0\n",
    "if not near.empty:\n",
    "    Hs=np.sort(near.loc[near[\"stable\"],\"H\"].values)\n",
    "    if Hs.size:\n",
    "        distinct=1\n",
    "        for i in range(1,len(Hs)):\n",
    "            if abs(Hs[i]-Hs[i-1])>1e-3:\n",
    "                distinct+=1\n",
    "bistable=(distinct>=2)\n",
    "\n",
    "# basins at baseline\n",
    "Hs=np.linspace(0.25,0.95,19)\n",
    "qs=np.linspace(0.0,1.0,21)\n",
    "Z=np.zeros((len(Hs),len(qs)))\n",
    "def relax(y0,T=360):\n",
    "    sol=solve_ivp(lambda t,z: rhs(z,p,d_fit),(0,T),y0,t_eval=np.linspace(0,T,900),\n",
    "                  rtol=1e-6,atol=1e-8,max_step=0.5)\n",
    "    return sol.y[:,-1]\n",
    "for i,H0 in enumerate(Hs):\n",
    "    for j,q0 in enumerate(qs):\n",
    "        y0=np.array([0.2,H0,0.1,q0],float)\n",
    "        yss=relax(y0)\n",
    "        Z[i,j]=yss[1]\n",
    "plt.figure(figsize=(6.6,5.2))\n",
    "plt.imshow(Z, origin=\"lower\", extent=[qs[0],qs[-1],Hs[0],Hs[-1]],\n",
    "           aspect=\"auto\", vmin=0.5, vmax=1.0, cmap=\"viridis\")\n",
    "plt.colorbar(label=\"Final H (steady)\")\n",
    "plt.xlabel(\"initial q\"); plt.ylabel(\"initial H\")\n",
    "plt.title(f\"Basins at baseline d={d_fit:.3f}\")\n",
    "plt.tight_layout(); plt.savefig(os.path.join(OUT,\"basins_heatmap.png\"), dpi=180); plt.close()\n",
    "\n",
    "with open(os.path.join(OUT,\"diagnosis.txt\"),\"w\") as f:\n",
    "    f.write(f\"Baseline d = {d_fit:.5f}\\n\")\n",
    "    f.write(f\"Distinct stable equilibria at baseline: {distinct}\\n\")\n",
    "    f.write(f\"Bistable at baseline? {'YES' if bistable else 'NO'}\\n\")\n",
    "\n",
    "print(\"Saved ->\", OUT, \"| Bistable at baseline? \", \"YES\" if bistable else \"NO\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f03574-e8da-41f9-8b3e-4001c89fb87d",
   "metadata": {},
   "source": [
    "### two-guild (P,C) + Hill host + saturable uptake + smooth memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e25dc6-f2cb-434c-b470-e028897121e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate_guild_hill_satpf.py\n",
    "# -------------------------------------------------------------\n",
    "# Minimal two-guild ecology (Producer P makes butyrate; Competitor C)\n",
    "# + Hill host benefit (n=2)\n",
    "# + Saturable uptake of butyrate\n",
    "# + Smooth \"memory\" q with H_on/H_off band\n",
    "#\n",
    "# Observables: stool butyrate intensity (per-subject z) and a host proxy H.\n",
    "# We fit global params + per-subject linear observation maps for B and H.\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "# ---------- Config ----------\n",
    "INPATH = \"timeseries/combined_scfas_table_scored.csv\"\n",
    "OUTDIR = \"mw_fit_out_guild_hill_satpf\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "H_COLS    = [\"H_proxy_meta_smooth\",\"H_proxy_meta\"]\n",
    "SCFA_COLS = [\"butyrate\"]\n",
    "\n",
    "MIN_ROWS  = 4\n",
    "KQ        = 60.0         # memory steepness\n",
    "PENALTY   = 1e3\n",
    "HILL_N    = 2            # Hill exponent in host benefit\n",
    "\n",
    "# ---------- Priors (mu, sd) ----------\n",
    "# p = [r0P, rHP, r0C, K_M, gamma, c, d, g, u, K_u, p_low, p_high, H_on, H_off, tau_q, K_B]\n",
    "PRIOR = {\n",
    "    \"r0P\":   (0.32, 0.08),\n",
    "    \"rHP\":   (0.07, 0.04),    # weak positive feedback P growth vs H\n",
    "    \"r0C\":   (0.28, 0.08),\n",
    "    \"K_M\":   (1.00, 0.25),\n",
    "    \"gamma\": (0.85, 0.25),    # cross-competition factor (P↔C)\n",
    "    \"c\":     (0.12, 0.05),    # cost of production\n",
    "    \"d\":     (0.12, 0.05),\n",
    "    \"g\":     (0.60, 0.30),\n",
    "    \"u\":     (0.60, 0.15),\n",
    "    \"K_u\":   (0.20, 0.08),\n",
    "    \"p_low\": (0.12, 0.06),\n",
    "    \"p_high\":(2.20, 0.60),\n",
    "    \"H_on\":  (0.60, 0.08),\n",
    "    \"H_off\": (0.86, 0.04),\n",
    "    \"tau_q\": (5.00, 2.00),\n",
    "    \"K_B\":   (0.20, 0.08),\n",
    "}\n",
    "\n",
    "# ---------- Bounds (tight but realistic) ----------\n",
    "LBg = np.array([0.18, 0.00, 0.15, 0.55, 0.40, 0.06, 0.06, 0.20, 0.45, 0.10, 0.06, 1.3, 0.50, 0.80, 1.0, 0.10])\n",
    "UBg = np.array([0.46, 0.14, 0.40, 1.60, 1.40, 0.20, 0.22, 1.40, 0.85, 0.40, 0.28, 3.2, 0.74, 0.92, 10., 0.40])\n",
    "\n",
    "x0g = np.array([\n",
    "    PRIOR[\"r0P\"][0], PRIOR[\"rHP\"][0], PRIOR[\"r0C\"][0], PRIOR[\"K_M\"][0], PRIOR[\"gamma\"][0],\n",
    "    PRIOR[\"c\"][0], PRIOR[\"d\"][0], PRIOR[\"g\"][0], PRIOR[\"u\"][0], PRIOR[\"K_u\"][0],\n",
    "    PRIOR[\"p_low\"][0], PRIOR[\"p_high\"][0], PRIOR[\"H_on\"][0], PRIOR[\"H_off\"][0],\n",
    "    PRIOR[\"tau_q\"][0], PRIOR[\"K_B\"][0]\n",
    "], float)\n",
    "\n",
    "# ---------- Load & prep data ----------\n",
    "df = pd.read_csv(INPATH)\n",
    "if not {\"subject_id\",\"sample_id\"}.issubset(df.columns):\n",
    "    raise ValueError(\"CSV must have subject_id, sample_id\")\n",
    "Hcol = next((c for c in H_COLS if c in df.columns), None)\n",
    "if Hcol is None:\n",
    "    raise ValueError(\"Need H_proxy_meta_smooth or H_proxy_meta\")\n",
    "\n",
    "for c in SCFA_COLS:\n",
    "    if c not in df.columns:\n",
    "        raise ValueError(f\"Missing SCFA column {c}\")\n",
    "\n",
    "df = df[[\"subject_id\",\"sample_id\",Hcol]+SCFA_COLS].dropna(subset=[\"subject_id\",\"sample_id\"]).copy()\n",
    "df[\"t_idx\"] = df.groupby(\"subject_id\").cumcount().astype(float)\n",
    "\n",
    "def robust_z(s: pd.Series) -> pd.Series:\n",
    "    x=s.astype(float).to_numpy(); m=np.isfinite(x)\n",
    "    if m.sum()==0: return pd.Series(np.zeros_like(x), index=s.index)\n",
    "    xm=x[m]; med=np.median(xm); mad=np.median(np.abs(xm-med))\n",
    "    if mad<1e-9:\n",
    "        q75,q25=np.percentile(xm,[75,25]); iqr=q75-q25\n",
    "        scale=iqr if iqr>1e-9 else (np.std(xm)+1e-9)\n",
    "    else:\n",
    "        scale=mad\n",
    "    return pd.Series((x-med)/(scale+1e-9), index=s.index)\n",
    "\n",
    "for c in SCFA_COLS:\n",
    "    df[c+\"_z\"] = df.groupby(\"subject_id\")[c].transform(robust_z)\n",
    "df[\"B_obs\"] = df[SCFA_COLS[0]+\"_z\"] if len(SCFA_COLS)==1 else df[[c+\"_z\" for c in SCFA_COLS]].mean(axis=1)\n",
    "df[\"H_obs\"] = df[Hcol].clip(0,1)\n",
    "\n",
    "subs=[]\n",
    "for sid, sub in df.groupby(\"subject_id\"):\n",
    "    sub=sub.sort_values(\"t_idx\").copy()\n",
    "    if len(sub)<MIN_ROWS: continue\n",
    "    t=sub[\"t_idx\"].values.astype(float)\n",
    "    B=sub[\"B_obs\"].values.astype(float)\n",
    "    H=sub[\"H_obs\"].values.astype(float)\n",
    "    mB=np.isfinite(B); mH=np.isfinite(H)\n",
    "    if mB.sum()<3 or mH.sum()<3: continue\n",
    "    def first(a,d):\n",
    "        a=np.asarray(a,float); idx=np.where(np.isfinite(a))[0]\n",
    "        return float(a[idx[0]]) if len(idx) else float(d)\n",
    "    subs.append({\n",
    "        \"sid\":sid,\n",
    "        \"t\":t,\"B\":B,\"H\":H,\n",
    "        \"maskB\":mB,\"maskH\":mH,\n",
    "        \"nB\":int(mB.sum()), \"nH\":int(mH.sum()),\n",
    "        \"H0\":float(np.clip(first(H,0.6),0,1)),\n",
    "        \"B0\":float(max(0.05, first(B,0.1))),\n",
    "    })\n",
    "if not subs:\n",
    "    raise RuntimeError(\"No subject passed minimal filters.\")\n",
    "print(f\"[info] Fitting {len(subs)} subjects...\")\n",
    "\n",
    "# ---------- Model ----------\n",
    "# State y = [P, C, H, B, q]\n",
    "# p = [r0P, rHP, r0C, K_M, gamma, c, d, g, u, K_u, p_low, p_high, H_on, H_off, tau_q, K_B]\n",
    "NAMES = [\"r0P\",\"rHP\",\"r0C\",\"K_M\",\"gamma\",\"c\",\"d\",\"g\",\"u\",\"K_u\",\"p_low\",\"p_high\",\"H_on\",\"H_off\",\"tau_q\",\"K_B\"]\n",
    "\n",
    "def q_inf(H,q,H_on,H_off,k=KQ):\n",
    "    th=(1.0-q)*H_on + q*H_off\n",
    "    return 1.0/(1.0 + np.exp(-k*(H - th)))\n",
    "\n",
    "def dH_hill(B,H,gH,d,K_B,n=HILL_N):\n",
    "    return gH*(B**n/(K_B**n + B**n))*(1 - H) - d*H\n",
    "\n",
    "def rhs(t,y,p):\n",
    "    P,C,H,B,q = y\n",
    "    r0P,rHP,r0C,K_M,gamma,c,d,gH,u,K_u,pL,pH,H_on,H_off,tau,K_B = p\n",
    "\n",
    "    pB = pL + (pH - pL)*np.clip(q,0,1)\n",
    "\n",
    "    # gLV-like competition with shared K_M and cross-coefficient gamma\n",
    "    # dP/dt = P*( r0P + rHP*H - c*pB - (P + gamma*C)/K_M )\n",
    "    # dC/dt = C*( r0C           - (C + gamma*P)/K_M )\n",
    "    dP = P*( r0P + rHP*H - c*pB - (P + gamma*C)/K_M )\n",
    "    dC = C*( r0C           -        (C + gamma*P)/K_M )\n",
    "\n",
    "    dH = dH_hill(B,H,gH,d,K_B)\n",
    "    uptake = u*H*B/(K_u + B + 1e-9)\n",
    "    dB = pB*P - uptake\n",
    "    dq = (q_inf(H,q,H_on,H_off) - q)/tau\n",
    "    return [dP,dC,dH,dB,dq]\n",
    "\n",
    "def simulate(ts,y0,p):\n",
    "    try:\n",
    "        sol=solve_ivp(lambda t,z: rhs(t,z,p),(ts[0],ts[-1]),y0,t_eval=ts,\n",
    "                      rtol=1e-6,atol=1e-8,max_step=0.5)\n",
    "        if not sol.success:\n",
    "            T=len(ts); return np.vstack([np.full(T,np.nan)]*5)\n",
    "        return sol.y\n",
    "    except Exception:\n",
    "        T=len(ts); return np.vstack([np.full(T,np.nan)]*5)\n",
    "\n",
    "# Per-subject observation maps (bounded so dynamics must explain signal)\n",
    "# for B: B_hat = alpha_B * B\n",
    "# for H: H_hat = beta0_H + beta1_H * H\n",
    "x0s=[]; LBs=[]; UBs=[]\n",
    "for _ in subs:\n",
    "    x0s += [1.0, 0.0, 1.0]   # alpha_B, beta0_H, beta1_H\n",
    "    LBs += [0.6, -0.2, 0.8]\n",
    "    UBs += [1.6,  0.2, 1.2]\n",
    "\n",
    "x0 = np.concatenate([x0g, np.array(x0s,float)])\n",
    "LB = np.concatenate([LBg, np.array(LBs,float)])\n",
    "UB = np.concatenate([UBg, np.array(UBs,float)])\n",
    "\n",
    "def unpack(x):\n",
    "    gpar = x[:len(NAMES)]\n",
    "    triples = np.split(x[len(NAMES):], len(subs))\n",
    "    return gpar, triples\n",
    "\n",
    "W_B, W_H = 0.6, 1.2\n",
    "TOTLEN = sum(S[\"nB\"] + S[\"nH\"] for S in subs) + len(PRIOR)\n",
    "\n",
    "def residuals(x):\n",
    "    gpar, triples = unpack(x)\n",
    "    if not (gpar[13] > gpar[12]):  # H_off > H_on\n",
    "        return np.full(TOTLEN, PENALTY)\n",
    "    if gpar[9] <= 0.06 or gpar[15] <= 0.06:  # K_u, K_B positive\n",
    "        return np.full(TOTLEN, PENALTY)\n",
    "\n",
    "    res=[]\n",
    "    for S, tr in zip(subs, triples):\n",
    "        aB, b0H, b1H = tr\n",
    "        ts=S[\"t\"]; H0=np.clip(S[\"H0\"],0,1); B0=max(0.05,S[\"B0\"])\n",
    "        # modest initial microbes: producer + competitor\n",
    "        P0 = 0.12\n",
    "        C0 = 0.12\n",
    "        q0 = 1.0 if H0 < 0.5*(gpar[12]+gpar[13]) else 0.0\n",
    "        y0=[P0,C0,H0,B0,q0]\n",
    "        Y=simulate(ts, y0, gpar)\n",
    "        if np.any(~np.isfinite(Y)):\n",
    "            res += [W_B*np.full(S[\"nB\"],PENALTY), W_H*np.full(S[\"nH\"],PENALTY)]\n",
    "            continue\n",
    "        P,C,H,B,q = Y\n",
    "\n",
    "        Bhat = aB*B\n",
    "        Hhat = np.clip(b0H + b1H*H, 0, 1)\n",
    "        b = (Bhat[S[\"maskB\"]] - S[\"B\"][S[\"maskB\"]])\n",
    "        h = (Hhat[S[\"maskH\"]] - S[\"H\"][S[\"maskH\"]])\n",
    "\n",
    "        b = np.where(np.isfinite(b), b, PENALTY)\n",
    "        h = np.where(np.isfinite(h), h, PENALTY)\n",
    "        res += [W_B*b.astype(float), W_H*h.astype(float)]\n",
    "\n",
    "    # priors as pseudo-residuals\n",
    "    idx = {name:i for i,name in enumerate(NAMES)}\n",
    "    prior_terms=[]\n",
    "    for name,(mu,sd) in PRIOR.items():\n",
    "        prior_terms.append( (gpar[idx[name]] - mu)/ (sd + 1e-9) )\n",
    "    res.append(np.array(prior_terms,float))\n",
    "\n",
    "    return np.concatenate(res)\n",
    "\n",
    "fit = least_squares(residuals, x0, bounds=(LB,UB),\n",
    "                    verbose=2, max_nfev=1200, loss=\"soft_l1\", f_scale=1.0)\n",
    "\n",
    "gpar_hat, triples_hat = unpack(fit.x)\n",
    "pd.Series(gpar_hat, index=NAMES).to_csv(os.path.join(OUTDIR,\"fitted_global_params.csv\"), header=False)\n",
    "pd.DataFrame(\n",
    "    [{\"subject_id\":S[\"sid\"], \"alpha_B\":tr[0], \"beta0_H\":tr[1], \"beta1_H\":tr[2]}\n",
    "     for S,tr in zip(subs, triples_hat)]\n",
    ").to_csv(os.path.join(OUTDIR,\"fitted_subject_scales.csv\"), index=False)\n",
    "\n",
    "print(\"[info] Fitted globals:\", dict(zip(NAMES, gpar_hat)))\n",
    "\n",
    "# quick diagnostics (first few)\n",
    "for S,tr in list(zip(subs, triples_hat))[:8]:\n",
    "    aB,b0,b1=tr\n",
    "    ts=S[\"t\"]; H0=np.clip(S[\"H0\"],0,1); B0=max(0.05,S[\"B0\"])\n",
    "    P0=C0=0.12; q0=1.0 if H0 < 0.5*(gpar_hat[12]+gpar_hat[13]) else 0.0\n",
    "    y0=[P0,C0,H0,B0,q0]\n",
    "    sol=solve_ivp(lambda t,z: rhs(t,z,gpar_hat),(ts[0],ts[-1]),y0,t_eval=ts,\n",
    "                  rtol=1e-6,atol=1e-8,max_step=0.5)\n",
    "    P,C,H,B,q=sol.y\n",
    "    Bhat=aB*B; Hhat=np.clip(b0 + b1*H, 0,1)\n",
    "    mB,mH=S[\"maskB\"],S[\"maskH\"]\n",
    "    fig,ax=plt.subplots(2,1,figsize=(7,6),sharex=True)\n",
    "    ax[0].plot(ts[mB],Bhat[mB]); ax[0].scatter(ts[mB],S[\"B\"][mB],s=18,c=\"k\"); ax[0].grid(True,ls=\":\")\n",
    "    ax[1].plot(ts[mH],Hhat[mH]); ax[1].scatter(ts[mH],S[\"H\"][mH],s=18,c=\"k\"); ax[1].grid(True,ls=\":\")\n",
    "    ax[1].axhline(gpar_hat[12],ls=\":\",c=\"gray\"); ax[1].axhline(gpar_hat[13],ls=\"--\",c=\"gray\")\n",
    "    ax[1].set_xlabel(\"time\"); ax[0].set_ylabel(\"B\"); ax[1].set_ylabel(\"H\")\n",
    "    plt.tight_layout(); plt.savefig(os.path.join(OUTDIR,f\"diag_{S['sid']}.png\"),dpi=170); plt.close()\n",
    "\n",
    "print(\"✅ Done. Outputs in:\", OUTDIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2ae366-591c-4a90-a0ed-a1f3cdbd5a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bifurcation_basins_guild_hill_satpf.py\n",
    "# Continuation in d and basins at baseline for the two-guild model.\n",
    "\n",
    "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from scipy.optimize import root\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "FIT = \"mw_fit_out_guild_hill_satpf/fitted_global_params.csv\"\n",
    "OUT = \"mw_bif_guild_hill_satpf\"; os.makedirs(OUT, exist_ok=True)\n",
    "\n",
    "KQ=60.0; HILL_N=2\n",
    "\n",
    "g = pd.read_csv(FIT, index_col=0, header=None).squeeze(\"columns\")\n",
    "# p = [r0P,rHP,r0C,K_M,gamma,c,d,g,u,K_u,p_low,p_high,H_on,H_off,tau_q,K_B]\n",
    "p = np.array([float(g[k]) for k in g.index.values], float)\n",
    "d_fit = float(p[6])\n",
    "\n",
    "def q_inf(H,q,H_on,H_off): th=(1-q)*H_on+q*H_off; return 1.0/(1.0+np.exp(-KQ*(H-th)))\n",
    "def dH_hill(B,H,gH,d,K_B,n=HILL_N): return gH*(B**n/(K_B**n + B**n))*(1-H) - d*H\n",
    "\n",
    "def rhs(y,pvec,d_override=None):\n",
    "    P,C,H,B,q = y\n",
    "    r0P,rHP,r0C,K_M,gamma,c,d,gH,u,K_u,pL,pH,H_on,H_off,tau,K_B = pvec.copy()\n",
    "    if d_override is not None: d = d_override\n",
    "    pB = pL + (pH - pL)*np.clip(q,0,1)\n",
    "    dP = P*( r0P + rHP*H - c*pB - (P + gamma*C)/K_M )\n",
    "    dC = C*( r0C           -          (C + gamma*P)/K_M )\n",
    "    dH = dH_hill(B,H,gH,d,K_B)\n",
    "    uptake = u*H*B/(K_u + B + 1e-9)\n",
    "    dB = pB*P - uptake\n",
    "    dq = (q_inf(H,q,H_on,H_off) - q)/tau\n",
    "    return np.array([dP,dC,dH,dB,dq], float)\n",
    "\n",
    "def jac_fd(fun,y,pvec,dval,eps=1e-7):\n",
    "    f0=fun(y,pvec,dval); J=np.zeros((5,5))\n",
    "    for i in range(5):\n",
    "        y2=y.copy(); y2[i]+=eps\n",
    "        J[:,i]=(fun(y2,pvec,dval)-f0)/eps\n",
    "    return J\n",
    "\n",
    "def find_eq(pvec, dval, guess):\n",
    "    sol=root(lambda yy: rhs(yy,pvec,dval), guess, method=\"hybr\")\n",
    "    if not sol.success: return None, False\n",
    "    y=sol.x\n",
    "    y=np.array([max(0,y[0]), max(0,y[1]), np.clip(y[2],0,1.2), max(0,y[3]), np.clip(y[4],0,1.2)], float)\n",
    "    if not np.all(np.isfinite(y)): return None, False\n",
    "    return y, True\n",
    "\n",
    "# (A) continuation in d\n",
    "d_vals=np.linspace(0.7*d_fit, 1.6*d_fit, 110)\n",
    "seeds=[np.array([0.15,0.05,0.3,0.05,1.0]),\n",
    "       np.array([0.05,0.20,0.9,0.10,0.0]),\n",
    "       np.array([0.30,0.15,0.6,0.15,0.5]),\n",
    "       np.array([0.05,0.05,0.5,0.05,0.8])]\n",
    "\n",
    "rows=[]\n",
    "for d in d_vals:\n",
    "    for wi,y0 in enumerate(seeds):\n",
    "        y, ok = find_eq(p, d, y0)\n",
    "        if not ok: continue\n",
    "        J=jac_fd(rhs,y,p,d)\n",
    "        stable=(np.max(np.real(np.linalg.eigvals(J)))<0)\n",
    "        rows.append({\"d\":d,\"H\":float(y[2]),\"q\":float(y[4]),\"seed\":wi,\"stable\":stable})\n",
    "branches=pd.DataFrame(rows)\n",
    "branches.to_csv(os.path.join(OUT,\"branches.csv\"), index=False)\n",
    "\n",
    "plt.figure(figsize=(7.2,5.0))\n",
    "for wi in sorted(branches[\"seed\"].unique()):\n",
    "    sub=branches[branches[\"seed\"]==wi]\n",
    "    plt.plot(sub[\"d\"], sub[\"H\"], \".\", ms=3, alpha=0.7, label=f\"seed{wi}\")\n",
    "for st, mk in [(True,\"o\"),(False,\"x\")]:\n",
    "    sub=branches[branches[\"stable\"]==st]\n",
    "    plt.scatter(sub[\"d\"], sub[\"H\"], s=22, marker=mk, alpha=0.6, label=(\"stable\" if st else \"unstable\"))\n",
    "plt.axvline(d_fit, ls=\"--\", c=\"gray\", label=\"baseline d\")\n",
    "plt.xlabel(\"d (1/h)\"); plt.ylabel(\"H*\"); plt.legend(); plt.grid(True, ls=\":\")\n",
    "plt.tight_layout(); plt.savefig(os.path.join(OUT,\"bifurcation_H_vs_d.png\"), dpi=180); plt.close()\n",
    "\n",
    "# (B) bistable at baseline?\n",
    "near=branches[np.isclose(branches[\"d\"], d_fit, atol=1e-3)]\n",
    "distinct=0\n",
    "if not near.empty:\n",
    "    Hs=np.sort(near.loc[near[\"stable\"],\"H\"].values)\n",
    "    if Hs.size:\n",
    "        distinct=1\n",
    "        for i in range(1,len(Hs)):\n",
    "            if abs(Hs[i]-Hs[i-1])>1e-3:\n",
    "                distinct+=1\n",
    "bistable=(distinct>=2)\n",
    "\n",
    "# (C) basins at baseline\n",
    "Hs=np.linspace(0.2,0.95,17)\n",
    "qs=np.linspace(0.0,1.0,17)\n",
    "Z=np.zeros((len(Hs),len(qs)))\n",
    "\n",
    "def relax(y0,T=360):\n",
    "    sol=solve_ivp(lambda t,z: rhs(z,p,d_fit),(0,T),y0,t_eval=np.linspace(0,T,1000),\n",
    "                  rtol=1e-6,atol=1e-8,max_step=0.5)\n",
    "    return sol.y[:,-1]\n",
    "\n",
    "for i,H0 in enumerate(Hs):\n",
    "    for j,q0 in enumerate(qs):\n",
    "        y0=np.array([0.12,0.12,H0,0.10,q0],float)\n",
    "        yss=relax(y0)\n",
    "        Z[i,j]=yss[2]\n",
    "\n",
    "plt.figure(figsize=(6.6,5.2))\n",
    "plt.imshow(Z, origin=\"lower\", extent=[qs[0],qs[-1],Hs[0],Hs[-1]],\n",
    "           aspect=\"auto\", vmin=0.5, vmax=1.0, cmap=\"viridis\")\n",
    "plt.colorbar(label=\"Final H (steady)\")\n",
    "plt.xlabel(\"initial q\"); plt.ylabel(\"initial H\")\n",
    "plt.title(f\"Basins at baseline d={d_fit:.3f}\")\n",
    "plt.tight_layout(); plt.savefig(os.path.join(OUT,\"basins_heatmap.png\"), dpi=180); plt.close()\n",
    "\n",
    "with open(os.path.join(OUT,\"diagnosis.txt\"),\"w\") as f:\n",
    "    f.write(f\"Baseline d = {d_fit:.5f}\\n\")\n",
    "    f.write(f\"Distinct stable equilibria at baseline: {distinct}\\n\")\n",
    "    f.write(f\"Bistable at baseline? {'YES' if bistable else 'NO'}\\n\")\n",
    "\n",
    "print(\"Saved ->\", OUT, \"| Bistable at baseline? \", \"YES\" if bistable else \"NO\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cbe14d-1b27-4406-8af5-29a246c52a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scan_bistability_2d_guild.py\n",
    "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from scipy.optimize import root\n",
    "import numpy.linalg as npl\n",
    "\n",
    "FIT = \"mw_fit_out_guild_hill_satpf/fitted_global_params.csv\"\n",
    "OUT = \"mw_scan2d_guild\"; os.makedirs(OUT, exist_ok=True)\n",
    "\n",
    "KQ = 60.0; HILL_N = 2\n",
    "\n",
    "g = pd.read_csv(FIT, index_col=0, header=None).squeeze(\"columns\")\n",
    "# p = [r0P,rHP,r0C,K_M,gamma,c,d,g,u,K_u,p_low,p_high,H_on,H_off,tau_q,K_B]\n",
    "p0 = np.array([float(g[k]) for k in g.index.values], float)\n",
    "d_fit = float(p0[6])\n",
    "\n",
    "def q_inf(H,q,H_on,H_off): th=(1-q)*H_on+q*H_off; return 1.0/(1.0+np.exp(-KQ*(H-th)))\n",
    "def dH(B,H,gH,d,K_B,n=HILL_N): return gH*(B**n/(K_B**n + B**n))*(1-H) - d*H\n",
    "def rhs(y,pvec,d_override=None):\n",
    "    P,C,H,B,q = y\n",
    "    r0P,rHP,r0C,K_M,gamma,c,d,gH,u,K_u,pL,pH,H_on,H_off,tau,K_B = pvec.copy()\n",
    "    if d_override is not None: d = d_override\n",
    "    pB = pL + (pH - pL)*np.clip(q,0,1)\n",
    "    dP = P*( r0P + rHP*H - c*pB - (P + gamma*C)/K_M )\n",
    "    dC = C*( r0C - (C + gamma*P)/K_M )\n",
    "    uptake = u*H*B/(K_u + B + 1e-9)\n",
    "    dB = pB*P - uptake\n",
    "    dH_ = dH(B,H,gH,d,K_B)\n",
    "    dq = (q_inf(H,q,H_on,H_off) - q)/tau\n",
    "    return np.array([dP,dC,dH_,dB,dq], float)\n",
    "\n",
    "def jac_fd(fun,y,pvec,dval,eps=1e-7):\n",
    "    f0=fun(y,pvec,dval); J=np.zeros((5,5))\n",
    "    for i in range(5):\n",
    "        y2=y.copy(); y2[i]+=eps\n",
    "        J[:,i]=(fun(y2,pvec,dval)-f0)/eps\n",
    "    return J\n",
    "\n",
    "def find_eq(pvec, dval, guess):\n",
    "    sol = root(lambda yy: rhs(yy,pvec,dval), guess, method=\"hybr\")\n",
    "    if not sol.success: return None, False\n",
    "    y = sol.x\n",
    "    y = np.array([max(0,y[0]), max(0,y[1]), np.clip(y[2],0,1.2), max(0,y[3]), np.clip(y[4],0,1.2)], float)\n",
    "    if not np.all(np.isfinite(y)): return None, False\n",
    "    return y, True\n",
    "\n",
    "def count_stable_at(pvec, dval, seeds):\n",
    "    Hs=[]\n",
    "    for y0 in seeds:\n",
    "        y, ok = find_eq(pvec, dval, y0)\n",
    "        if not ok: continue\n",
    "        J = jac_fd(rhs, y, pvec, dval)\n",
    "        lam_max = np.max(np.real(npl.eigvals(J)))\n",
    "        if lam_max < 0:\n",
    "            Hs.append(float(y[2]))\n",
    "    Hs = np.array(sorted(Hs))\n",
    "    if Hs.size == 0: return 0\n",
    "    distinct = 1\n",
    "    for i in range(1,len(Hs)):\n",
    "        if abs(Hs[i]-Hs[i-1]) > 1e-3:\n",
    "            distinct += 1\n",
    "    return distinct\n",
    "\n",
    "seeds = [\n",
    "    np.array([0.12,0.12,0.30,0.08,1.0]),\n",
    "    np.array([0.05,0.20,0.85,0.15,0.0]),\n",
    "    np.array([0.30,0.05,0.55,0.10,0.7]),\n",
    "    np.array([0.18,0.18,0.65,0.12,0.4]),\n",
    "]\n",
    "\n",
    "# --- planes to scan: (nameA, idxA, gridA), (nameB, idxB, gridB)\n",
    "planes = []\n",
    "\n",
    "# 1) (u, p_high)\n",
    "u0, pH0 = p0[8], p0[11]\n",
    "planes.append( (\"u\",\"p_high\", 8,11,\n",
    "                np.linspace(max(0.45,u0-0.25), min(0.85,u0+0.10), 13),\n",
    "                np.linspace(max(1.4,pH0-0.6),  min(3.0,pH0+0.8),  13)) )\n",
    "\n",
    "# 2) (gamma, p_high)\n",
    "ga0 = p0[4]\n",
    "planes.append( (\"gamma\",\"p_high\", 4,11,\n",
    "                np.linspace(max(0.5,ga0-0.3), min(1.3,ga0+0.3), 13),\n",
    "                np.linspace(max(1.4,pH0-0.6), min(3.0,pH0+0.8), 13)) )\n",
    "\n",
    "# 3) (K_u, p_high)\n",
    "Ku0 = p0[9]\n",
    "planes.append( (\"K_u\",\"p_high\", 9,11,\n",
    "                np.linspace(max(0.10,Ku0-0.10), min(0.40,Ku0+0.14), 13),\n",
    "                np.linspace(max(1.4,pH0-0.6),  min(3.0,pH0+0.8),  13)) )\n",
    "\n",
    "# 4) (rHP, p_high)\n",
    "rHP0 = p0[1]\n",
    "planes.append( (\"rHP\",\"p_high\", 1,11,\n",
    "                np.linspace(max(0.00,rHP0-0.05), min(0.15,rHP0+0.06), 13),\n",
    "                np.linspace(max(1.4,pH0-0.6),   min(3.0,pH0+0.8),   13)) )\n",
    "\n",
    "for (nameA,nameB,idxA,idxB,gridA,gridB) in planes:\n",
    "    Z = np.zeros((len(gridA), len(gridB)), int)\n",
    "    for i,a in enumerate(gridA):\n",
    "        for j,b in enumerate(gridB):\n",
    "            p = p0.copy()\n",
    "            p[idxA] = a; p[idxB] = b\n",
    "            Z[i,j] = count_stable_at(p, d_fit, seeds)\n",
    "    df = pd.DataFrame(Z, index=np.round(gridA,3), columns=np.round(gridB,3))\n",
    "    df.to_csv(os.path.join(OUT, f\"stablecount_{nameA}_vs_{nameB}.csv\"))\n",
    "    plt.figure(figsize=(6.6,5.2))\n",
    "    plt.imshow(Z, origin=\"lower\",\n",
    "               extent=[gridB[0], gridB[-1], gridA[0], gridA[-1]],\n",
    "               aspect=\"auto\", cmap=\"viridis\", vmin=0, vmax=3)\n",
    "    cbar=plt.colorbar(); cbar.set_label(\"# distinct stable eq at baseline d\")\n",
    "    plt.xlabel(nameB); plt.ylabel(nameA)\n",
    "    plt.title(f\"Distinct stable equilibria at baseline d={d_fit:.3f}\\nplane: {nameA} vs {nameB}\")\n",
    "    plt.tight_layout(); plt.savefig(os.path.join(OUT, f\"heatmap_{nameA}_vs_{nameB}.png\"), dpi=180); plt.close()\n",
    "\n",
    "print(\"Saved ->\", OUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf3e119-90f4-4a2f-8822-72b9fc2c8dc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calibrate_guild_hill_satpf_targeted.py\n",
    "# As calibrate_guild_hill_satpf.py, but adds soft targets for a few params\n",
    "# (from the 2D scan) to gently bias the optimizer toward a bistable pocket.\n",
    "\n",
    "import os, numpy as np, pandas as pd\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "INPATH = \"timeseries/combined_scfas_table_scored.csv\"\n",
    "OUTDIR = \"mw_fit_out_guild_hill_satpf_targeted\"; os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "# --- choose targets after inspecting the heatmaps from scan_bistability_2d_guild.py ---\n",
    "# Example targets (EDIT these based on your heatmaps):\n",
    "TARGETS = {\n",
    "    \"rHP\":   (0.117, 0.04),   # weak positive feedback, modest SD\n",
    "    \"u\":     (0.725, 0.06),   # a bit lower than your fitted 0.85\n",
    "    \"K_u\":   (0.212, 0.06),   # slightly higher saturation half-point\n",
    "    \"gamma\": (1.063, 0.18),   # mildly stronger competition\n",
    "    \"p_high\":(2.092, 0.30),   # more production headroom\n",
    "}\n",
    "\n",
    "# Everything else (data prep/model) mirrors the first two-guild script:\n",
    "H_COLS    = [\"H_proxy_meta_smooth\",\"H_proxy_meta\"]\n",
    "SCFA_COLS = [\"butyrate\"]\n",
    "MIN_ROWS  = 4\n",
    "KQ        = 60.0\n",
    "PENALTY   = 1e3\n",
    "HILL_N    = 2\n",
    "\n",
    "# Baseline priors (kept modest)\n",
    "PRIOR = {\n",
    "    \"r0P\":(0.32,0.08), \"rHP\":(0.07,0.04), \"r0C\":(0.28,0.08), \"K_M\":(1.00,0.25),\n",
    "    \"gamma\":(0.85,0.25), \"c\":(0.12,0.05), \"d\":(0.12,0.05), \"g\":(0.60,0.30),\n",
    "    \"u\":(0.60,0.15), \"K_u\":(0.20,0.08), \"p_low\":(0.12,0.06), \"p_high\":(2.20,0.60),\n",
    "    \"H_on\":(0.60,0.08), \"H_off\":(0.86,0.04), \"tau_q\":(5.0,2.0), \"K_B\":(0.20,0.08)\n",
    "}\n",
    "\n",
    "# Bounds (same as earlier)\n",
    "LBg = np.array([0.18,0.00,0.15,0.55,0.40,0.06,0.06,0.20,0.45,0.10,0.06,1.3,0.50,0.80,1.0,0.10])\n",
    "UBg = np.array([0.46,0.14,0.40,1.60,1.40,0.20,0.22,1.40,0.85,0.40,0.28,3.2,0.74,0.92,10.,0.40])\n",
    "\n",
    "x0g = np.array([0.32,0.07,0.28,1.0,0.85,0.12,0.12,0.60,0.60,0.20,0.12,2.20,0.60,0.86,5.0,0.20], float)\n",
    "\n",
    "# --- load data (same as before; omitted plots to keep short) ---\n",
    "df = pd.read_csv(INPATH)\n",
    "Hcol = next((c for c in H_COLS if c in df.columns), None)\n",
    "for c in SCFA_COLS:\n",
    "    if c not in df.columns: raise ValueError(f\"Missing SCFA column {c}\")\n",
    "df = df[[\"subject_id\",\"sample_id\",Hcol]+SCFA_COLS].dropna(subset=[\"subject_id\",\"sample_id\"]).copy()\n",
    "df[\"t_idx\"] = df.groupby(\"subject_id\").cumcount().astype(float)\n",
    "\n",
    "def robust_z(s):\n",
    "    import numpy as np, pandas as pd\n",
    "    x=s.astype(float).to_numpy(); m=np.isfinite(x)\n",
    "    if m.sum()==0: return pd.Series(np.zeros_like(x), index=s.index)\n",
    "    xm=x[m]; med=np.median(xm); mad=np.median(np.abs(xm-med))\n",
    "    if mad<1e-9:\n",
    "        q75,q25=np.percentile(xm,[75,25]); iqr=q75-q25\n",
    "        scale=iqr if iqr>1e-9 else (np.std(xm)+1e-9)\n",
    "    else:\n",
    "        scale=mad\n",
    "    return pd.Series((x-med)/(scale+1e-9), index=s.index)\n",
    "\n",
    "for c in SCFA_COLS:\n",
    "    df[c+\"_z\"] = df.groupby(\"subject_id\")[c].transform(robust_z)\n",
    "df[\"B_obs\"] = df[SCFA_COLS[0]+\"_z\"]\n",
    "df[\"H_obs\"] = df[Hcol].clip(0,1)\n",
    "\n",
    "subs=[]\n",
    "for sid, sub in df.groupby(\"subject_id\"):\n",
    "    sub=sub.sort_values(\"t_idx\").copy()\n",
    "    if len(sub)<MIN_ROWS: continue\n",
    "    t=sub[\"t_idx\"].values.astype(float)\n",
    "    B=sub[\"B_obs\"].values.astype(float)\n",
    "    H=sub[\"H_obs\"].values.astype(float)\n",
    "    mB=np.isfinite(B); mH=np.isfinite(H)\n",
    "    if mB.sum()<3 or mH.sum()<3: continue\n",
    "    def first(a,d):\n",
    "        a=np.asarray(a,float); idx=np.where(np.isfinite(a))[0]\n",
    "        return float(a[idx[0]]) if len(idx) else float(d)\n",
    "    subs.append({\n",
    "        \"sid\":sid,\"t\":t,\"B\":B,\"H\":H,\"maskB\":mB,\"maskH\":mH,\n",
    "        \"nB\":int(mB.sum()),\"nH\":int(mH.sum()),\n",
    "        \"H0\":float(np.clip(first(H,0.6),0,1)),\"B0\":float(max(0.05, first(B,0.1)))\n",
    "    })\n",
    "if not subs: raise RuntimeError(\"No subject passed minimal filters.\")\n",
    "\n",
    "# --- model (same as before) ---\n",
    "NAMES = [\"r0P\",\"rHP\",\"r0C\",\"K_M\",\"gamma\",\"c\",\"d\",\"g\",\"u\",\"K_u\",\"p_low\",\"p_high\",\"H_on\",\"H_off\",\"tau_q\",\"K_B\"]\n",
    "\n",
    "def q_inf(H,q,H_on,H_off,k=60.0):\n",
    "    th=(1.0-q)*H_on + q*H_off\n",
    "    return 1.0/(1.0 + np.exp(-k*(H - th)))\n",
    "\n",
    "def dH_hill(B,H,gH,d,K_B,n=2):\n",
    "    return gH*(B**n/(K_B**n + B**n))*(1 - H) - d*H\n",
    "\n",
    "def rhs(t,y,p):\n",
    "    P,C,H,B,q = y\n",
    "    r0P,rHP,r0C,K_M,gamma,c,d,gH,u,K_u,pL,pH,H_on,H_off,tau,K_B = p\n",
    "    pB = pL + (pH - pL)*np.clip(q,0,1)\n",
    "    dP = P*( r0P + rHP*H - c*pB - (P + gamma*C)/K_M )\n",
    "    dC = C*( r0C - (C + gamma*P)/K_M )\n",
    "    uptake = u*H*B/(K_u + B + 1e-9)\n",
    "    dB = pB*P - uptake\n",
    "    dH = dH_hill(B,H,gH,d,K_B)\n",
    "    dq = (q_inf(H,q,H_on,H_off) - q)/tau\n",
    "    return [dP,dC,dH,dB,dq]\n",
    "\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "def simulate(ts,y0,p):\n",
    "    try:\n",
    "        sol=solve_ivp(lambda t,z: rhs(t,z,p),(ts[0],ts[-1]),y0,t_eval=ts,\n",
    "                      rtol=1e-6,atol=1e-8,max_step=0.5)\n",
    "        if not sol.success:\n",
    "            T=len(ts); return np.vstack([np.full(T,np.nan)]*5)\n",
    "        return sol.y\n",
    "    except Exception:\n",
    "        T=len(ts); return np.vstack([np.full(T,np.nan)]*5)\n",
    "\n",
    "# per-subject obs maps\n",
    "x0s=[]; LBs=[]; UBs=[]\n",
    "for _ in subs:\n",
    "    x0s += [1.0, 0.0, 1.0]\n",
    "    LBs += [0.6, -0.2, 0.8]\n",
    "    UBs += [1.6,  0.2, 1.2]\n",
    "\n",
    "x0 = np.concatenate([x0g, np.array(x0s,float)])\n",
    "LB = np.concatenate([LBg, np.array(LBs,float)])\n",
    "UB = np.concatenate([UBg, np.array(UBs,float)])\n",
    "\n",
    "def unpack(x):\n",
    "    gpar = x[:len(NAMES)]\n",
    "    triples = np.split(x[len(NAMES):], len(subs))\n",
    "    return gpar, triples\n",
    "\n",
    "W_B, W_H = 0.6, 1.2\n",
    "TOTLEN = sum(S[\"nB\"] + S[\"nH\"] for S in subs) + len(PRIOR) + len(TARGETS)\n",
    "\n",
    "def residuals(x):\n",
    "    gpar, triples = unpack(x)\n",
    "    if not (gpar[13] > gpar[12]):\n",
    "        return np.full(TOTLEN, 1e3)\n",
    "    if gpar[9] <= 0.06 or gpar[15] <= 0.06:\n",
    "        return np.full(TOTLEN, 1e3)\n",
    "\n",
    "    res=[]\n",
    "    for S, tr in zip(subs, triples):\n",
    "        aB,b0H,b1H = tr\n",
    "        ts=S[\"t\"]; H0=np.clip(S[\"H0\"],0,1); B0=max(0.05,S[\"B0\"])\n",
    "        P0=C0=0.12; q0 = 1.0 if H0 < 0.5*(gpar[12]+gpar[13]) else 0.0\n",
    "        y0=[P0,C0,H0,B0,q0]\n",
    "        Y=simulate(ts,y0,gpar)\n",
    "        if np.any(~np.isfinite(Y)):\n",
    "            res += [W_B*np.full(S[\"nB\"],1e3), W_H*np.full(S[\"nH\"],1e3)]\n",
    "            continue\n",
    "        P,C,H,B,q = Y\n",
    "        Bhat=aB*B; Hhat=np.clip(b0H + b1H*H, 0,1)\n",
    "        b = (Bhat[S[\"maskB\"]] - S[\"B\"][S[\"maskB\"]])\n",
    "        h = (Hhat[S[\"maskH\"]] - S[\"H\"][S[\"maskH\"]])\n",
    "        res += [W_B*b.astype(float), W_H*h.astype(float)]\n",
    "\n",
    "    # baseline priors\n",
    "    idx = {nm:i for i,nm in enumerate(NAMES)}\n",
    "    for name,(mu,sd) in PRIOR.items():\n",
    "        res.append( np.array([(gpar[idx[name]] - mu)/(sd + 1e-9)]) )\n",
    "\n",
    "    # targeted priors (small set; stronger pull)\n",
    "    for name,(mu,sd) in TARGETS.items():\n",
    "        res.append( np.array([(gpar[idx[name]] - mu)/(sd + 1e-9)]) )\n",
    "\n",
    "    return np.concatenate(res)\n",
    "\n",
    "from scipy.optimize import least_squares\n",
    "fit = least_squares(residuals, x0, bounds=(LB,UB),\n",
    "                    verbose=2, max_nfev=1200, loss=\"soft_l1\", f_scale=1.0)\n",
    "gpar_hat, triples_hat = unpack(fit.x)\n",
    "\n",
    "pd.Series(gpar_hat, index=NAMES).to_csv(os.path.join(OUTDIR,\"fitted_global_params.csv\"), header=False)\n",
    "pd.DataFrame(\n",
    "    [{\"subject_id\":S[\"sid\"], \"alpha_B\":tr[0], \"beta0_H\":tr[1], \"beta1_H\":tr[2]}\n",
    "     for S,tr in zip(subs, triples_hat)]\n",
    ").to_csv(os.path.join(OUTDIR,\"fitted_subject_scales.csv\"), index=False)\n",
    "\n",
    "print(\"[info] Fitted globals:\", dict(zip(NAMES, gpar_hat)))\n",
    "print(\"✅ Done. Outputs in:\", OUTDIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aad51a-cdaa-470e-9fbd-1d137a14ffa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bifurcation_basins_guild_hill_satpf_TARGETED.py\n",
    "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from scipy.optimize import root\n",
    "from scipy.integrate import solve_ivp\n",
    "import numpy.linalg as npl\n",
    "\n",
    "FIT = \"mw_fit_out_guild_hill_satpf_targeted/fitted_global_params.csv\"\n",
    "OUT = \"mw_bif_guild_hill_satpf_targeted\"; os.makedirs(OUT, exist_ok=True)\n",
    "\n",
    "KQ=60.0; HILL_N=2\n",
    "g = pd.read_csv(FIT, index_col=0, header=None).squeeze(\"columns\")\n",
    "p = np.array([float(g[k]) for k in g.index.values], float)\n",
    "d_fit = float(p[6])\n",
    "\n",
    "def q_inf(H,q,H_on,H_off): th=(1-q)*H_on+q*H_off; return 1.0/(1.0+np.exp(-KQ*(H-th)))\n",
    "def dH(B,H,gH,d,K_B,n=HILL_N): return gH*(B**n/(K_B**n + B**n))*(1-H) - d*H\n",
    "def rhs(y,pvec,dval=None):\n",
    "    P,C,H,B,q=y\n",
    "    r0P,rHP,r0C,K_M,gamma,c,d,gH,u,K_u,pL,pH,H_on,H_off,tau,K_B=pvec.copy()\n",
    "    if dval is not None: d=dval\n",
    "    pB=pL+(pH-pL)*np.clip(q,0,1)\n",
    "    uptake=u*H*B/(K_u + B + 1e-9)\n",
    "    return np.array([\n",
    "        P*( r0P + rHP*H - c*pB - (P + gamma*C)/K_M ),\n",
    "        C*( r0C           -        (C + gamma*P)/K_M ),\n",
    "        dH(B,H,gH,d,K_B),\n",
    "        pB*P - uptake,\n",
    "        (q_inf(H,q,H_on,H_off)-q)/tau\n",
    "    ], float)\n",
    "\n",
    "def jac_fd(fun,y,pvec,dval,eps=1e-7):\n",
    "    f0=fun(y,pvec,dval); J=np.zeros((5,5))\n",
    "    for i in range(5):\n",
    "        y2=y.copy(); y2[i]+=eps\n",
    "        J[:,i]=(fun(y2,pvec,dval)-f0)/eps\n",
    "    return J\n",
    "\n",
    "def find_eq(pvec,dval,guess):\n",
    "    sol=root(lambda yy: rhs(yy,pvec,dval), guess, method=\"hybr\")\n",
    "    if not sol.success: return None, False\n",
    "    y=sol.x\n",
    "    y=np.array([max(0,y[0]), max(0,y[1]), np.clip(y[2],0,1.2), max(0,y[3]), np.clip(y[4],0,1.2)], float)\n",
    "    if not np.all(np.isfinite(y)): return None, False\n",
    "    return y, True\n",
    "\n",
    "# continuation in d\n",
    "d_vals=np.linspace(0.7*d_fit, 1.6*d_fit, 120)\n",
    "seeds=[np.array([0.15,0.05,0.3,0.05,1.0]),\n",
    "       np.array([0.05,0.20,0.9,0.10,0.0]),\n",
    "       np.array([0.30,0.15,0.6,0.15,0.5]),\n",
    "       np.array([0.05,0.05,0.5,0.05,0.8])]\n",
    "rows=[]\n",
    "for d in d_vals:\n",
    "    for wi,y0 in enumerate(seeds):\n",
    "        y,ok=find_eq(p,d,y0)\n",
    "        if not ok: continue\n",
    "        J=jac_fd(rhs,y,p,d)\n",
    "        stable=(np.max(np.real(npl.eigvals(J)))<0)\n",
    "        rows.append({\"d\":d,\"H\":float(y[2]),\"q\":float(y[4]),\"seed\":wi,\"stable\":stable})\n",
    "branches=pd.DataFrame(rows)\n",
    "branches.to_csv(os.path.join(OUT,\"branches.csv\"), index=False)\n",
    "\n",
    "plt.figure(figsize=(7.2,5.0))\n",
    "for wi in sorted(branches[\"seed\"].unique()):\n",
    "    sub=branches[branches[\"seed\"]==wi]\n",
    "    plt.plot(sub[\"d\"], sub[\"H\"], \".\", ms=3, alpha=0.7, label=f\"seed{wi}\")\n",
    "for st, mk in [(True,\"o\"),(False,\"x\")]:\n",
    "    sub=branches[branches[\"stable\"]==st]\n",
    "    plt.scatter(sub[\"d\"], sub[\"H\"], s=22, marker=mk, alpha=0.6, label=(\"stable\" if st else \"unstable\"))\n",
    "plt.axvline(d_fit, ls=\"--\", c=\"gray\", label=\"baseline d\")\n",
    "plt.xlabel(\"d (1/h)\"); plt.ylabel(\"H*\"); plt.legend(); plt.grid(True, ls=\":\")\n",
    "plt.tight_layout(); plt.savefig(os.path.join(OUT,\"bifurcation_H_vs_d.png\"), dpi=180); plt.close()\n",
    "\n",
    "# bistability at baseline?\n",
    "near=branches[np.isclose(branches[\"d\"], d_fit, atol=1e-3)]\n",
    "distinct=0\n",
    "if not near.empty:\n",
    "    Hs=np.sort(near.loc[near[\"stable\"],\"H\"].values)\n",
    "    if Hs.size:\n",
    "        distinct=1\n",
    "        for i in range(1,len(Hs)):\n",
    "            if abs(Hs[i]-Hs[i-1])>1e-3:\n",
    "                distinct+=1\n",
    "bistable=(distinct>=2)\n",
    "\n",
    "# basins at baseline\n",
    "from scipy.integrate import solve_ivp\n",
    "def relax(y0,T=360):\n",
    "    sol=solve_ivp(lambda t,z: rhs(z,p,d_fit),(0,T),y0,t_eval=np.linspace(0,T,900),\n",
    "                  rtol=1e-6,atol=1e-8,max_step=0.5)\n",
    "    return sol.y[:,-1]\n",
    "\n",
    "Hs=np.linspace(0.2,0.95,17)\n",
    "qs=np.linspace(0.0,1.0,17)\n",
    "Z=np.zeros((len(Hs),len(qs)))\n",
    "for i,H0 in enumerate(Hs):\n",
    "    for j,q0 in enumerate(qs):\n",
    "        y0=np.array([0.12,0.12,H0,0.10,q0],float)\n",
    "        yss=relax(y0)\n",
    "        Z[i,j]=yss[2]\n",
    "\n",
    "plt.figure(figsize=(6.6,5.2))\n",
    "plt.imshow(Z, origin=\"lower\", extent=[qs[0],qs[-1],Hs[0],Hs[-1]],\n",
    "           aspect=\"auto\", vmin=0.5, vmax=1.0, cmap=\"viridis\")\n",
    "plt.colorbar(label=\"Final H (steady)\")\n",
    "plt.xlabel(\"initial q\"); plt.ylabel(\"initial H\")\n",
    "plt.title(f\"Basins at baseline d={d_fit:.3f}  |  Bistable? {'YES' if bistable else 'NO'}\")\n",
    "plt.tight_layout(); plt.savefig(os.path.join(OUT,\"basins_heatmap.png\"), dpi=180); plt.close()\n",
    "\n",
    "with open(os.path.join(OUT,\"diagnosis.txt\"),\"w\") as f:\n",
    "    f.write(f\"Baseline d = {d_fit:.5f}\\n\")\n",
    "    f.write(f\"Distinct stable equilibria at baseline: {distinct}\\n\")\n",
    "    f.write(f\"Bistable at baseline? {'YES' if bistable else 'NO'}\\n\")\n",
    "\n",
    "print(\"Saved ->\", OUT, \"| Bistable at baseline? \", \"YES\" if bistable else \"NO\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127f7a16-7e12-439e-859d-d55b97d7ee7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scan_bistability_guild_wide.py\n",
    "# Two-guild model (P,C) + Hill host + saturable uptake + memory.\n",
    "# Scans a wider pocket with more curvature: Hill n in {3,4}, KQ=100.\n",
    "# Looks for >=2 distinct stable equilibria at baseline d.\n",
    "\n",
    "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from scipy.optimize import root\n",
    "import numpy.linalg as npl\n",
    "\n",
    "FIT = \"mw_fit_out_guild_hill_satpf/fitted_global_params.csv\"\n",
    "OUT = \"mw_scan_guild_wide\"; os.makedirs(OUT, exist_ok=True)\n",
    "\n",
    "# --- load fitted globals ---\n",
    "g = pd.read_csv(FIT, index_col=0, header=None).squeeze(\"columns\")\n",
    "# p = [r0P,rHP,r0C,K_M,gamma,c,d,g,u,K_u,p_low,p_high,H_on,H_off,tau_q,K_B]\n",
    "p0 = np.array([float(g[k]) for k in g.index.values], float)\n",
    "d_fit = float(p0[6])\n",
    "\n",
    "def q_inf(H,q,H_on,H_off,KQ):\n",
    "    th=(1-q)*H_on + q*H_off\n",
    "    return 1.0/(1.0 + np.exp(-KQ*(H - th)))\n",
    "\n",
    "def rhs(y,pvec,dval,n,KQ):\n",
    "    P,C,H,B,q = y\n",
    "    r0P,rHP,r0C,K_M,gamma,c,d,gH,u,K_u,pL,pH,H_on,H_off,tau,K_B = pvec.copy()\n",
    "    if dval is not None: d = dval\n",
    "    pB = pL + (pH - pL)*np.clip(q,0,1)\n",
    "    # ecology\n",
    "    dP = P*( r0P + rHP*H - c*pB - (P + gamma*C)/K_M )\n",
    "    dC = C*( r0C               - (C + gamma*P)/K_M )\n",
    "    # host and butyrate\n",
    "    uptake = u*H*B/(K_u + B + 1e-9)\n",
    "    dB = pB*P - uptake\n",
    "    dH = gH*(B**n/(K_B**n + B**n))*(1 - H) - d*H\n",
    "    dq = (q_inf(H,q,H_on,H_off,KQ) - q)/tau\n",
    "    return np.array([dP,dC,dH,dB,dq], float)\n",
    "\n",
    "def jac_fd(fun,y,args,eps=1e-7):\n",
    "    f0=fun(y,*args); J=np.zeros((5,5))\n",
    "    for i in range(5):\n",
    "        y2=y.copy(); y2[i]+=eps\n",
    "        J[:,i]=(fun(y2,*args)-f0)/eps\n",
    "    return J\n",
    "\n",
    "def find_eq(pvec,dval,guess,n,KQ):\n",
    "    sol=root(lambda yy: rhs(yy,pvec,dval,n,KQ), guess, method=\"hybr\")\n",
    "    if not sol.success: return None, False\n",
    "    y=sol.x\n",
    "    y=np.array([max(0,y[0]), max(0,y[1]), np.clip(y[2],0,1.2), max(0,y[3]), np.clip(y[4],0,1.2)], float)\n",
    "    if not np.all(np.isfinite(y)): return None, False\n",
    "    return y, True\n",
    "\n",
    "def count_stable(pvec,dval,n,KQ):\n",
    "    seeds = [\n",
    "        np.array([0.12,0.12,0.30,0.08,1.0]),\n",
    "        np.array([0.05,0.20,0.85,0.15,0.0]),\n",
    "        np.array([0.30,0.08,0.55,0.10,0.6]),\n",
    "        np.array([0.18,0.18,0.65,0.12,0.4]),\n",
    "    ]\n",
    "    Hs=[]\n",
    "    for y0 in seeds:\n",
    "        y,ok = find_eq(pvec,dval,y0,n,KQ)\n",
    "        if not ok: continue\n",
    "        J = jac_fd(rhs,y,(pvec,dval,n,KQ))\n",
    "        if np.max(np.real(npl.eigvals(J)))<0:\n",
    "            Hs.append(float(y[2]))\n",
    "    if not Hs: return 0\n",
    "    Hs=np.sort(Hs)\n",
    "    distinct=1\n",
    "    for i in range(1,len(Hs)):\n",
    "        if abs(Hs[i]-Hs[i-1])>1e-3:\n",
    "            distinct+=1\n",
    "    return distinct\n",
    "\n",
    "# --- scan ranges (wider than before, still plausible) ---\n",
    "grid = {\n",
    "    \"u\":      np.linspace(max(0.50,p0[8]-0.25),  min(0.80,p0[8]+0.05),  13),\n",
    "    \"K_u\":    np.linspace(max(0.10,p0[9]-0.10),  min(0.30,p0[9]+0.12),  11),\n",
    "    \"gamma\":  np.linspace(max(0.70,p0[4]-0.20),  min(1.30,p0[4]+0.44),  13),\n",
    "    \"p_high\": np.linspace(max(1.8,p0[11]-0.2),   3.2,                    15),\n",
    "    \"rHP\":    np.linspace(max(0.00,p0[1]-0.06),  min(0.15,p0[1]+0.08),  11),\n",
    "}\n",
    "hill_list = [3,4]\n",
    "KQ_list   = [80,100]\n",
    "# also allow a small baseline d tweak (±20%) to see nearby pockets\n",
    "d_list    = [d_fit, 0.9*d_fit, 1.1*d_fit]\n",
    "\n",
    "rows=[]\n",
    "for n in hill_list:\n",
    "    for KQ in KQ_list:\n",
    "        for d0 in d_list:\n",
    "            for u in grid[\"u\"]:\n",
    "                for Ku in grid[\"K_u\"]:\n",
    "                    for ga in grid[\"gamma\"]:\n",
    "                        for pH in grid[\"p_high\"]:\n",
    "                            for rHP in grid[\"rHP\"]:\n",
    "                                p = p0.copy()\n",
    "                                p[8]=u; p[9]=Ku; p[4]=ga; p[11]=pH; p[1]=rHP\n",
    "                                sc = count_stable(p, d0, n, KQ)\n",
    "                                rows.append({\"n\":n,\"KQ\":KQ,\"d_eval\":d0,\"u\":u,\"K_u\":Ku,\"gamma\":ga,\"p_high\":pH,\"rHP\":rHP,\n",
    "                                             \"stable_count\":sc})\n",
    "\n",
    "df=pd.DataFrame(rows)\n",
    "os.makedirs(OUT, exist_ok=True)\n",
    "out_csv=os.path.join(OUT,\"scan_results.csv\")\n",
    "df.to_csv(out_csv,index=False)\n",
    "\n",
    "# quick top summary\n",
    "top=df.sort_values([\"stable_count\",\"p_high\"],ascending=[False,False]).head(20)\n",
    "top.to_csv(os.path.join(OUT,\"top20.csv\"),index=False)\n",
    "print(\"Saved:\", out_csv)\n",
    "print(\"Top candidates:\\n\", top)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384f9f08-a321-4ff0-9ac1-6e09d3f8a241",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calibrate_and_check_guild_target_from_scan.py\n",
    "# Uses the same two-guild model and your data, adds soft targets from the scan,\n",
    "# refits, then immediately rechecks bifurcation & basins at the fitted baseline d.\n",
    "\n",
    "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.optimize import least_squares, root\n",
    "import numpy.linalg as npl\n",
    "\n",
    "DATA = \"timeseries/combined_scfas_table_scored.csv\"\n",
    "FIT_OUT = \"mw_fit_out_guild_hill_satpf_target_FROMSCAN\"; os.makedirs(FIT_OUT, exist_ok=True)\n",
    "BIF_OUT = \"mw_bif_guild_target_FROMSCAN\"; os.makedirs(BIF_OUT, exist_ok=True)\n",
    "\n",
    "# === Paste a row from mw_scan_guild_wide/top20.csv with stable_count >= 2 ===\n",
    "TARGETS = {\n",
    "    # example centers; replace with your own from the scan:\n",
    "    \"n\": 3,        # Hill exponent used only for bifurcation/check (not fitted)\n",
    "    \"KQ\": 80,     # memory steepness used for check (not fitted)\n",
    "    \"u\": 0.77,     \"sd_u\": 0.05,\n",
    "    \"K_u\": 0.18,   \"sd_K_u\": 0.05,\n",
    "    \"gamma\": 1.25, \"sd_gamma\": 0.15,\n",
    "    \"p_high\": 3.20,\"sd_p_high\": 0.30,\n",
    "    \"rHP\": 0.0344,   \"sd_rHP\": 0.04,\n",
    "}\n",
    "\n",
    "# === Model pieces (same as calibration script) ===\n",
    "H_COLS = [\"H_proxy_meta_smooth\",\"H_proxy_meta\"]\n",
    "SCFA_COLS=[\"butyrate\"]; MIN_ROWS=4\n",
    "PENALTY=1e3; HILL_N=3  # keep n=2 for fitting; use TARGETS[\"n\"] for the check\n",
    "KQ_fit=60.0\n",
    "\n",
    "# priors/bounds (same as earlier two-guild calibration)\n",
    "PRIOR = {\"r0P\":(0.32,0.08),\"rHP\":(0.07,0.04),\"r0C\":(0.28,0.08),\"K_M\":(1.00,0.25),\n",
    "         \"gamma\":(0.85,0.25),\"c\":(0.12,0.05),\"d\":(0.12,0.05),\"g\":(0.60,0.30),\n",
    "         \"u\":(0.60,0.15),\"K_u\":(0.20,0.08),\"p_low\":(0.12,0.06),\"p_high\":(2.20,0.60),\n",
    "         \"H_on\":(0.60,0.08),\"H_off\":(0.86,0.04),\"tau_q\":(5.0,2.0),\"K_B\":(0.20,0.08)}\n",
    "LBg=np.array([0.18,0.00,0.15,0.55,0.40,0.06,0.06,0.20,0.45,0.10,0.06,1.3,0.50,0.80,1.0,0.10])\n",
    "UBg=np.array([0.46,0.14,0.40,1.60,1.40,0.20,0.22,1.40,0.85,0.40,0.28,3.2,0.74,0.92,10.,0.40])\n",
    "x0g=np.array([0.32,0.07,0.28,1.0,0.85,0.12,0.12,0.60,0.60,0.20,0.12,2.2,0.60,0.86,5.0,0.20],float)\n",
    "\n",
    "def q_inf(H,q,H_on,H_off,KQ):\n",
    "    th=(1-q)*H_on + q*H_off\n",
    "    return 1.0/(1.0 + np.exp(-KQ*(H - th)))\n",
    "\n",
    "def rhs_fit(t,y,p):  # n=2, KQ_fit for calibration\n",
    "    P,C,H,B,q=y\n",
    "    r0P,rHP,r0C,K_M,gamma,c,d,gH,u,K_u,pL,pH,H_on,H_off,tau,K_B=p\n",
    "    pB = pL + (pH - pL)*np.clip(q,0,1)\n",
    "    dP = P*( r0P + rHP*H - c*pB - (P + gamma*C)/K_M )\n",
    "    dC = C*( r0C           -        (C + gamma*P)/K_M )\n",
    "    uptake = u*H*B/(K_u + B + 1e-9)\n",
    "    dB = pB*P - uptake\n",
    "    dH = gH*(B**2/(K_B**2 + B**2))*(1 - H) - d*H\n",
    "    dq = (q_inf(H,q,H_on,H_off,KQ_fit) - q)/tau\n",
    "    return [dP,dC,dH,dB,dq]\n",
    "\n",
    "def simulate(ts,y0,p):\n",
    "    from scipy.integrate import solve_ivp\n",
    "    try:\n",
    "        sol=solve_ivp(lambda t,z: rhs_fit(t,z,p),(ts[0],ts[-1]),y0,t_eval=ts,\n",
    "                      rtol=1e-6,atol=1e-8,max_step=0.5)\n",
    "        if not sol.success:\n",
    "            T=len(ts); return np.vstack([np.full(T,np.nan)]*5)\n",
    "        return sol.y\n",
    "    except Exception:\n",
    "        T=len(ts); return np.vstack([np.full(T,np.nan)]*5)\n",
    "\n",
    "# --- load data\n",
    "df=pd.read_csv(DATA)\n",
    "Hcol=next((c for c in H_COLS if c in df.columns), None)\n",
    "for c in SCFA_COLS:\n",
    "    if c not in df.columns: raise ValueError(f\"Missing {c}\")\n",
    "df=df[[\"subject_id\",\"sample_id\",Hcol]+SCFA_COLS].dropna(subset=[\"subject_id\",\"sample_id\"]).copy()\n",
    "df[\"t_idx\"]=df.groupby(\"subject_id\").cumcount().astype(float)\n",
    "\n",
    "def robust_z(s):\n",
    "    x=s.astype(float).to_numpy(); m=np.isfinite(x)\n",
    "    if m.sum()==0: import pandas as pd; return pd.Series(np.zeros_like(x), index=s.index)\n",
    "    xm=x[m]; med=np.median(xm); mad=np.median(np.abs(xm-med))\n",
    "    scale = mad if mad>1e-9 else (np.percentile(xm,75)-np.percentile(xm,25) or np.std(xm)+1e-9)\n",
    "    import pandas as pd; return pd.Series((x-med)/(scale+1e-9), index=s.index)\n",
    "\n",
    "df[\"B_z\"]=df.groupby(\"subject_id\")[SCFA_COLS[0]].transform(robust_z)\n",
    "df[\"H_obs\"]=df[Hcol].clip(0,1)\n",
    "\n",
    "subs=[]\n",
    "for sid,sub in df.groupby(\"subject_id\"):\n",
    "    sub=sub.sort_values(\"t_idx\").copy()\n",
    "    if len(sub)<4: continue\n",
    "    t=sub[\"t_idx\"].values.astype(float)\n",
    "    B=sub[\"B_z\"].values.astype(float)\n",
    "    H=sub[\"H_obs\"].values.astype(float)\n",
    "    mB=np.isfinite(B); mH=np.isfinite(H)\n",
    "    if mB.sum()<3 or mH.sum()<3: continue\n",
    "    def first(a,d):\n",
    "        import numpy as np\n",
    "        a=np.asarray(a,float); idx=np.where(np.isfinite(a))[0]\n",
    "        return float(a[idx[0]]) if len(idx) else float(d)\n",
    "    subs.append({\"sid\":sid,\"t\":t,\"B\":B,\"H\":H,\"maskB\":mB,\"maskH\":mH,\n",
    "                 \"nB\":int(mB.sum()),\"nH\":int(mH.sum()),\n",
    "                 \"H0\":float(np.clip(first(H,0.6),0,1)),\n",
    "                 \"B0\":float(max(0.05, first(B,0.1)))})\n",
    "if not subs: raise RuntimeError(\"no usable subjects\")\n",
    "\n",
    "# per-subject obs maps\n",
    "x0s=[];LBs=[];UBs=[]\n",
    "for _ in subs:\n",
    "    x0s += [1.0, 0.0, 1.0]\n",
    "    LBs += [0.6, -0.2, 0.8]\n",
    "    UBs += [1.6,  0.2, 1.2]\n",
    "\n",
    "x0=np.concatenate([x0g, np.array(x0s,float)])\n",
    "LB=np.concatenate([LBg, np.array(LBs,float)])\n",
    "UB=np.concatenate([UBg, np.array(UBs,float)])\n",
    "\n",
    "NAMES=[\"r0P\",\"rHP\",\"r0C\",\"K_M\",\"gamma\",\"c\",\"d\",\"g\",\"u\",\"K_u\",\"p_low\",\"p_high\",\"H_on\",\"H_off\",\"tau_q\",\"K_B\"]\n",
    "def unpack(x):\n",
    "    gpar=x[:len(NAMES)]\n",
    "    triples=np.split(x[len(NAMES):], len(subs))\n",
    "    return gpar, triples\n",
    "\n",
    "W_B,W_H=0.6,1.2\n",
    "TOT = sum(S[\"nB\"]+S[\"nH\"] for S in subs) + len(PRIOR) + 5  # 5 targeted priors\n",
    "\n",
    "def residuals(x):\n",
    "    gpar,triples=unpack(x)\n",
    "    if not (gpar[13] > gpar[12]): return np.full(TOT, PENALTY)\n",
    "    if gpar[9] <= 0.06 or gpar[15] <= 0.06: return np.full(TOT, PENALTY)\n",
    "    res=[]\n",
    "    for S,tr in zip(subs, triples):\n",
    "        aB,b0,b1 = tr\n",
    "        ts=S[\"t\"]; H0=np.clip(S[\"H0\"],0,1); B0=max(0.05,S[\"B0\"])\n",
    "        P0=C0=0.12; q0 = 1.0 if H0 < 0.5*(gpar[12]+gpar[13]) else 0.0\n",
    "        y0=[P0,C0,H0,B0,q0]\n",
    "        Y=simulate(ts,y0,gpar)\n",
    "        if np.any(~np.isfinite(Y)):\n",
    "            res += [W_B*np.full(S[\"nB\"],PENALTY), W_H*np.full(S[\"nH\"],PENALTY)]\n",
    "            continue\n",
    "        P,C,H,B,q = Y\n",
    "        Bh = aB*B; Hh=np.clip(b0 + b1*H,0,1)\n",
    "        b = (Bh[S[\"maskB\"]] - S[\"B\"][S[\"maskB\"]])\n",
    "        h = (Hh[S[\"maskH\"]] - S[\"H\"][S[\"maskH\"]])\n",
    "        res += [W_B*b.astype(float), W_H*h.astype(float)]\n",
    "    # baseline priors\n",
    "    idx={nm:i for i,nm in enumerate(NAMES)}\n",
    "    for nm,(mu,sd) in PRIOR.items():\n",
    "        res.append( np.array([(gpar[idx[nm]]-mu)/(sd+1e-9)]) )\n",
    "    # targeted priors\n",
    "    res.append( np.array([(gpar[idx[\"u\"]]      - TARGETS[\"u\"])/     (TARGETS[\"sd_u\"]+1e-9)]) )\n",
    "    res.append( np.array([(gpar[idx[\"K_u\"]]    - TARGETS[\"K_u\"])/   (TARGETS[\"sd_K_u\"]+1e-9)]) )\n",
    "    res.append( np.array([(gpar[idx[\"gamma\"]]  - TARGETS[\"gamma\"])/ (TARGETS[\"sd_gamma\"]+1e-9)]) )\n",
    "    res.append( np.array([(gpar[idx[\"p_high\"]] - TARGETS[\"p_high\"])/(TARGETS[\"sd_p_high\"]+1e-9)]) )\n",
    "    res.append( np.array([(gpar[idx[\"rHP\"]]    - TARGETS[\"rHP\"])/   (TARGETS[\"sd_rHP\"]+1e-9)]) )\n",
    "    return np.concatenate(res)\n",
    "\n",
    "fit = least_squares(residuals, x0, bounds=(LB,UB), verbose=2, max_nfev=1400, loss=\"soft_l1\", f_scale=1.0)\n",
    "gpar_hat,triples_hat=unpack(fit.x)\n",
    "pd.Series(gpar_hat,index=NAMES).to_csv(os.path.join(FIT_OUT,\"fitted_global_params.csv\"), header=False)\n",
    "\n",
    "print(\"[fit] globals:\", dict(zip(NAMES, gpar_hat)))\n",
    "\n",
    "# === Recheck bifurcation at the new fit using n=TARGETS['n'], KQ=TARGETS['KQ'] ===\n",
    "def rhs_check(y,pvec,dval):\n",
    "    P,C,H,B,q=y\n",
    "    r0P,rHP,r0C,K_M,gamma,c,d,gH,u,K_u,pL,pH,H_on,H_off,tau,K_B = pvec.copy()\n",
    "    if dval is not None: d=dval\n",
    "    pB=pL+(pH-pL)*np.clip(q,0,1)\n",
    "    uptake=u*H*B/(K_u + B + 1e-9)\n",
    "    n=int(TARGETS[\"n\"]); KQ=int(TARGETS[\"KQ\"])\n",
    "    dP=P*( r0P + rHP*H - c*pB - (P + gamma*C)/K_M )\n",
    "    dC=C*( r0C           -        (C + gamma*P)/K_M )\n",
    "    dB=pB*P - uptake\n",
    "    dH=gH*(B**n/(K_B**n + B**n))*(1-H) - d*H\n",
    "    dq=(1.0/(1.0+np.exp(-KQ*((H - ((1-q)*H_on + q*H_off)))))-q)/tau\n",
    "    return np.array([dP,dC,dH,dB,dq],float)\n",
    "\n",
    "def jac_fd(fun,y,args,eps=1e-7):\n",
    "    f0=fun(y,*args); J=np.zeros((5,5))\n",
    "    for i in range(5):\n",
    "        y2=y.copy(); y2[i]+=eps\n",
    "        J[:,i]=(fun(y2,*args)-f0)/eps\n",
    "    return J\n",
    "\n",
    "from scipy.optimize import root\n",
    "def find_eq(pvec,dval,guess):\n",
    "    sol=root(lambda yy: rhs_check(yy,pvec,dval), guess, method=\"hybr\")\n",
    "    if not sol.success: return None,False\n",
    "    y=sol.x\n",
    "    y=np.array([max(0,y[0]), max(0,y[1]), np.clip(y[2],0,1.2), max(0,y[3]), np.clip(y[4],0,1.2)], float)\n",
    "    return (y, True) if np.all(np.isfinite(y)) else (None, False)\n",
    "\n",
    "d_fit_new=float(gpar_hat[6])\n",
    "ds=np.linspace(0.7*d_fit_new, 1.6*d_fit_new, 120)\n",
    "seeds=[np.array([0.12,0.12,0.3,0.1,1.0]), np.array([0.05,0.2,0.85,0.1,0.0]),\n",
    "       np.array([0.3,0.05,0.55,0.1,0.6]), np.array([0.15,0.15,0.65,0.1,0.4])]\n",
    "\n",
    "rows=[]\n",
    "for dval in ds:\n",
    "    for wi,y0 in enumerate(seeds):\n",
    "        y,ok=find_eq(gpar_hat,dval,y0)\n",
    "        if not ok: continue\n",
    "        J=jac_fd(rhs_check,y,(gpar_hat,dval))\n",
    "        stable=(np.max(np.real(npl.eigvals(J)))<0)\n",
    "        rows.append({\"d\":dval,\"H\":float(y[2]),\"q\":float(y[4]),\"seed\":wi,\"stable\":stable})\n",
    "branches=pd.DataFrame(rows)\n",
    "branches.to_csv(os.path.join(BIF_OUT,\"branches.csv\"), index=False)\n",
    "\n",
    "plt.figure(figsize=(7.2,5.0))\n",
    "for wi in sorted(branches[\"seed\"].unique()):\n",
    "    sub=branches[branches[\"seed\"]==wi]\n",
    "    plt.plot(sub[\"d\"], sub[\"H\"], \".\", ms=3, alpha=0.7, label=f\"seed{wi}\")\n",
    "for st, mk in [(True,\"o\"),(False,\"x\")]:\n",
    "    sub=branches[branches[\"stable\"]==st]\n",
    "    plt.scatter(sub[\"d\"], sub[\"H\"], s=22, marker=mk, alpha=0.6, label=(\"stable\" if st else \"unstable\"))\n",
    "plt.axvline(d_fit_new, ls=\"--\", c=\"gray\", label=\"baseline d\")\n",
    "plt.xlabel(\"d (1/h)\"); plt.ylabel(\"H*\"); plt.legend(); plt.grid(True, ls=\":\")\n",
    "plt.tight_layout(); plt.savefig(os.path.join(BIF_OUT,\"bifurcation_H_vs_d.png\"), dpi=180); plt.close()\n",
    "\n",
    "near=branches[np.isclose(branches[\"d\"], d_fit_new, atol=1e-3)]\n",
    "distinct=0\n",
    "if not near.empty:\n",
    "    Hs=np.sort(near.loc[near[\"stable\"],\"H\"].values)\n",
    "    if Hs.size:\n",
    "        distinct=1\n",
    "        for i in range(1,len(Hs)):\n",
    "            if abs(Hs[i]-Hs[i-1])>1e-3:\n",
    "                distinct+=1\n",
    "bistable=(distinct>=2)\n",
    "with open(os.path.join(BIF_OUT,\"diagnosis.txt\"),\"w\") as f:\n",
    "    f.write(f\"Baseline d = {d_fit_new:.5f}\\n\")\n",
    "    f.write(f\"Distinct stable equilibria at baseline: {distinct}\\n\")\n",
    "    f.write(f\"Bistable at baseline? {'YES' if bistable else 'NO'}\\n\")\n",
    "print(\"Saved:\", BIF_OUT, \"| Bistable at baseline? \", \"YES\" if bistable else \"NO\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0dc72b-ff98-4645-904a-4ac67c0afe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bifurcation_guild_use_targets.py\n",
    "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from scipy.optimize import root\n",
    "import numpy.linalg as npl\n",
    "\n",
    "FIT = \"mw_fit_out_guild_hill_satpf/fitted_global_params.csv\"\n",
    "OUT = \"mw_bif_guild_use_targets\"; os.makedirs(OUT, exist_ok=True)\n",
    "\n",
    "# <<< paste your chosen row from the scan here >>>\n",
    "TARGETS = {\n",
    "    \"n\": 3,    # Hill exponent for host benefit\n",
    "    \"KQ\": 80,  # memory steepness\n",
    "    \"u\": 0.77,\n",
    "    \"K_u\": 0.18,\n",
    "    \"gamma\": 1.25,\n",
    "    \"p_high\": 3.20,\n",
    "    \"rHP\": 0.0344,\n",
    "    # optionally, if your top row used d_eval != d_fit, set it here:\n",
    "    \"d_override\": None,   # e.g., 0.9 * d_fit  -> put a float to test\n",
    "}\n",
    "\n",
    "g = pd.read_csv(FIT, index_col=0, header=None).squeeze(\"columns\")\n",
    "# p = [r0P,rHP,r0C,K_M,gamma,c,d,g,u,K_u,p_low,p_high,H_on,H_off,tau_q,K_B]\n",
    "p = np.array([float(g[k]) for k in g.index.values], float)\n",
    "\n",
    "# Override with targets\n",
    "idx = {\"r0P\":0,\"rHP\":1,\"r0C\":2,\"K_M\":3,\"gamma\":4,\"c\":5,\"d\":6,\"g\":7,\"u\":8,\"K_u\":9,\n",
    "       \"p_low\":10,\"p_high\":11,\"H_on\":12,\"H_off\":13,\"tau_q\":14,\"K_B\":15}\n",
    "p[idx[\"rHP\"]]   = TARGETS[\"rHP\"]\n",
    "p[idx[\"u\"]]     = TARGETS[\"u\"]\n",
    "p[idx[\"K_u\"]]   = TARGETS[\"K_u\"]\n",
    "p[idx[\"gamma\"]] = TARGETS[\"gamma\"]\n",
    "p[idx[\"p_high\"]]= TARGETS[\"p_high\"]\n",
    "\n",
    "d_fit = float(p[6])\n",
    "if TARGETS.get(\"d_override\") is not None:\n",
    "    d_fit = float(TARGETS[\"d_override\"])\n",
    "\n",
    "def q_inf(H,q,H_on,H_off,KQ):\n",
    "    th=(1-q)*H_on + q*H_off\n",
    "    return 1.0/(1.0 + np.exp(-KQ*(H - th)))\n",
    "\n",
    "def rhs(y,pvec,dval):\n",
    "    n   = int(TARGETS[\"n\"]); KQ = int(TARGETS[\"KQ\"])\n",
    "    P,C,H,B,q = y\n",
    "    r0P,rHP,r0C,K_M,gamma,c,d,gH,u,K_u,pL,pH,H_on,H_off,tau,K_B = pvec.copy()\n",
    "    if dval is not None: d = dval\n",
    "    pB = pL + (pH - pL)*np.clip(q,0,1)\n",
    "    # ecology\n",
    "    dP = P*( r0P + rHP*H - c*pB - (P + gamma*C)/K_M )\n",
    "    dC = C*( r0C               - (C + gamma*P)/K_M )\n",
    "    # host & butyrate\n",
    "    uptake = u*H*B/(K_u + B + 1e-9)\n",
    "    dB = pB*P - uptake\n",
    "    dH = gH*(B**n/(K_B**n + B**n))*(1 - H) - d*H\n",
    "    dq = (q_inf(H,q,H_on,H_off,KQ) - q)/tau\n",
    "    return np.array([dP,dC,dH,dB,dq], float)\n",
    "\n",
    "def jac_fd(fun,y,args,eps=1e-7):\n",
    "    f0=fun(y,*args); J=np.zeros((5,5))\n",
    "    for i in range(5):\n",
    "        y2=y.copy(); y2[i]+=eps\n",
    "        J[:,i]=(fun(y2,*args)-f0)/eps\n",
    "    return J\n",
    "\n",
    "def find_eq(pvec,dval,guess):\n",
    "    sol=root(lambda yy: rhs(yy,pvec,dval), guess, method=\"hybr\")\n",
    "    if not sol.success: return None,False\n",
    "    y=sol.x\n",
    "    y=np.array([max(0,y[0]), max(0,y[1]), np.clip(y[2],0,1.2), max(0,y[3]), np.clip(y[4],0,1.2)], float)\n",
    "    if not np.all(np.isfinite(y)): return None,False\n",
    "    return y,True\n",
    "\n",
    "# continuation in d around (possibly overridden) baseline\n",
    "ds=np.linspace(0.7*d_fit, 1.6*d_fit, 120)\n",
    "seeds=[np.array([0.12,0.12,0.3,0.1,1.0]),\n",
    "       np.array([0.05,0.2,0.9,0.1,0.0]),\n",
    "       np.array([0.3,0.05,0.55,0.1,0.6]),\n",
    "       np.array([0.15,0.15,0.65,0.1,0.4])]\n",
    "rows=[]\n",
    "for d in ds:\n",
    "    for wi,y0 in enumerate(seeds):\n",
    "        y,ok=find_eq(p,d,y0)\n",
    "        if not ok: continue\n",
    "        lam_max = np.max(np.real(npl.eigvals(jac_fd(rhs,y,(p,d)))))\n",
    "        rows.append({\"d\":d,\"H\":float(y[2]),\"seed\":wi,\"stable\":(lam_max<0)})\n",
    "\n",
    "branches=pd.DataFrame(rows)\n",
    "os.makedirs(OUT, exist_ok=True)\n",
    "branches.to_csv(os.path.join(OUT,\"branches.csv\"), index=False)\n",
    "\n",
    "plt.figure(figsize=(7.2,5.0))\n",
    "for wi in sorted(branches[\"seed\"].unique()):\n",
    "    sub=branches[branches[\"seed\"]==wi]\n",
    "    plt.plot(sub[\"d\"], sub[\"H\"], \".\", ms=3, alpha=0.7, label=f\"seed{wi}\")\n",
    "for st, mk in [(True,\"o\"),(False,\"x\")]:\n",
    "    sub=branches[branches[\"stable\"]==st]\n",
    "    plt.scatter(sub[\"d\"], sub[\"H\"], s=22, marker=mk, alpha=0.6, label=(\"stable\" if st else \"unstable\"))\n",
    "plt.axvline(d_fit, ls=\"--\", c=\"gray\", label=\"baseline d (tested)\")\n",
    "plt.xlabel(\"d (1/h)\"); plt.ylabel(\"H*\"); plt.legend(); plt.grid(True, ls=\":\")\n",
    "plt.tight_layout(); plt.savefig(os.path.join(OUT,\"bifurcation_H_vs_d.png\"), dpi=180); plt.close()\n",
    "\n",
    "near=branches[np.isclose(branches[\"d\"], d_fit, atol=1e-3)]\n",
    "distinct=0\n",
    "if not near.empty:\n",
    "    Hs=np.sort(near.loc[near[\"stable\"],\"H\"].values)\n",
    "    if Hs.size:\n",
    "        distinct=1\n",
    "        for i in range(1,len(Hs)):\n",
    "            if abs(Hs[i]-Hs[i-1])>1e-3:\n",
    "                distinct+=1\n",
    "bistable=(distinct>=2)\n",
    "with open(os.path.join(OUT,\"diagnosis.txt\"),\"w\") as f:\n",
    "    f.write(f\"d_tested = {d_fit:.5f}\\n\")\n",
    "    f.write(f\"Distinct stable equilibria at this d: {distinct}\\n\")\n",
    "    f.write(f\"Bistable at tested d? {'YES' if bistable else 'NO'}\\n\")\n",
    "print(\"Saved:\", OUT, \"| Bistable at tested d? \", \"YES\" if bistable else \"NO\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87926183-1545-4b28-8e57-23f634980eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate_guild_hard_targets.py\n",
    "import os, numpy as np, pandas as pd\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "INPATH = \"timeseries/combined_scfas_table_scored.csv\"\n",
    "OUTDIR = \"mw_fit_out_guild_hard_targets\"; os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "# === anchor around the pocket that gave 2 stable eq in the scan ===\n",
    "TARGETS = {\n",
    "    \"u\": 0.77,     \"sd_u\": 0.03,    # tighter\n",
    "    \"K_u\": 0.18,   \"sd_K_u\": 0.03,\n",
    "    \"gamma\": 1.25, \"sd_gamma\": 0.10,\n",
    "    \"p_high\": 3.20,\"sd_p_high\": 0.20,\n",
    "    \"rHP\": 0.0344, \"sd_rHP\": 0.02,\n",
    "    # If your best pocket appeared at d_eval different from baseline, anchor d too:\n",
    "    # \"d\": 0.054,   \"sd_d\": 0.006,\n",
    "}\n",
    "\n",
    "H_COLS=[\"H_proxy_meta_smooth\",\"H_proxy_meta\"]\n",
    "SCFA=[\"butyrate\"]; MIN_ROWS=4\n",
    "KQ=80.0; HILL_N=3\n",
    "PENALTY=1e3\n",
    "\n",
    "# Baseline priors (kept modest)\n",
    "PRIOR={\"r0P\":(0.32,0.08),\"rHP\":(0.07,0.04),\"r0C\":(0.28,0.08),\"K_M\":(1.0,0.25),\n",
    "       \"gamma\":(0.85,0.25),\"c\":(0.12,0.05),\"d\":(0.12,0.05),\"g\":(0.60,0.30),\n",
    "       \"u\":(0.60,0.15),\"K_u\":(0.20,0.08),\"p_low\":(0.12,0.06),\"p_high\":(2.20,0.60),\n",
    "       \"H_on\":(0.60,0.08),\"H_off\":(0.86,0.04),\"tau_q\":(5.0,2.0),\"K_B\":(0.20,0.08)}\n",
    "\n",
    "# Start from your previous two-guild bounds, but **shrink** key ones around TARGETS\n",
    "def band(c, w_lo, w_hi): return c - w_lo, c + w_hi\n",
    "uL,uU   = band(TARGETS[\"u\"],   0.05, 0.05)\n",
    "KuL,KuU = band(TARGETS[\"K_u\"], 0.06, 0.06)\n",
    "gaL,gaU = band(TARGETS[\"gamma\"], 0.20, 0.15)\n",
    "pHL,pHU = band(TARGETS[\"p_high\"], 0.40, 0.30)\n",
    "# other bounds (safe defaults)\n",
    "LBg=np.array([0.18,0.00,0.15,0.55,gaL,0.06,0.06,0.20,uL,KuL,0.06,pHL,0.50,0.80,1.0,0.10])\n",
    "UBg=np.array([0.46,0.14,0.40,1.60,gaU,0.20,0.22,1.40,uU,KuU,0.28,pHU,0.74,0.92,10.,0.40])\n",
    "# Optional: also narrow d if you know the pocket needed d slightly lower/higher.\n",
    "if \"d\" in TARGETS:\n",
    "    LBg[6], UBg[6] = band(TARGETS[\"d\"], 0.01, 0.01)\n",
    "\n",
    "x0g=np.array([0.32,0.05,0.28,1.0,1.10,0.12,0.10,0.70, TARGETS[\"u\"], TARGETS[\"K_u\"],\n",
    "              0.12, TARGETS[\"p_high\"], 0.60,0.86,5.5,0.20], float)\n",
    "\n",
    "# --- data prep (same as before; omitted plotting for brevity) ---\n",
    "df=pd.read_csv(INPATH)\n",
    "Hcol=next((c for c in H_COLS if c in df.columns), None)\n",
    "if Hcol is None: raise ValueError(\"Need H proxy col\")\n",
    "for c in SCFA:\n",
    "    if c not in df.columns: raise ValueError(f\"Missing {c}\")\n",
    "df=df[[\"subject_id\",\"sample_id\",Hcol]+SCFA].dropna(subset=[\"subject_id\",\"sample_id\"]).copy()\n",
    "df[\"t_idx\"]=df.groupby(\"subject_id\").cumcount().astype(float)\n",
    "\n",
    "def robust_z(s):\n",
    "    x=s.astype(float).to_numpy(); m=np.isfinite(x)\n",
    "    if m.sum()==0: import pandas as pd; return pd.Series(np.zeros_like(x), index=s.index)\n",
    "    xm=x[m]; med=np.median(xm); mad=np.median(np.abs(xm-med))\n",
    "    scale=mad if mad>1e-9 else (np.percentile(xm,75)-np.percentile(xm,25) or np.std(xm)+1e-9)\n",
    "    import pandas as pd; return pd.Series((x-med)/(scale+1e-9), index=s.index)\n",
    "\n",
    "df[\"B_z\"]=df.groupby(\"subject_id\")[SCFA[0]].transform(robust_z)\n",
    "df[\"H_obs\"]=df[Hcol].clip(0,1)\n",
    "\n",
    "subs=[]\n",
    "for sid,sub in df.groupby(\"subject_id\"):\n",
    "    sub=sub.sort_values(\"t_idx\")\n",
    "    if len(sub)<MIN_ROWS: continue\n",
    "    t=sub[\"t_idx\"].to_numpy(float)\n",
    "    B=sub[\"B_z\"].to_numpy(float); H=sub[\"H_obs\"].to_numpy(float)\n",
    "    mB=np.isfinite(B); mH=np.isfinite(H)\n",
    "    if mB.sum()<3 or mH.sum()<3: continue\n",
    "    def first(a,d):\n",
    "        import numpy as np\n",
    "        a=np.asarray(a,float); idx=np.where(np.isfinite(a))[0]\n",
    "        return float(a[idx[0]]) if len(idx) else float(d)\n",
    "    subs.append({\"sid\":sid,\"t\":t,\"B\":B,\"H\":H,\"maskB\":mB,\"maskH\":mH,\n",
    "                 \"nB\":int(mB.sum()),\"nH\":int(mH.sum()),\n",
    "                 \"H0\":float(np.clip(first(H,0.6),0,1)),\n",
    "                 \"B0\":float(max(0.05, first(B,0.1)))})\n",
    "if not subs: raise RuntimeError(\"no subjects\")\n",
    "\n",
    "# --- model (same RHS as before for calibration; n=3, KQ=80) ---\n",
    "def q_inf(H,q,H_on,H_off,KQ):\n",
    "    th=(1-q)*H_on + q*H_off\n",
    "    return 1.0/(1.0 + np.exp(-KQ*(H - th)))\n",
    "\n",
    "def rhs(t,y,p):\n",
    "    P,C,H,B,q=y\n",
    "    r0P,rHP,r0C,K_M,gamma,c,d,gH,u,K_u,pL,pH,H_on,H_off,tau,K_B = p\n",
    "    pB = pL + (pH - pL)*np.clip(q,0,1)\n",
    "    dP = P*( r0P + rHP*H - c*pB - (P + gamma*C)/K_M )\n",
    "    dC = C*( r0C           -        (C + gamma*P)/K_M )\n",
    "    uptake = u*H*B/(K_u + B + 1e-9)\n",
    "    dB = pB*P - uptake\n",
    "    n = 3\n",
    "    dH = gH*(B**n/(K_B**n + B**n))*(1 - H) - d*H\n",
    "    dq = (q_inf(H,q,H_on,H_off,KQ) - q)/tau\n",
    "    return [dP,dC,dH,dB,dq]\n",
    "\n",
    "def simulate(ts,y0,p):\n",
    "    try:\n",
    "        sol=solve_ivp(lambda t,z: rhs(t,z,p),(ts[0],ts[-1]),y0,t_eval=ts,\n",
    "                      rtol=1e-6,atol=1e-8,max_step=0.5)\n",
    "        if not sol.success:\n",
    "            T=len(ts); return np.vstack([np.full(T,np.nan)]*5)\n",
    "        return sol.y\n",
    "    except Exception:\n",
    "        T=len(ts); return np.vstack([np.full(T,np.nan)]*5)\n",
    "\n",
    "# per-subject obs maps\n",
    "x0s=[]; LBs=[]; UBs=[]\n",
    "for _ in subs: x0s += [1.0, 0.0, 1.0]; LBs += [0.6, -0.2, 0.8]; UBs += [1.6, 0.2, 1.2]\n",
    "x0=np.concatenate([x0g, np.array(x0s,float)])\n",
    "LB=np.concatenate([LBg, np.array(LBs,float)])\n",
    "UB=np.concatenate([UBg, np.array(UBs,float)])\n",
    "\n",
    "NAMES=[\"r0P\",\"rHP\",\"r0C\",\"K_M\",\"gamma\",\"c\",\"d\",\"g\",\"u\",\"K_u\",\"p_low\",\"p_high\",\"H_on\",\"H_off\",\"tau_q\",\"K_B\"]\n",
    "def unpack(x):\n",
    "    gpar=x[:len(NAMES)]\n",
    "    triples=np.split(x[len(NAMES):], len(subs))\n",
    "    return gpar, triples\n",
    "\n",
    "W_B,W_H=0.6,1.2\n",
    "# heavier weights for target priors\n",
    "WT=6.0\n",
    "\n",
    "def residuals(x):\n",
    "    gpar, triples = unpack(x)\n",
    "    if not (gpar[13] > gpar[12]): return np.ones(1000)*PENALTY\n",
    "    res=[]\n",
    "    for S,tr in zip(subs, triples):\n",
    "        aB,b0,b1=tr\n",
    "        ts=S[\"t\"]; H0=np.clip(S[\"H0\"],0,1); B0=max(0.05,S[\"B0\"])\n",
    "        P0=C0=0.12; q0=1.0 if H0 < 0.5*(gpar[12]+gpar[13]) else 0.0\n",
    "        y0=[P0,C0,H0,B0,q0]\n",
    "        Y=simulate(ts,y0,gpar)\n",
    "        if np.any(~np.isfinite(Y)):\n",
    "            res += [W_B*np.full(S[\"nB\"],PENALTY), W_H*np.full(S[\"nH\"],PENALTY)]\n",
    "            continue\n",
    "        P,C,H,B,q=Y\n",
    "        Bh=aB*B; Hh=np.clip(b0 + b1*H,0,1)\n",
    "        res += [W_B*(Bh[S[\"maskB\"]] - S[\"B\"][S[\"maskB\"]]),\n",
    "                W_H*(Hh[S[\"maskH\"]] - S[\"H\"][S[\"maskH\"]])]\n",
    "    # modest baseline priors\n",
    "    idx={nm:i for i,nm in enumerate(NAMES)}\n",
    "    for nm,(mu,sd) in PRIOR.items():\n",
    "        res.append(np.array([(gpar[idx[nm]]-mu)/(sd+1e-9)]))\n",
    "    # HARD targets\n",
    "    res.append(WT*np.array([(gpar[idx[\"u\"]]      - TARGETS[\"u\"])/     (TARGETS[\"sd_u\"]+1e-9)]))\n",
    "    res.append(WT*np.array([(gpar[idx[\"K_u\"]]    - TARGETS[\"K_u\"])/   (TARGETS[\"sd_K_u\"]+1e-9)]))\n",
    "    res.append(WT*np.array([(gpar[idx[\"gamma\"]]  - TARGETS[\"gamma\"])/ (TARGETS[\"sd_gamma\"]+1e-9)]))\n",
    "    res.append(WT*np.array([(gpar[idx[\"p_high\"]] - TARGETS[\"p_high\"])/(TARGETS[\"sd_p_high\"]+1e-9)]))\n",
    "    res.append(WT*np.array([(gpar[idx[\"rHP\"]]    - TARGETS[\"rHP\"])/   (TARGETS[\"sd_rHP\"]+1e-9)]))\n",
    "    if \"d\" in TARGETS:\n",
    "        res.append(WT*np.array([(gpar[idx[\"d\"]] - TARGETS[\"d\"])/(TARGETS[\"sd_d\"]+1e-9)]))\n",
    "    return np.concatenate(res)\n",
    "\n",
    "fit=least_squares(residuals, x0, bounds=(LB,UB), verbose=2, max_nfev=1500, loss=\"soft_l1\", f_scale=1.0)\n",
    "gpar_hat,_=unpack(fit.x)\n",
    "pd.Series(gpar_hat,index=NAMES).to_csv(os.path.join(OUTDIR,\"fitted_global_params.csv\"), header=False)\n",
    "print(\"[info] globals:\", dict(zip(NAMES, gpar_hat)))\n",
    "print(\"Saved:\", OUTDIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88141d6d-2cf1-4f31-a222-fc67ba4fd83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bifurcation_basins_from_hard_fit.py\n",
    "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from scipy.optimize import root\n",
    "import numpy.linalg as npl\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "FIT = \"mw_fit_out_guild_hard_targets/fitted_global_params.csv\"   # <- your latest fit\n",
    "OUT = \"mw_bif_guild_hard_fit\"; os.makedirs(OUT, exist_ok=True)\n",
    "\n",
    "# Curvature / memory for the check (tune if needed)\n",
    "N_HILL = 4\n",
    "KQ     = 80\n",
    "\n",
    "# Load fitted globals\n",
    "g = pd.read_csv(FIT, index_col=0, header=None).squeeze(\"columns\")\n",
    "# p = [r0P,rHP,r0C,K_M,gamma,c,d,g,u,K_u,p_low,p_high,H_on,H_off,tau_q,K_B]\n",
    "p = np.array([float(g[k]) for k in g.index.values], float)\n",
    "d_fit = float(p[6])\n",
    "\n",
    "def q_inf(H,q,H_on,H_off):\n",
    "    th=(1-q)*H_on + q*H_off\n",
    "    return 1.0/(1.0 + np.exp(-KQ*(H - th)))\n",
    "\n",
    "def rhs(y,pvec,d_override=None):\n",
    "    P,C,H,B,q = y\n",
    "    r0P,rHP,r0C,K_M,gamma,c,d,gH,u,K_u,pL,pH,H_on,H_off,tau,K_B = pvec.copy()\n",
    "    if d_override is not None:\n",
    "        d = d_override\n",
    "    pB = pL + (pH - pL)*np.clip(q,0,1)\n",
    "    # ecology\n",
    "    dP = P*( r0P + rHP*H - c*pB - (P + gamma*C)/K_M )\n",
    "    dC = C*( r0C           -        (C + gamma*P)/K_M )\n",
    "    # butyrate & host\n",
    "    uptake = u*H*B/(K_u + B + 1e-9)\n",
    "    dB = pB*P - uptake\n",
    "    dH = gH*(B**N_HILL/(K_B**N_HILL + B**N_HILL))*(1 - H) - d*H\n",
    "    dq = (q_inf(H,q,H_on,H_off) - q)/tau\n",
    "    return np.array([dP,dC,dH,dB,dq], float)\n",
    "\n",
    "def jac_fd(fun,y,args,eps=1e-7):\n",
    "    f0=fun(y,*args); J=np.zeros((5,5))\n",
    "    for i in range(5):\n",
    "        y2=y.copy(); y2[i]+=eps\n",
    "        J[:,i]=(fun(y2,*args)-f0)/eps\n",
    "    return J\n",
    "\n",
    "def find_eq(pvec,dval,guess):\n",
    "    sol=root(lambda yy: rhs(yy,pvec,dval), guess, method=\"hybr\")\n",
    "    if not sol.success:\n",
    "        return None, False\n",
    "    y=sol.x\n",
    "    y=np.array([max(0,y[0]), max(0,y[1]),\n",
    "                np.clip(y[2],0,1.2), max(0,y[3]), np.clip(y[4],0,1.2)], float)\n",
    "    if not np.all(np.isfinite(y)): return None, False\n",
    "    return y, True\n",
    "\n",
    "# ---- Continuation in d\n",
    "d_vals = np.linspace(0.7*d_fit, 1.6*d_fit, 140)\n",
    "seeds = [\n",
    "    np.array([0.12,0.12,0.30,0.10,1.0]),\n",
    "    np.array([0.05,0.20,0.90,0.12,0.0]),\n",
    "    np.array([0.30,0.08,0.55,0.10,0.6]),\n",
    "    np.array([0.15,0.15,0.65,0.12,0.4]),\n",
    "]\n",
    "rows=[]\n",
    "for d in d_vals:\n",
    "    for wi,y0 in enumerate(seeds):\n",
    "        y, ok = find_eq(p, d, y0)\n",
    "        if not ok: continue\n",
    "        lam_max = np.max(np.real(npl.eigvals(jac_fd(rhs, y, (p,d)))))\n",
    "        rows.append({\"d\":d, \"H\":float(y[2]), \"seed\":wi, \"stable\":(lam_max<0)})\n",
    "\n",
    "branches = pd.DataFrame(rows)\n",
    "branches.to_csv(os.path.join(OUT,\"branches.csv\"), index=False)\n",
    "\n",
    "# Plot bifurcation\n",
    "plt.figure(figsize=(7.6,5.2))\n",
    "for wi in sorted(branches[\"seed\"].unique()):\n",
    "    sub=branches[branches[\"seed\"]==wi]\n",
    "    plt.plot(sub[\"d\"], sub[\"H\"], \".\", ms=3, alpha=0.7, label=f\"seed{wi}\")\n",
    "for st, mk in [(True,\"o\"),(False,\"x\")]:\n",
    "    sub=branches[branches[\"stable\"]==st]\n",
    "    plt.scatter(sub[\"d\"], sub[\"H\"], s=24, marker=mk, alpha=0.7, label=(\"stable\" if st else \"unstable\"))\n",
    "plt.axvline(d_fit, ls=\"--\", c=\"gray\", label=\"baseline d\")\n",
    "plt.xlabel(\"d (1/h)\"); plt.ylabel(\"H*\"); plt.legend(); plt.grid(True, ls=\":\")\n",
    "plt.tight_layout(); plt.savefig(os.path.join(OUT,\"bifurcation_H_vs_d.png\"), dpi=180); plt.close()\n",
    "\n",
    "# Count distinct stable equilibria at baseline\n",
    "near = branches[np.isclose(branches[\"d\"], d_fit, atol=1e-3)]\n",
    "distinct=0\n",
    "if not near.empty:\n",
    "    Hs = np.sort(near.loc[near[\"stable\"],\"H\"].values)\n",
    "    if Hs.size:\n",
    "        distinct=1\n",
    "        for i in range(1,len(Hs)):\n",
    "            if abs(Hs[i]-Hs[i-1])>1e-3:\n",
    "                distinct+=1\n",
    "bistable = (distinct>=2)\n",
    "\n",
    "# ---- Basins at baseline\n",
    "def relax(y0,T=360):\n",
    "    sol=solve_ivp(lambda t,z: rhs(z,p,d_fit),(0,T),y0,t_eval=np.linspace(0,T,900),\n",
    "                  rtol=1e-6, atol=1e-8, max_step=0.5)\n",
    "    return sol.y[:,-1]\n",
    "\n",
    "Hs = np.linspace(0.20, 0.95, 19)\n",
    "qs = np.linspace(0.0, 1.0, 19)\n",
    "Z = np.zeros((len(Hs), len(qs)))\n",
    "for i,H0 in enumerate(Hs):\n",
    "    for j,q0 in enumerate(qs):\n",
    "        y0 = np.array([0.12,0.12,H0,0.10,q0], float)\n",
    "        yss = relax(y0)\n",
    "        Z[i,j] = yss[2]\n",
    "\n",
    "plt.figure(figsize=(6.8,5.4))\n",
    "plt.imshow(Z, origin=\"lower\", extent=[qs[0],qs[-1],Hs[0],Hs[-1]],\n",
    "           aspect=\"auto\", vmin=0.4, vmax=1.0, cmap=\"viridis\")\n",
    "plt.colorbar(label=\"Final H (steady)\")\n",
    "plt.xlabel(\"initial q\"); plt.ylabel(\"initial H\")\n",
    "plt.title(f\"Basins at baseline d={d_fit:.3f} | Bistable? {'YES' if bistable else 'NO'}\")\n",
    "plt.tight_layout(); plt.savefig(os.path.join(OUT,\"basins_heatmap.png\"), dpi=180); plt.close()\n",
    "\n",
    "with open(os.path.join(OUT,\"diagnosis.txt\"),\"w\") as f:\n",
    "    f.write(f\"Baseline d = {d_fit:.5f}\\n\")\n",
    "    f.write(f\"Distinct stable equilibria at baseline: {distinct}\\n\")\n",
    "    f.write(f\"Bistable at baseline? {'YES' if bistable else 'NO'}\\n\")\n",
    "\n",
    "print(\"Saved ->\", OUT, \"| Bistable at baseline? \", \"YES\" if bistable else \"NO\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767f50c2-47d2-4353-93d9-f5021e9e4652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export_equilibria_and_basins_fallback.py\n",
    "# Robust equilibria export with basin-scan fallback for stiff/hysteretic pockets.\n",
    "\n",
    "import os, numpy as np, pandas as pd, numpy.linalg as npl\n",
    "from scipy.optimize import root\n",
    "from scipy.integrate import solve_ivp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mw_model_constants import FIT_PATH, N_HILL, KQ, D_OVERRIDE\n",
    "\n",
    "OUT = \"mw_eq_export\"; os.makedirs(OUT, exist_ok=True)\n",
    "\n",
    "# ----- Load fitted globals -----\n",
    "g = pd.read_csv(FIT_PATH, index_col=0, header=None).squeeze(\"columns\")\n",
    "# p = [r0P,rHP,r0C,K_M,gamma,c,d,g,u,K_u,p_low,p_high,H_on,H_off,tau_q,K_B]\n",
    "p = np.array([float(g[k]) for k in g.index.values], float)\n",
    "if D_OVERRIDE is not None:\n",
    "    p[6] = float(D_OVERRIDE)\n",
    "d_fit = float(p[6])\n",
    "\n",
    "# ----- Model -----\n",
    "def q_inf(H,q,H_on,H_off):\n",
    "    th = (1-q)*H_on + q*H_off\n",
    "    return 1.0/(1.0 + np.exp(-KQ*(H - th)))\n",
    "\n",
    "def rhs(y, pvec):\n",
    "    P,C,H,B,q = y\n",
    "    r0P,rHP,r0C,K_M,gamma,c,d,gH,u,K_u,pL,pH,H_on,H_off,tau,K_B = pvec\n",
    "    pB = pL + (pH - pL)*np.clip(q,0,1)\n",
    "    # ecology\n",
    "    dP = P*( r0P + rHP*H - c*pB - (P + gamma*C)/K_M )\n",
    "    dC = C*( r0C           -        (C + gamma*P)/K_M )\n",
    "    # butyrate & host\n",
    "    uptake = u*H*B/(K_u + B + 1e-9)\n",
    "    dB = pB*P - uptake\n",
    "    dH = gH*(B**N_HILL/(K_B**N_HILL + B**N_HILL))*(1 - H) - d*H\n",
    "    dq = (q_inf(H,q,H_on,H_off) - q)/tau\n",
    "    return np.array([dP,dC,dH,dB,dq], float)\n",
    "\n",
    "def jac_fd(fun, y, args=(), eps=1e-6):\n",
    "    f0 = fun(y, *args); J = np.zeros((5,5))\n",
    "    for i in range(5):\n",
    "        y2 = y.copy(); y2[i] += eps\n",
    "        J[:, i] = (fun(y2, *args) - f0) / eps\n",
    "    return J\n",
    "\n",
    "def clamp_state(y):\n",
    "    return np.array([max(0,y[0]), max(0,y[1]),\n",
    "                     np.clip(y[2],0,1.2), max(0,y[3]), np.clip(y[4],0,1.2)], float)\n",
    "\n",
    "# ----- Root-finding attempt (multi-start) -----\n",
    "seeds = [\n",
    "    np.array([0.12,0.12,0.30,0.10,1.0]),\n",
    "    np.array([0.05,0.20,0.90,0.12,0.0]),\n",
    "    np.array([0.30,0.08,0.55,0.10,0.6]),\n",
    "    np.array([0.15,0.15,0.65,0.12,0.4]),\n",
    "    np.array([0.25,0.05,0.75,0.15,0.8]),\n",
    "    np.array([0.08,0.25,0.85,0.10,0.2]),\n",
    "]\n",
    "rows=[]\n",
    "for s in seeds:\n",
    "    sol = root(lambda yy: rhs(yy, p), s, method=\"hybr\")\n",
    "    if not sol.success: continue\n",
    "    y = clamp_state(sol.x)\n",
    "    if not np.all(np.isfinite(y)): continue\n",
    "    lam = np.real(npl.eigvals(jac_fd(lambda z: rhs(z,p), y)))\n",
    "    rows.append({\"P\":y[0],\"C\":y[1],\"H\":y[2],\"B\":y[3],\"q\":y[4],\n",
    "                 \"lam_max\":float(np.max(lam)),\"stable\":bool(np.max(lam)<0)})\n",
    "\n",
    "eqs = pd.DataFrame(rows).sort_values(\"H\").reset_index(drop=True)\n",
    "\n",
    "# De-duplicate by H\n",
    "def dedup_by_H(df, tol=1e-3):\n",
    "    if df.empty: return df\n",
    "    kept=[df.iloc[0]]\n",
    "    for i in range(1,len(df)):\n",
    "        if abs(df.iloc[i][\"H\"] - kept[-1][\"H\"]) > tol:\n",
    "            kept.append(df.iloc[i])\n",
    "    return pd.DataFrame(kept).reset_index(drop=True)\n",
    "\n",
    "eqs = dedup_by_H(eqs)\n",
    "\n",
    "# If we already have ≥2 stables, save & plot basins and return\n",
    "def save_all_and_exit(eqs_df, note=\"root-based\"):\n",
    "    eqs_df.to_csv(f\"{OUT}/equilibria.csv\", index=False)\n",
    "    # Basins heatmap\n",
    "    def relax(y0,T=900):\n",
    "        sol=solve_ivp(lambda t,z: rhs(z,p),(0,T),y0,t_eval=np.linspace(0,T,1200),\n",
    "                      rtol=1e-6, atol=1e-8, max_step=0.5)\n",
    "        return sol.y[:,-1]\n",
    "    Hs=np.linspace(0.15,0.95,25); qs=np.linspace(0.0,1.0,25)\n",
    "    Z=np.zeros((len(Hs),len(qs)))\n",
    "    for i,H0 in enumerate(Hs):\n",
    "        for j,q0 in enumerate(qs):\n",
    "            y0=np.array([0.12,0.12,H0,0.10,q0],float)\n",
    "            Z[i,j]=relax(y0)[2]\n",
    "    plt.figure(figsize=(6.6,5.2))\n",
    "    plt.imshow(Z, origin=\"lower\", extent=[qs[0],qs[-1],Hs[0],Hs[-1]], aspect=\"auto\", cmap=\"viridis\")\n",
    "    plt.colorbar(label=\"final H\")\n",
    "    plt.xlabel(\"q0\"); plt.ylabel(\"H0\")\n",
    "    plt.title(f\"Basins @ baseline (exported via {note})\")\n",
    "    plt.tight_layout(); plt.savefig(f\"{OUT}/basins.png\"), plt.close()\n",
    "    print(f\"Saved -> {OUT} | equilibria.csv + basins.png ({note})\")\n",
    "\n",
    "# Check if already bistable\n",
    "if not eqs.empty and (eqs[\"stable\"].sum() >= 2):\n",
    "    save_all_and_exit(eqs, note=\"root-only\")\n",
    "    raise SystemExit\n",
    "\n",
    "# ----- Fallback: basin scan to infer two attractors -----\n",
    "print(\"[info] Root-finder recovered <2 stable eq. Trying basin-scan fallback...\")\n",
    "def relax(y0, T=1200):\n",
    "    sol=solve_ivp(lambda t,z: rhs(z,p),(0,T),y0,t_eval=np.linspace(0,T,1400),\n",
    "                  rtol=1e-6, atol=1e-8, max_step=0.5)\n",
    "    return clamp_state(sol.y[:,-1])\n",
    "\n",
    "# dense grid; increase if needed\n",
    "Hs = np.linspace(0.12, 0.98, 29)\n",
    "qs = np.linspace(0.0,  1.0,  29)\n",
    "endpoints=[]\n",
    "for H0 in Hs:\n",
    "    for q0 in qs:\n",
    "        y0 = np.array([0.12,0.12,H0,0.10,q0], float)\n",
    "        yss= relax(y0, T=1400)\n",
    "        endpoints.append(yss)\n",
    "EP = np.array(endpoints)          # shape (N,5)\n",
    "H_end = EP[:,2]\n",
    "H_sorted = np.sort(H_end)\n",
    "\n",
    "# detect a gap in final H to split into two clusters\n",
    "gaps = np.diff(H_sorted)\n",
    "if gaps.size == 0 or np.max(gaps) < 0.03:   # require at least ~0.03 separation\n",
    "    # no clear two-basin structure found -> keep the monostable export (if any rows) and stop\n",
    "    # still save whatever we had (could be monostable)\n",
    "    if not eqs.empty:\n",
    "        save_all_and_exit(eqs, note=\"root-only (monostable)\")\n",
    "    else:\n",
    "        # fabricate a single 'equilibrium' by relaxing from mid initial\n",
    "        y_mid = relax(np.array([0.12,0.12,0.5,0.10,0.5],float))\n",
    "        lam = np.real(npl.eigvals(jac_fd(lambda z: rhs(z,p), y_mid)))\n",
    "        df = pd.DataFrame([{\"P\":y_mid[0],\"C\":y_mid[1],\"H\":y_mid[2],\"B\":y_mid[3],\"q\":y_mid[4],\n",
    "                            \"lam_max\":float(np.max(lam)),\"stable\":bool(np.max(lam)<0)}])\n",
    "        save_all_and_exit(df, note=\"fabricated-single (no split)\")\n",
    "    raise SystemExit\n",
    "\n",
    "# split by largest gap\n",
    "k = np.argmax(gaps)\n",
    "H_cut = 0.5*(H_sorted[k] + H_sorted[k+1])\n",
    "low_idxs  = np.where(H_end <= H_cut)[0]\n",
    "high_idxs = np.where(H_end >  H_cut)[0]\n",
    "low_mean  = EP[low_idxs].mean(axis=0)\n",
    "high_mean = EP[high_idxs].mean(axis=0)\n",
    "# representatives nearest to cluster means\n",
    "def nearest_idx(X, v):\n",
    "    return np.argmin(np.sum((X - v)**2, axis=1))\n",
    "i_low  = nearest_idx(EP[low_idxs],  low_mean)\n",
    "i_high = nearest_idx(EP[high_idxs], high_mean)\n",
    "y_low0  = EP[low_idxs][i_low]\n",
    "y_high0 = EP[high_idxs][i_high]\n",
    "\n",
    "# short refinement via root (optional but helpful)\n",
    "def refine(y_start):\n",
    "    try:\n",
    "        sol = root(lambda yy: rhs(yy, p), y_start, method=\"hybr\")\n",
    "        if sol.success:\n",
    "            y = clamp_state(sol.x)\n",
    "        else:\n",
    "            y = clamp_state(y_start)\n",
    "    except Exception:\n",
    "        y = clamp_state(y_start)\n",
    "    lam = np.real(npl.eigvals(jac_fd(lambda z: rhs(z,p), y)))\n",
    "    return y, float(np.max(lam))\n",
    "\n",
    "y_low,  lam_low  = refine(y_low0)\n",
    "y_high, lam_high = refine(y_high0)\n",
    "\n",
    "eq_fallback = pd.DataFrame([\n",
    "    {\"P\":y_low[0],\"C\":y_low[1],\"H\":y_low[2],\"B\":y_low[3],\"q\":y_low[4],\n",
    "     \"lam_max\":lam_low,  \"stable\": bool(lam_low  < 0)},\n",
    "    {\"P\":y_high[0],\"C\":y_high[1],\"H\":y_high[2],\"B\":y_high[3],\"q\":y_high[4],\n",
    "     \"lam_max\":lam_high, \"stable\": bool(lam_high < 0)},\n",
    "]).sort_values(\"H\").reset_index(drop=True)\n",
    "\n",
    "# (optional) attempt to locate an intermediate saddle by root from mid-H\n",
    "mid_guess = 0.5*(y_low + y_high); mid_guess[2] = 0.5*(y_low[2] + y_high[2])\n",
    "try:\n",
    "    sol_mid = root(lambda yy: rhs(yy,p), mid_guess, method=\"hybr\")\n",
    "    if sol_mid.success:\n",
    "        y_mid = clamp_state(sol_mid.x)\n",
    "        lam_mid = np.real(npl.eigvals(jac_fd(lambda z: rhs(z,p), y_mid)))\n",
    "        eq_fallback = pd.concat([eq_fallback,\n",
    "                                 pd.DataFrame([{\"P\":y_mid[0],\"C\":y_mid[1],\"H\":y_mid[2],\"B\":y_mid[3],\"q\":y_mid[4],\n",
    "                                                \"lam_max\":float(np.max(lam_mid)),\"stable\": bool(np.max(lam_mid)<0)}])],\n",
    "                                ignore_index=True).sort_values(\"H\").reset_index(drop=True)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "save_all_and_exit(eq_fallback, note=\"basin-fallback\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fd4bdc-a650-4394-8c24-df731b4cd9d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46668123-7181-4dbf-a31a-9ecd4b76d34a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854c412e-9d3a-4fca-8bf7-d2f2e3002af3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b962dab6-f5fb-4177-ac8c-4c59bf6e988c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5deb14e4-5079-43d1-affa-3b626a7eab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 07_mw_baseline_export.py\n",
    "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from mw_model_core import load_params, find_equilibria, relax_to_ss\n",
    "from mw_model_constants import N_HILL, KQ\n",
    "\n",
    "OUT = \"results/baseline_export\"; os.makedirs(OUT, exist_ok=True)\n",
    "p = load_params()\n",
    "\n",
    "# Equilibria\n",
    "eqs = find_equilibria(p)\n",
    "eqs.to_csv(f\"{OUT}/equilibria.csv\", index=False)\n",
    "\n",
    "# Basins heatmap in (H0, q0)\n",
    "Hs = np.linspace(0.15, 0.95, 25)\n",
    "qs = np.linspace(0.0, 1.0, 25)\n",
    "Z = np.zeros((len(Hs), len(qs)))\n",
    "for i,H0 in enumerate(Hs):\n",
    "    for j,q0 in enumerate(qs):\n",
    "        y0 = np.array([0.12,0.12,H0,0.10,q0], float)\n",
    "        yss, _ = relax_to_ss(p, y0, T=900)\n",
    "        Z[i,j] = yss[2]\n",
    "\n",
    "plt.figure(figsize=(6.6,5.2))\n",
    "plt.imshow(Z, origin=\"lower\", extent=[qs[0],qs[-1],Hs[0],Hs[-1]],\n",
    "           aspect=\"auto\", cmap=\"viridis\")\n",
    "plt.colorbar(label=\"final H\")\n",
    "plt.xlabel(\"q0\"); plt.ylabel(\"H0\")\n",
    "plt.title(f\"Basins @ baseline | N_HILL={N_HILL}, KQ={KQ}\")\n",
    "plt.tight_layout(); plt.savefig(f\"{OUT}/basins.png\"), plt.close()\n",
    "\n",
    "print(\"Saved ->\", OUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369fd588-60d1-4029-ae36-c14ce960ed62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 01_mw_phase_diagrams.py\n",
    "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from mw_model_core import load_params, bistability_by_multistart\n",
    "\n",
    "OUT = \"results/phase_diagrams\"; os.makedirs(OUT, exist_ok=True)\n",
    "p0 = load_params()\n",
    "\n",
    "def scan_pair(change_fn, grid_x, grid_y, label_x, label_y, tag, n_inits=80):\n",
    "    \"\"\" change_fn(p_base, x, y) -> new_p \"\"\"\n",
    "    A = np.zeros((len(grid_y), len(grid_x)))  # 1 if bistable else 0\n",
    "    rows=[]\n",
    "    for j,y in enumerate(grid_y):\n",
    "        for i,x in enumerate(grid_x):\n",
    "            p = change_fn(p0.copy(), x, y)\n",
    "            n_states, _ = bistability_by_multistart(p, n_inits=n_inits)\n",
    "            A[j,i] = 1 if n_states >= 2 else 0\n",
    "            rows.append({label_x:x, label_y:y, \"bistable\":bool(A[j,i])})\n",
    "        print(f\"[{tag}] row {j+1}/{len(grid_y)} done.\")\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(os.path.join(OUT, f\"{tag}_grid.csv\"), index=False)\n",
    "    plt.figure(figsize=(6.6,5.2))\n",
    "    plt.imshow(A, origin=\"lower\",\n",
    "               extent=[grid_x[0], grid_x[-1], grid_y[0], grid_y[-1]],\n",
    "               aspect=\"auto\", cmap=\"Blues\")\n",
    "    plt.colorbar(label=\"bistable (1) / mono (0)\")\n",
    "    plt.xlabel(label_x); plt.ylabel(label_y)\n",
    "    plt.title(f\"Bistability area: {tag} (fraction={A.mean():.2f})\")\n",
    "    plt.tight_layout(); plt.savefig(os.path.join(OUT, f\"{tag}_heatmap.png\")), plt.close()\n",
    "    print(f\"[{tag}] bistable fraction = {A.mean():.3f}\")\n",
    "\n",
    "# 1) (d, p_high)\n",
    "dx = np.linspace(0.7*p0[6], 1.6*p0[6], 20)\n",
    "py = np.linspace(0.6*p0[11], 1.4*p0[11], 20)\n",
    "def ch1(p,x,y): p[6]=x; p[11]=y; return p\n",
    "scan_pair(ch1, dx, py, \"d\", \"p_high\", \"d_vs_p_high\")\n",
    "\n",
    "# 2) (gamma, p_high)\n",
    "gx = np.linspace(0.6*p0[4], 1.6*p0[4], 20)\n",
    "def ch2(p,x,y): p[4]=x; p[11]=y; return p\n",
    "scan_pair(ch2, gx, py, \"gamma\", \"p_high\", \"gamma_vs_p_high\")\n",
    "\n",
    "# 3) (N_HILL, KQ) – treat as integers; here: 2..6 and 60..140\n",
    "nx = np.array([2,3,4,5,6], int)\n",
    "kqx = np.array([60,80,100,120,140], int)\n",
    "def ch3(p,x,y): return p  # p unchanged; we pass x,y via bistability_by_multistart kwargs\n",
    "def scan_pair_hill_kq(nx, kqx, tag):\n",
    "    A = np.zeros((len(kqx), len(nx)))\n",
    "    rows=[]\n",
    "    for j,KQv in enumerate(kqx):\n",
    "        for i,nv in enumerate(nx):\n",
    "            n_states, _ = bistability_by_multistart(p0.copy(), n_inits=60,\n",
    "                                                    KQ_local=KQv, N_HILL_local=nv)\n",
    "            A[j,i] = 1 if n_states >= 2 else 0\n",
    "            rows.append({\"N_HILL\":int(nv), \"KQ\":int(KQv), \"bistable\":bool(A[j,i])})\n",
    "        print(f\"[{tag}] row {j+1}/{len(kqx)} done.\")\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(os.path.join(OUT, f\"{tag}_grid.csv\"), index=False)\n",
    "    plt.figure(figsize=(6.6,5.2))\n",
    "    plt.imshow(A, origin=\"lower\", extent=[nx[0],nx[-1],kqx[0],kqx[-1]],\n",
    "               aspect=\"auto\", cmap=\"Blues\")\n",
    "    plt.colorbar(label=\"bistable (1) / mono (0)\")\n",
    "    plt.xlabel(\"N_HILL\"); plt.ylabel(\"KQ\")\n",
    "    plt.title(f\"Bistability area: {tag} (fraction={A.mean():.2f})\")\n",
    "    plt.tight_layout(); plt.savefig(os.path.join(OUT, f\"{tag}_heatmap.png\")), plt.close()\n",
    "    print(f\"[{tag}] bistable fraction = {A.mean():.3f}\")\n",
    "\n",
    "scan_pair_hill_kq(nx, kqx, \"N_HILL_vs_KQ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb33547-3492-4936-ab40-ca79291484d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02_mw_attractor_counting.py\n",
    "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from mw_model_core import load_params, relax_to_ss\n",
    "\n",
    "OUT = \"results/attractor_counting\"; os.makedirs(OUT, exist_ok=True)\n",
    "p = load_params()\n",
    "\n",
    "def many_inits(pvec, n=200, T=1200, tag=\"baseline\"):\n",
    "    rng = np.random.default_rng(1)\n",
    "    box = ((0.05,0.30),(0.05,0.30),(0.10,0.95),(0.05,0.20),(0.0,1.0))\n",
    "    def rand_in(box): return np.array([rng.uniform(a,b) for (a,b) in box], float)\n",
    "    endpoints=[]; H_trajs=[]\n",
    "    for k in range(n):\n",
    "        y0 = rand_in(box)\n",
    "        yss, sol = relax_to_ss(pvec, y0, T=T)\n",
    "        endpoints.append(yss)\n",
    "        H_trajs.append(sol.y[2,:])\n",
    "    EP = np.array(endpoints); Hs = EP[:,2]\n",
    "    H_sorted = np.sort(Hs); gaps = np.diff(H_sorted)\n",
    "    n_states = 1 + np.sum(gaps >= 0.03)\n",
    "    pd.DataFrame(EP, columns=[\"P\",\"C\",\"H\",\"B\",\"q\"]).to_csv(os.path.join(OUT, f\"{tag}_endpoints.csv\"), index=False)\n",
    "    # small panel of random trajectories\n",
    "    plt.figure(figsize=(7,4))\n",
    "    for i in np.linspace(0, len(H_trajs)-1, 30, dtype=int):\n",
    "        plt.plot(H_trajs[i], alpha=0.4)\n",
    "    plt.xlabel(\"time step\"); plt.ylabel(\"H(t)\")\n",
    "    plt.title(f\"Attractor test ({tag}) | distinct≈{n_states}\")\n",
    "    plt.tight_layout(); plt.savefig(os.path.join(OUT, f\"{tag}_trajectories.png\")), plt.close()\n",
    "    print(f\"[{tag}] distinct steady states (by gaps in H): ~{int(n_states)}\")\n",
    "    return int(n_states)\n",
    "\n",
    "# Baseline\n",
    "many_inits(p, n=200, T=1200, tag=\"baseline\")\n",
    "\n",
    "# Slight offsets around baseline (±10%)\n",
    "p1 = p.copy(); p1[6] = 0.9*p[6]   # d down\n",
    "p2 = p.copy(); p2[6] = 1.1*p[6]   # d up\n",
    "many_inits(p1, n=150, tag=\"d_minus10\")\n",
    "many_inits(p2, n=150, tag=\"d_plus10\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98e63af-ebec-4a4f-87ee-8f8e26481395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 03_mw_sensitivity_curves.py\n",
    "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from mw_model_core import bistability_by_multistart, load_params\n",
    "\n",
    "OUT = \"results/sensitivity_curves\"; os.makedirs(OUT, exist_ok=True)\n",
    "p0 = load_params()\n",
    "\n",
    "def frac_bistable_vs_param(idx, vals, label, tag):\n",
    "    fracs=[]\n",
    "    for v in vals:\n",
    "        p = p0.copy(); p[idx] = v\n",
    "        n_states, _ = bistability_by_multistart(p, n_inits=80)\n",
    "        fracs.append(1.0 if n_states>=2 else 0.0)\n",
    "    df = pd.DataFrame({label: vals, \"bistable\": fracs})\n",
    "    df.to_csv(os.path.join(OUT, f\"{tag}.csv\"), index=False)\n",
    "    plt.figure(figsize=(6.8,4.2))\n",
    "    plt.plot(vals, fracs, \"-o\")\n",
    "    plt.xlabel(label); plt.ylabel(\"bistable fraction\")\n",
    "    plt.ylim(-0.05, 1.05); plt.grid(True, ls=\":\")\n",
    "    plt.title(tag)\n",
    "    plt.tight_layout(); plt.savefig(os.path.join(OUT, f\"{tag}.png\")), plt.close()\n",
    "    print(f\"[{tag}] mean={np.mean(fracs):.3f}\")\n",
    "\n",
    "# d (index 6)\n",
    "d_vals = np.linspace(0.6*p0[6], 1.6*p0[6], 24)\n",
    "frac_bistable_vs_param(6, d_vals, \"d\", \"bistability_vs_d\")\n",
    "\n",
    "# gamma (index 4)\n",
    "g_vals = np.linspace(0.6*p0[4], 1.6*p0[4], 24)\n",
    "frac_bistable_vs_param(4, g_vals, \"gamma\", \"bistability_vs_gamma\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400bbd94-f67b-49c1-89c2-911286233b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 04_mw_gamma_heterogeneity.py\n",
    "import os, numpy as np, pandas as pd\n",
    "from mw_model_core import load_params, bistability_by_multistart\n",
    "\n",
    "OUT = \"results/gamma_heterogeneity\"; os.makedirs(OUT, exist_ok=True)\n",
    "p0 = load_params()\n",
    "rng = np.random.default_rng(7)\n",
    "\n",
    "def experiment(mean_gamma, sd_gamma, trials=20):\n",
    "    flags=[]\n",
    "    for _ in range(trials):\n",
    "        p = p0.copy()\n",
    "        g_draw = float(np.clip(rng.normal(mean_gamma, sd_gamma), 0.2, 3.0))\n",
    "        p[4] = g_draw\n",
    "        n_states, _ = bistability_by_multistart(p, n_inits=60)\n",
    "        flags.append(1 if n_states>=2 else 0)\n",
    "    return np.mean(flags)\n",
    "\n",
    "rows=[]\n",
    "means = np.linspace(0.6*p0[4], 1.6*p0[4], 8)\n",
    "sds   = np.linspace(0.0, 0.4, 6)\n",
    "for m in means:\n",
    "    for s in sds:\n",
    "        frac = experiment(m, s, trials=30)\n",
    "        rows.append({\"mean_gamma\":m, \"sd_gamma\":s, \"bistable_frac\":frac})\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(os.path.join(OUT, \"gamma_heterogeneity_grid.csv\"), index=False)\n",
    "print(\"Saved ->\", OUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49931cdc-8f45-4095-81f6-62dad5a6726f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05_mw_epistasis_analog.py\n",
    "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from mw_model_core import load_params, bistability_by_multistart\n",
    "\n",
    "OUT = \"results/epistasis_analog\"; os.makedirs(OUT, exist_ok=True)\n",
    "p0 = load_params()\n",
    "\n",
    "# We'll vary: rHP (index 1) for Producer;\n",
    "# and add an artificial \"competitor host coupling\" by shifting r0C (index 2) with k*H (sign analog).\n",
    "# Implement sign analog by altering effective r0C during integration? Simpler: use a static proxy:\n",
    "#   We emulate 'sign' by adding delta to r0C when H is high at steady state via a two-stage test.\n",
    "#   For area maps, we approximate by direct parameter offsets to r0C: neutral (0), beneficial (+δ), costly (-δ).\n",
    "\n",
    "def area_bistable_over_grid(deltaC, rHP_scale_grid, tag):\n",
    "    # deltaC in {-dlt, 0, +dlt} approximates sign epistasis\n",
    "    rows=[]; cnt=0; total=0\n",
    "    for s in rHP_scale_grid:\n",
    "        for ph in np.linspace(0.7*p0[11], 1.4*p0[11], 12):  # p_high axis\n",
    "            p = p0.copy()\n",
    "            p[1] = s * p0[1]      # rHP scaled\n",
    "            p[11]= ph\n",
    "            p[2] = p0[2] + deltaC # competitor base growth shift (proxy for sign)\n",
    "            n_states, _ = bistability_by_multistart(p, n_inits=60)\n",
    "            is_bi = (n_states >= 2)\n",
    "            rows.append({\"rHP_scale\":s, \"p_high\":ph, \"bistable\":bool(is_bi)})\n",
    "            cnt += int(is_bi); total += 1\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(os.path.join(OUT, f\"{tag}.csv\"), index=False)\n",
    "    frac = cnt/total if total>0 else 0.0\n",
    "    print(f\"[{tag}] bistable fraction={frac:.3f}\")\n",
    "    # quick plot\n",
    "    S = sorted(df[\"rHP_scale\"].unique())\n",
    "    P = sorted(df[\"p_high\"].unique())\n",
    "    W = np.zeros((len(P), len(S)))\n",
    "    for j,ph in enumerate(P):\n",
    "        for i,s in enumerate(S):\n",
    "            W[j,i] = 1.0 if bool(df[(df[\"rHP_scale\"]==s)&(df[\"p_high\"]==ph)][\"bistable\"].iloc[0]) else 0.0\n",
    "    plt.figure(figsize=(6.4,5.0))\n",
    "    plt.imshow(W, origin=\"lower\", extent=[min(S), max(S), min(P), max(P)], aspect=\"auto\", cmap=\"Blues\")\n",
    "    plt.colorbar(label=\"bistable\")\n",
    "    plt.xlabel(\"rHP scale\"); plt.ylabel(\"p_high\")\n",
    "    plt.title(tag + f\" (fraction={frac:.2f})\")\n",
    "    plt.tight_layout(); plt.savefig(os.path.join(OUT, f\"{tag}.png\")), plt.close()\n",
    "\n",
    "rHP_scales = np.linspace(0.5, 1.8, 12)\n",
    "dlt = 0.05\n",
    "\n",
    "area_bistable_over_grid( 0.0, rHP_scales, \"magnitude_only\")\n",
    "area_bistable_over_grid(+dlt, rHP_scales, \"sign_beneficial_for_competitor\")\n",
    "area_bistable_over_grid(-dlt, rHP_scales, \"sign_costly_for_competitor\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acedb519-72c8-4085-aee9-3e6cdc684387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 06_mw_metacommunity_mosaic.py\n",
    "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from mw_model_core import load_params, relax_to_ss\n",
    "\n",
    "OUT = \"results/metacommunity\"; os.makedirs(OUT, exist_ok=True)\n",
    "p = load_params()\n",
    "rng = np.random.default_rng(11)\n",
    "\n",
    "# Grid of patches\n",
    "G = (12, 12)  # 12x12 patches\n",
    "H_final = np.zeros(G)\n",
    "\n",
    "for i in range(G[0]):\n",
    "    for j in range(G[1]):\n",
    "        # small jitter around two typical initials to populate both basins\n",
    "        if (i+j) % 2 == 0:\n",
    "            H0 = 0.25 + 0.05*rng.normal()\n",
    "            q0 = 0.8  + 0.05*rng.normal()\n",
    "        else:\n",
    "            H0 = 0.75 + 0.05*rng.normal()\n",
    "            q0 = 0.2  + 0.05*rng.normal()\n",
    "        y0 = np.array([0.12,0.12, np.clip(H0,0.1,0.95), 0.10, np.clip(q0,0,1)], float)\n",
    "        yss, _ = relax_to_ss(p, y0, T=1100)\n",
    "        H_final[i,j] = yss[2]\n",
    "\n",
    "np.save(os.path.join(OUT,\"H_mosaic.npy\"), H_final)\n",
    "plt.figure(figsize=(6.2,5.2))\n",
    "plt.imshow(H_final, origin=\"lower\", cmap=\"viridis\", vmin=0.1, vmax=1.0)\n",
    "plt.colorbar(label=\"final H*\")\n",
    "plt.title(\"Metacommunity mosaic (independent patches)\")\n",
    "plt.tight_layout(); plt.savefig(os.path.join(OUT,\"mosaic.png\")), plt.close()\n",
    "\n",
    "print(\"Saved ->\", OUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d9018d-e815-4247-8362-3a163ef457a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 08_mw_bootstrap_robustness.py\n",
    "import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from mw_model_core import load_params, bistability_by_multistart\n",
    "\n",
    "OUT = \"results/bootstrap_robustness\"; os.makedirs(OUT, exist_ok=True)\n",
    "p0 = load_params()\n",
    "rng = np.random.default_rng(23)\n",
    "\n",
    "def area_fraction_dp(p_base, n_x=10, n_y=10, jitter=None):\n",
    "    dx = np.linspace(0.8*p_base[6], 1.3*p_base[6], n_x)     # d\n",
    "    ph = np.linspace(0.7*p_base[11], 1.3*p_base[11], n_y)   # p_high\n",
    "    cnt=0; tot=0\n",
    "    for x in dx:\n",
    "        for y in ph:\n",
    "            p = p_base.copy(); p[6]=x; p[11]=y\n",
    "            n_states,_ = bistability_by_multistart(p, n_inits=50)\n",
    "            cnt += int(n_states>=2); tot += 1\n",
    "    return cnt / tot\n",
    "\n",
    "def jitter_params(p, cv=0.08):\n",
    "    \"\"\" multiplicative noise on selected entries: g(7), u(8), K_u(9), p_high(11) \"\"\"\n",
    "    idx = [7,8,9,11]\n",
    "    p2 = p.copy()\n",
    "    for k in idx:\n",
    "        p2[k] = p2[k] * float(np.exp(rng.normal(0, cv)))\n",
    "    return p2\n",
    "\n",
    "B = 40\n",
    "vals=[]\n",
    "for b in range(B):\n",
    "    pB = jitter_params(p0, cv=0.10)  # 10% lognormal CV\n",
    "    frac = area_fraction_dp(pB, n_x=9, n_y=9)\n",
    "    vals.append(frac)\n",
    "    print(f\"[bootstrap] {b+1}/{B}: {frac:.3f}\")\n",
    "\n",
    "pd.DataFrame({\"area_fraction\":vals}).to_csv(os.path.join(OUT, \"bootstrap_area_fractions.csv\"), index=False)\n",
    "plt.figure(figsize=(5.0,4.2))\n",
    "plt.plot(np.arange(1,B+1), vals, \"-o\", alpha=0.7)\n",
    "plt.axhline(np.mean(vals), ls=\"--\", c=\"gray\", label=f\"mean={np.mean(vals):.2f}\")\n",
    "plt.xlabel(\"bootstrap draw\"); plt.ylabel(\"bistable area fraction\")\n",
    "plt.legend(); plt.grid(True, ls=\":\")\n",
    "plt.tight_layout(); plt.savefig(os.path.join(OUT,\"bootstrap_trace.png\")), plt.close()\n",
    "print(\"Saved ->\", OUT)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benpyenv",
   "language": "python",
   "name": "benpyenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
